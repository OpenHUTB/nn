import sys
import os
sys.path.append('/home/dacun/nn/src')

import numpy as np
import cv2
from tensorflow.keras.models import load_model
from common.transformations.camera import transform_img, eon_intrinsics
from common.transformations.model import medmodel_intrinsics
from common.tools.lib.parser import parser

# å…³é—­TensorFlowæ‰€æœ‰å†—ä½™è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# -------------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° --------------------------
def frames_to_tensor(frames):
    if len(frames) == 0:
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    tensor[:, 4] = frames[:, H:H+H//4].reshape((-1, H//2, W//2))
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape((-1, H//2, W//2))
    return tensor / 128.0 - 1.0

def preprocess_frames(imgs):
    if not imgs:
        return np.array([])
    processed = np.zeros((len(imgs), 384, 512), dtype=np.uint8)
    for i, img in enumerate(imgs):
        try:
            processed[i] = transform_img(img, from_intr=eon_intrinsics, to_intr=medmodel_intrinsics, yuv=True, output_size=(512, 256))
        except:
            processed[i] = np.zeros((384, 512), dtype=np.uint8)
    return frames_to_tensor(processed)

# -------------------------- ä¸»å‡½æ•°ï¼ˆæ— å‚æ•°ã€å…¨è‹±æ–‡ã€è½¦é“çº¿ä¼˜åŒ–ï¼‰ --------------------------
def main():
    # 1. åˆå§‹åŒ–æ˜¾ç¤ºçª—å£ï¼ˆ800x600ï¼Œå›ºå®šå°ºå¯¸ï¼‰
    win_name = "Lane Line Prediction (Blue=Left | Red=Right | Green=Path)"
    cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(win_name, 800, 600)

    # 2. è¯»å–è§†é¢‘ï¼ˆå†™æ­»è·¯å¾„ï¼Œæ— éœ€ä¼ å‚ï¼‰
    video_path = "/home/dacun/nn/sample.hevc"
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        empty_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
        cv2.putText(empty_frame, "Cannot open video", (150, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        cv2.imshow(win_name, empty_frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return

    # è¯»å–å‰10å¸§ï¼ˆç”¨äºæ¨ç†ï¼Œä¿ç•™åŸå§‹å¸§å’Œæ¨¡å‹è¾“å…¥å¸§ï¼‰
    raw_display_frames = []  # ç”¨äºæ˜¾ç¤ºçš„800x600å¸§
    model_input_imgs = []    # ç”¨äºæ¨¡å‹çš„512x384 YUVå¸§
    for _ in range(10):
        ret, frame = cap.read()
        if not ret:
            break
        # ç¼©æ”¾ä¸ºæ˜¾ç¤ºå°ºå¯¸ï¼ˆ800x600ï¼‰
        display_frame = cv2.resize(frame, (800, 600))
        raw_display_frames.append(display_frame)
        # è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„YUVæ ¼å¼å¹¶ç¼©æ”¾
        yuv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        model_frame = cv2.resize(yuv_frame, (512, 384), cv2.INTER_AREA)
        model_input_imgs.append(model_frame)
    cap.release()

    # æ ¡éªŒå¸§æ•°æ˜¯å¦è¶³å¤Ÿ
    if len(raw_display_frames) < 2:
        empty_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
        cv2.putText(empty_frame, "Insufficient video frames", (100, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
        cv2.imshow(win_name, empty_frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return

    # 3. åŠ è½½æ¨¡å‹ï¼ˆæ˜¾ç¤ºè‹±æ–‡æç¤ºï¼Œæ— ä¹±ç ï¼‰
    load_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
    cv2.putText(load_frame, "Loading model...", (200, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)
    cv2.imshow(win_name, load_frame)
    cv2.waitKey(200)  # åˆ·æ–°æ˜¾ç¤º

    # æ¨¡å‹è·¯å¾„ï¼ˆå†™æ­»ï¼Œæ— éœ€ä¿®æ”¹ï¼‰
    model_path = "/home/dacun/æ¡Œé¢/openpilot-modeld-main/models/supercombo.h5"
    try:
        supercombo_model = load_model(model_path, compile=False)
    except Exception as e:
        empty_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
        cv2.putText(empty_frame, "Model load failed", (180, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        cv2.imshow(win_name, empty_frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return

    # 4. é¢„å¤„ç†å¸§ï¼ˆæ˜¾ç¤ºè‹±æ–‡æç¤ºï¼‰
    preprocess_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
    cv2.putText(preprocess_frame, "Preprocessing frames...", (150, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)
    cv2.imshow(win_name, preprocess_frame)
    cv2.waitKey(200)

    frame_tensors = preprocess_frames(model_input_imgs)
    if frame_tensors.size == 0:
        empty_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
        cv2.putText(empty_frame, "Preprocessing failed", (180, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
        cv2.imshow(win_name, empty_frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return

    # 5. æ¨¡å‹çŠ¶æ€åˆå§‹åŒ–
    model_state = np.zeros((1, 512))
    model_desire = np.zeros((1, 8))

    # 6. é€å¸§æ¨ç†+ç»˜åˆ¶ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šè½¦é“çº¿å³ç§»+æ”¾å¤§åœ†ç‚¹ï¼‰
    print("âœ… Start inference and display (Press Q to exit)")
    for i in range(len(frame_tensors) - 1):
        # ç¡®ä¿å¸§å­˜åœ¨ï¼Œé¿å…ç´¢å¼•è¶Šç•Œ
        if i >= len(raw_display_frames):
            current_frame = np.ones((600, 800, 3), dtype=np.uint8) * 255
        else:
            current_frame = raw_display_frames[i].copy()  # å¤åˆ¶åŸå§‹å¸§ï¼Œé¿å…ä¿®æ”¹

        try:
            # æ¨¡å‹æ¨ç†ï¼ˆè¿ç»­ä¸¤å¸§ä½œä¸ºè¾“å…¥ï¼‰
            input_data = [np.vstack(frame_tensors[i:i+2])[None], model_desire, model_state]
            model_output = supercombo_model.predict(input_data, verbose=0)
            parsed_result = parser(model_output)
            model_state = model_output[-1]

            # -------------------------- è½¦é“çº¿ç»˜åˆ¶ä¼˜åŒ– --------------------------
            # æå–æ¨¡å‹è¾“å‡ºçš„è½¦é“çº¿/è·¯å¾„xåæ ‡
            left_lane_x = parsed_result["lll"][0]
            right_lane_x = parsed_result["rll"][0]
            path_x = parsed_result["path"][0]
            
            # çª—å£å°ºå¯¸
            win_h, win_w = 600, 800
            # yåæ ‡æ˜ å°„ï¼ˆ0-191 â†’ 0-599ï¼‰
            y_points = np.linspace(0, win_h - 1, 192).astype(int)
            # xåæ ‡æ˜ å°„ï¼ˆ0-512 â†’ 0-799ï¼‰+ å³ç§»100åƒç´ ï¼ˆè§£å†³åå·¦é—®é¢˜ï¼‰+ æ”¾å¤§åœ†ç‚¹åˆ°8px
            left_x_mapped = (left_lane_x / 512 * win_w + 100).astype(int)
            right_x_mapped = (right_lane_x / 512 * win_w + 100).astype(int)
            path_x_mapped = (path_x / 512 * win_w + 100).astype(int)

            # ç»˜åˆ¶å·¦è½¦é“çº¿ï¼ˆè“è‰²ï¼Œ8pxå®å¿ƒåœ†ï¼‰
            for x, y in zip(left_x_mapped, y_points):
                if 0 <= x < win_w and 0 <= y < win_h:
                    cv2.circle(current_frame, (x, y), 8, (255, 0, 0), -1)
            # ç»˜åˆ¶å³è½¦é“çº¿ï¼ˆçº¢è‰²ï¼Œ8pxå®å¿ƒåœ†ï¼‰
            for x, y in zip(right_x_mapped, y_points):
                if 0 <= x < win_w and 0 <= y < win_h:
                    cv2.circle(current_frame, (x, y), 8, (0, 0, 255), -1)
            # ç»˜åˆ¶é¢„æµ‹è·¯å¾„ï¼ˆç»¿è‰²ï¼Œ6pxå®å¿ƒåœ†ï¼‰
            for x, y in zip(path_x_mapped, y_points):
                if 0 <= x < win_w and 0 <= y < win_h:
                    cv2.circle(current_frame, (x, y), 6, (0, 255, 0), -1)

        except Exception as e:
            # æ¨ç†å¤±è´¥æ—¶ä»…æ‰“å°é”™è¯¯ï¼Œä»æ˜¾ç¤ºåŸå§‹å¸§
            print(f"âš ï¸ Frame {i+1} inference error: {str(e)[:30]}")

        # å¼ºåˆ¶æ˜¾ç¤ºå½“å‰å¸§
        cv2.imshow(win_name, current_frame)
        # æŒ‰Qé€€å‡º
        if cv2.waitKey(100) & 0xFF == ord('q'):
            print("ğŸ›‘ Exit by user (Q pressed)")
            break

    # 7. ç¨‹åºæ”¶å°¾
    cv2.destroyAllWindows()
    print("ğŸ‰ All frames processed successfully!")

if __name__ == "__main__":
    main()
