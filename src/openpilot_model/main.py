#!/usr/bin/env python3
# ç¬¬ä¸€æ­¥ï¼šä¼˜å…ˆé…ç½®Pythonæœç´¢è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°commonæ¨¡å—
import sys
import os
import time  # æ–°å¢ï¼šç”¨äºè®¡æ—¶/è¶…æ—¶æç¤º

# é¡¹ç›®æ ¹ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼Œé€‚é…ä½ çš„è™šæ‹Ÿæœºè·¯å¾„ï¼‰
PROJECT_ROOT = "/home/dacun/nn"
# å°†æ ¹ç›®å½•åŠ å…¥Pythonæœç´¢è·¯å¾„
sys.path.append(PROJECT_ROOT)
# éªŒè¯è·¯å¾„æ˜¯å¦æ·»åŠ æˆåŠŸï¼ˆå¯é€‰ï¼Œå¯åˆ é™¤ï¼‰
print(f"âœ… é¡¹ç›®æ ¹ç›®å½•å·²æ·»åŠ åˆ°Pythonæœç´¢è·¯å¾„ï¼š{PROJECT_ROOT}")

# ç¬¬äºŒæ­¥ï¼šå¯¼å…¥ä¾èµ–åº“ï¼ˆåŒ…æ‹¬commonæ¨¡å—ï¼‰
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm  # ç”¨äºè¿›åº¦æç¤º
from tensorflow.keras.models import load_model

# ä¼˜åŒ–ç‚¹1ï¼šè®¾ç½®matplotlibéäº¤äº’å¼åç«¯ï¼ˆé€‚é…è™šæ‹Ÿæœºæ— GUIåœºæ™¯ï¼Œé¿å…pltå´©æºƒï¼‰
plt.switch_backend('Agg') if os.environ.get('DISPLAY') is None else plt.switch_backend('TkAgg')

# ç°åœ¨èƒ½æ­£å¸¸å¯¼å…¥commonæ¨¡å—
from common.transformations.camera import transform_img, eon_intrinsics
from common.transformations.model import medmodel_intrinsics
from common.tools.lib.parser import parser

def frames_to_tensor(frames):
    if len(frames) == 0:
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    # ä¼˜åŒ–ç‚¹2ï¼šnumpyå‘é‡åŒ–é‡æ„ï¼Œæ›¿æ¢éƒ¨åˆ†å¾ªç¯ï¼Œæå‡å¼ é‡è®¡ç®—æ•ˆç‡ï¼ˆå‡å°‘è™šæ‹ŸæœºCPUå ç”¨ï¼‰
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    # å‘é‡åŒ–reshapeï¼Œé¿å…é€å…ƒç´ æ“ä½œ
    tensor[:, 4] = frames[:, H:H+H//4].reshape(-1, H//2, W//2)
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape(-1, H//2, W//2)
    return tensor / 128.0 - 1.0

def preprocess_frames(imgs):
    if not imgs:
        return np.array([])
    processed = np.zeros((len(imgs), 384, 512), dtype=np.uint8)
    # ä¼˜åŒ–ç‚¹3ï¼šæ‰¹é‡å¤„ç†+å¼‚å¸¸æ•è·ç»†åŒ–ï¼Œé¿å…å•å¸§é”™è¯¯å¯¼è‡´æ•´æ‰¹å¤±æ•ˆ
    valid_imgs = np.array(imgs, dtype=object)
    mask = np.ones(len(valid_imgs), dtype=bool)
    for i, img in enumerate(valid_imgs):
        try:
            processed[i] = transform_img(img, from_intr=eon_intrinsics, to_intr=medmodel_intrinsics, yuv=True, output_size=(512, 256))
        except Exception as e:
            mask[i] = False
            processed[i] = np.zeros((384, 512), dtype=np.uint8)
    if np.sum(~mask) > 0:
        print(f"âš ï¸  æœ‰ {np.sum(~mask)} å¸§é¢„å¤„ç†å¤±è´¥ï¼Œå·²å¡«å……ç©ºå¸§")
    return frames_to_tensor(processed)

def read_video_with_opencv(video_path, max_frames=10):
    # ä¼˜åŒ–ç‚¹4ï¼šæ ¡éªŒè§†é¢‘æ ¼å¼ï¼ˆä»…æ”¯æŒMP4ï¼‰ï¼Œæå‰æ‹¦æˆªé”™è¯¯
    if not video_path.lower().endswith('.mp4'):
        raise ValueError(f"âŒ ä»…æ”¯æŒMP4æ ¼å¼è§†é¢‘ï¼Œå½“å‰æ–‡ä»¶ï¼š{video_path}")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}ï¼Œè¯·å®‰è£…FFmpegï¼ˆsudo apt install ffmpegï¼‰")
    # è®¾ç½®ç¼“å­˜å¤§å°ï¼Œé™ä½è™šæ‹Ÿæœºå†…å­˜å ç”¨
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
    imgs = []
    raw_frames = []
    for i in tqdm(range(max_frames), desc="è¯»å–è§†é¢‘å¸§"):
        ret, frame = cap.read()
        if not ret:
            tqdm.write(f"âš ï¸  è§†é¢‘ä»…è¯»å–åˆ° {i} å¸§ï¼Œå·²è¾¾æœ«å°¾")
            break
        raw_frames.append(frame)
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        yuv_resized = cv2.resize(yuv, (512, 384), interpolation=cv2.INTER_AREA)
        imgs.append(yuv_resized)
    cap.release()
    return imgs, raw_frames

def main():
    # ä¼˜åŒ–ç‚¹5ï¼šæ”¯æŒé»˜è®¤è§†é¢‘è·¯å¾„ï¼Œä¸ä¼ å‚æ•°æ—¶ä¼˜å…ˆç”¨é»˜è®¤ï¼ˆæ›´å‹å¥½ï¼‰
    default_video_path = os.path.join(PROJECT_ROOT, "sample.mp4")
    if len(sys.argv) == 1:
        if os.path.exists(default_video_path):
            video_path = default_video_path
            print(f"â„¹ï¸  æœªä¼ å…¥è§†é¢‘è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼š{video_path}")
        else:
            print("âŒ ç¼ºå°‘è§†é¢‘æ–‡ä»¶è·¯å¾„å‚æ•°ï¼")
            print("âœ… æ­£ç¡®ç”¨æ³•: python main.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
            print("ğŸ’¡ ç¤ºä¾‹: python main.py /home/dacun/nn/sample.mp4")
            sys.exit(1)
    else:
        video_path = sys.argv[1]
    
    if not os.path.exists(video_path):
        print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ - {video_path}")
        sys.exit(1)

    model_path = "models/supercombo.h5"
    model_abs_path = os.path.join(PROJECT_ROOT, model_path)
    if not os.path.exists(model_abs_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_abs_path}")
        sys.exit(1)

    # åŠ è½½æ¨¡å‹ï¼ˆæ·»åŠ è®¡æ—¶+è¶…æ—¶æç¤ºï¼‰
    try:
        print(f"ğŸ“Œ åŠ è½½æ¨¡å‹ï¼š{model_abs_path}")
        start_time = time.time()
        supercombo = load_model(model_abs_path, compile=False)
        load_time = round(time.time() - start_time, 2)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶ {load_time} ç§’")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # è¯»å–è§†é¢‘
    try:
        print(f"ğŸ“Œ è¯»å–è§†é¢‘ï¼š{video_path}ï¼ˆä»…10å¸§ï¼Œè½»é‡åŒ–æ¨¡å¼ï¼‰")
        imgs, raw_frames = read_video_with_opencv(video_path)
        if not imgs:
            print("âŒ é”™è¯¯ï¼šæœªè¯»å–åˆ°å¸§")
            sys.exit(1)
    except Exception as e:
        print(f"âŒ è§†é¢‘è¯»å–å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # é¢„å¤„ç†å¸§
    print("ğŸ“Œ é¢„å¤„ç†å¸§æ•°æ®...")
    frame_tensors = preprocess_frames(imgs)
    if frame_tensors.size == 0:
        print("âŒ é”™è¯¯ï¼šé¢„å¤„ç†æ— æœ‰æ•ˆæ•°æ®")
        sys.exit(1)

    # åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€
    state = np.zeros((1, 512))
    desire = np.zeros((1, 8))

    # è½»é‡åŒ–å¯è§†åŒ–
    plt.ion()
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.set_title("è½¦é“çº¿é¢„æµ‹ï¼ˆè“=å·¦è½¦é“ï¼Œçº¢=å³è½¦é“ï¼Œç»¿=è·¯å¾„ï¼‰")
    ax.set_ylim(0, 191)
    ax.invert_xaxis()
    ax.grid(alpha=0.3)
    lll_line, = ax.plot([], [], "b-", linewidth=3, label="å·¦è½¦é“çº¿")
    rll_line, = ax.plot([], [], "r-", linewidth=3, label="å³è½¦é“çº¿")
    path_line, = ax.plot([], [], "g-", linewidth=2, label="é¢„æµ‹è·¯å¾„")
    ax.legend()

    # é€å¸§æ¨ç†+å¯è§†åŒ–
    total_frames = len(frame_tensors) - 1
    print(f"\nğŸš€ å¼€å§‹æ¨ç†+å¯è§†åŒ–ï¼ˆå…±{total_frames}å¸§ï¼ŒæŒ‰Qé”®/5ç§’æ— æ“ä½œè‡ªåŠ¨é€€å‡ºï¼‰...")
    try:
        for i in range(total_frames):
            try:
                inputs = [np.vstack(frame_tensors[i:i+2])[None], desire, state]
                outs = supercombo.predict(inputs, verbose=0)
                parsed = parser(outs)
                state = outs[-1]

                # æ›´æ–°çº¿æ¡æ•°æ®
                lll_line.set_data(parsed["lll"][0], range(192))
                rll_line.set_data(parsed["rll"][0], range(192))
                path_line.set_data(parsed["path"][0], range(192))
                fig.canvas.draw()
                fig.canvas.flush_events()

                # ä¼˜åŒ–ç‚¹6ï¼šCV2çª—å£5ç§’æ— æ“ä½œè‡ªåŠ¨å…³é—­ï¼Œé¿å…è™šæ‹Ÿæœºå¡æ­»
                if i < len(raw_frames):
                    cv2.imshow("åŸå§‹å¸§", cv2.resize(raw_frames[i], (480, 270)))
                    key = cv2.waitKey(100) & 0xFF
                    if key == ord('q'):
                        print("ğŸ›‘ ç”¨æˆ·æŒ‰Qé”®é€€å‡º")
                        break
                    # 5ç§’æ— æ“ä½œè‡ªåŠ¨é€€å‡ºï¼ˆ100ms*50=5ç§’ï¼‰
                    if i % 50 == 0 and i != 0:
                        print("âš ï¸  5ç§’æ— æ“ä½œï¼Œè‡ªåŠ¨é€€å‡º...")
                        break

                print(f"âœ… å¸§ {i+1}/{total_frames} å®Œæˆ")

            except Exception as e:
                print(f"âš ï¸  å¸§ {i+1} å¤±è´¥ï¼š{str(e)}")
                continue
    finally:
        # å½»åº•é‡Šæ”¾èµ„æºï¼ˆé€‚é…è™šæ‹Ÿæœºï¼‰
        print("\nğŸ§¹ é‡Šæ”¾èµ„æºä¸­...")
        plt.ioff()
        plt.close(fig)
        cv2.destroyAllWindows()
        
        for _ in range(2):
            cv2.waitKey(1)
        print("ğŸ‰ å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
