#!/usr/bin/env python3

import sys
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from tensorflow.keras.models import load_model

# å¯¼å…¥ç›¸æœº/æ¨¡å‹å˜æ¢ã€è§£æç›¸å…³å·¥å…·ï¼ˆopenpilotæ ¸å¿ƒä¾èµ–ï¼‰
from common.transformations.camera import transform_img, eon_intrinsics
from common.transformations.model import medmodel_intrinsics
from common.tools.lib.parser import parser

def frames_to_tensor(frames):
    """
    å°†YUVå¸§è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥çš„6é€šé“å¼ é‡
    :param frames: np.ndarray - è¾“å…¥çš„YUVå¸§æ•°æ®ï¼ˆshape: [å¸§æ•°é‡, é«˜åº¦, å®½åº¦]ï¼‰
    :return: np.ndarray - å½’ä¸€åŒ–åçš„6é€šé“å¼ é‡ï¼ˆshape: [å¸§æ•°é‡, 6, é«˜åº¦//2, å®½åº¦//2]ï¼‰
    """
    if len(frames) == 0:
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    # æ‹†åˆ†YUVé€šé“ç”Ÿæˆ6ç»´è¾“å…¥ï¼ˆé€‚é…supercomboæ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    tensor[:, 4] = frames[:, H:H+H//4].reshape((-1, H//2, W//2))
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape((-1, H//2, W//2))
    # å½’ä¸€åŒ–è‡³[-1, 1]ï¼ˆæ¨¡å‹è¾“å…¥è§„èŒƒï¼‰
    return tensor / 128.0 - 1.0

def preprocess_frames(imgs):
    """
    å¸§é¢„å¤„ç†ï¼šè½¬æ¢ç›¸æœºå†…å‚+æ ¼å¼ï¼Œç”Ÿæˆæ¨¡å‹è¾“å…¥å¼ é‡
    :param imgs: list/np.ndarray - åŸå§‹YUVå¸§åˆ—è¡¨
    :return: np.ndarray - é¢„å¤„ç†åçš„6é€šé“å¼ é‡ï¼ˆç©ºåˆ—è¡¨è¿”å›ç©ºæ•°ç»„ï¼‰
    """
    if not imgs:
        return np.array([])
    processed = np.zeros((len(imgs), 384, 512), dtype=np.uint8)
    for i, img in enumerate(imgs):
        try:
            # è½¬æ¢ç›¸æœºå†…å‚ï¼ˆeonâ†’medmodelï¼‰+ è½¬ä¸ºYUVæ ¼å¼ + è°ƒæ•´å°ºå¯¸
            processed[i] = transform_img(img, from_intr=eon_intrinsics, to_intr=medmodel_intrinsics, yuv=True, output_size=(512, 256))
        except:
            # å¼‚å¸¸æ—¶å¡«å……ç©ºå¸§ï¼Œé¿å…ç¨‹åºä¸­æ–­
            processed[i] = np.zeros((384, 512), dtype=np.uint8)
    return frames_to_tensor(processed)

def read_video_with_opencv(video_path, max_frames=10):  # å…³é”®ï¼šå¸§æ•°ä»20å‡åˆ°10ï¼Œè¿›ä¸€æ­¥é™ä½å‹åŠ›
    """
    è½»é‡åŒ–è¯»å–è§†é¢‘å¸§ï¼ˆä»…è¯»å–æŒ‡å®šå¸§æ•°ï¼Œé€‚é…è™šæ‹Ÿæœºä½èµ„æºï¼‰
    :param video_path: str - è§†é¢‘æ–‡ä»¶è·¯å¾„
    :param max_frames: int - æœ€å¤§è¯»å–å¸§æ•°ï¼ˆé»˜è®¤10å¸§ï¼‰
    :return: tuple - (é¢„å¤„ç†YUVå¸§åˆ—è¡¨, åŸå§‹BGRå¸§åˆ—è¡¨)
    :raises Exception: è§†é¢‘æ— æ³•æ‰“å¼€æ—¶æŠ›å‡ºå¼‚å¸¸ï¼ˆæç¤ºå®‰è£…FFmpegï¼‰
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}ï¼Œè¯·å®‰è£…FFmpegï¼ˆsudo apt install ffmpegï¼‰")
    imgs = []  # å­˜å‚¨é¢„å¤„ç†åçš„YUVå¸§
    raw_frames = []  # å­˜å‚¨åŸå§‹BGRå¸§ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
    for i in range(max_frames):
        ret, frame = cap.read()
        if not ret:
            break
        raw_frames.append(frame)
        # è½¬æ¢ä¸ºYUV_I420æ ¼å¼ï¼ˆæ¨¡å‹è¾“å…¥è¦æ±‚ï¼‰+ è°ƒæ•´å°ºå¯¸
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        yuv_resized = cv2.resize(yuv, (512, 384), interpolation=cv2.INTER_AREA)
        imgs.append(yuv_resized)
    cap.release()  # é‡Šæ”¾è§†é¢‘æ•è·èµ„æº
    return imgs, raw_frames

def main():
    """
    ç¨‹åºä¸»å…¥å£ï¼šä¸²è”è§†é¢‘è¯»å–â†’é¢„å¤„ç†â†’æ¨¡å‹æ¨ç†â†’è½»é‡åŒ–å¯è§†åŒ–å…¨æµç¨‹
    ç”¨æ³•ï¼špython main.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>
    """
    # å‚æ•°æ ¡éªŒï¼šæ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°æ•°é‡
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python main.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    video_path = sys.argv[1]
    # æ ¡éªŒè§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ - {video_path}")
        sys.exit(1)

    # æ¨¡å‹è·¯å¾„é…ç½®+å­˜åœ¨æ€§æ ¡éªŒ
    model_path = "models/supercombo.h5"
    if not os.path.exists(model_path):
        print(f"é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_path}")
        sys.exit(1)

    # åŠ è½½æ¨¡å‹ï¼ˆç¦ç”¨ç¼–è¯‘ï¼Œé€‚é…é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ï¼‰
    try:
        print(f"åŠ è½½æ¨¡å‹ï¼š{model_path}")
        supercombo = load_model(model_path, compile=False)
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # è¯»å–è§†é¢‘ï¼ˆä»…10å¸§ï¼‰
    try:
        print(f"è¯»å–è§†é¢‘ï¼š{video_path}ï¼ˆä»…10å¸§ï¼Œè½»é‡åŒ–æ¨¡å¼ï¼‰")
        imgs, raw_frames = read_video_with_opencv(video_path)
        if not imgs:
            print("é”™è¯¯ï¼šæœªè¯»å–åˆ°å¸§")
            sys.exit(1)
    except Exception as e:
        print(f"è§†é¢‘è¯»å–å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # é¢„å¤„ç†å¸§æ•°æ®ï¼ˆè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡ï¼‰
    print("é¢„å¤„ç†å¸§æ•°æ®...")
    frame_tensors = preprocess_frames(imgs)
    if frame_tensors.size == 0:
        print("é”™è¯¯ï¼šé¢„å¤„ç†æ— æœ‰æ•ˆæ•°æ®")
        sys.exit(1)

    # åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€+é©¾é©¶æ„å›¾å‚æ•°ï¼ˆsupercomboæ¨¡å‹å¿…éœ€ï¼‰
    state = np.zeros((1, 512))
    desire = np.zeros((1, 8))

    # -------------------------- è½»é‡åŒ–å¯è§†åŒ–ï¼ˆä»…1ä¸ªçª—å£ï¼Œåªç”»è½¦é“çº¿ï¼‰ --------------------------
    plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼ï¼ˆé¿å…çª—å£é˜»å¡ï¼‰
    fig, ax = plt.subplots(figsize=(8, 6))  # å•ä¸ªçª—å£ï¼Œé¿å…å­å›¾æ¸²æŸ“å‹åŠ›
    ax.set_title("è½¦é“çº¿é¢„æµ‹ï¼ˆè“=å·¦è½¦é“ï¼Œçº¢=å³è½¦é“ï¼Œç»¿=è·¯å¾„ï¼‰")
    ax.set_ylim(0, 191)  # å›ºå®šYè½´ï¼Œå‡å°‘é‡ç»˜è®¡ç®—
    ax.invert_xaxis()     # åŒ¹é…é©¾é©¶è§†è§’ï¼ˆXè½´ä»å³åˆ°å·¦ï¼‰
    ax.grid(alpha=0.3)    # ç®€å•ç½‘æ ¼ï¼Œä¸å èµ„æº

    # åˆå§‹åŒ–ä¸‰æ¡çº¿ï¼ˆæå‰åˆ›å»ºï¼Œé¿å…æ¯æ¬¡é‡ç»˜æ–°å»ºå¯¹è±¡ï¼Œé™ä½èµ„æºå ç”¨ï¼‰
    lll_line, = ax.plot([], [], "b-", linewidth=3, label="å·¦è½¦é“çº¿")
    rll_line, = ax.plot([], [], "r-", linewidth=3, label="å³è½¦é“çº¿")
    path_line, = ax.plot([], [], "g-", linewidth=2, label="é¢„æµ‹è·¯å¾„")
    ax.legend()
    # -------------------------------------------------------------------

    # é€å¸§æ¨ç†+è½»é‡åŒ–å¯è§†åŒ–
    print(f"\nå¼€å§‹æ¨ç†+å¯è§†åŒ–ï¼ˆå…±{len(frame_tensors)-1}å¸§ï¼ŒæŒ‰Qé”®é€€å‡ºï¼‰...")
    for i in range(len(frame_tensors) - 1):
        try:
            # æ¨¡å‹æ¨ç†ï¼šæ‹¼æ¥2å¸§æ•°æ®+æ„å›¾+çŠ¶æ€ä½œä¸ºè¾“å…¥
            inputs = [np.vstack(frame_tensors[i:i+2])[None], desire, state]
            outs = supercombo.predict(inputs, verbose=0)  # é™é»˜æ¨ç†ï¼Œä¸è¾“å‡ºæ—¥å¿—
            parsed = parser(outs)  # è§£ææ¨¡å‹è¾“å‡ºï¼ˆæå–è½¦é“çº¿/è·¯å¾„åæ ‡ï¼‰
            state = outs[-1]  # æ›´æ–°æ¨¡å‹çŠ¶æ€ï¼ˆç”¨äºä¸‹ä¸€å¸§æ¨ç†ï¼‰

            # -------------------------- ä»…æ›´æ–°çº¿çš„æ•°æ®ï¼Œä¸é‡ç»˜æ•´ä¸ªçª—å£ --------------------------
            lll_line.set_data(parsed["lll"][0], range(192))  # åªæ›´æ–°å·¦è½¦é“çº¿æ•°æ®
            rll_line.set_data(parsed["rll"][0], range(192))  # åªæ›´æ–°å³è½¦é“çº¿æ•°æ®
            path_line.set_data(parsed["path"][0], range(192))# åªæ›´æ–°è·¯å¾„æ•°æ®
            fig.canvas.draw()  # è½»é‡é‡ç»˜ï¼ˆåªæ›´æ”¹é€ å˜çš„éƒ¨åˆ†ï¼‰
            fig.canvas.flush_events()  # å¼ºåˆ¶åˆ·æ–°çª—å£ï¼Œé¿å…å¡ä½
            # -------------------------------------------------------------------

            # æ˜¾ç¤ºåŸå§‹å¸§ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨Matplotlibæ˜¾ç¤ºï¼Œé¿å…OpenCVé¢å¤–çª—å£ï¼‰
            if i < len(raw_frames):
                # æ–°å»ºä¸€ä¸ªå°çª—å£æ˜¾ç¤ºåŸå§‹å¸§ï¼Œç¼©å°å°ºå¯¸å‡å°‘æ¸²æŸ“å‹åŠ›
                cv2.imshow("åŸå§‹å¸§", cv2.resize(raw_frames[i], (480, 270)))
                # å»¶é•¿ç­‰å¾…æ—¶é—´ï¼ˆ100msï¼‰ï¼Œç»™CPUå–˜æ¯ï¼Œé¿å…è™šæ‹Ÿæœºå¡é¡¿
                if cv2.waitKey(100) & 0xFF == ord('q'):
                    print("ç”¨æˆ·æŒ‰Qé”®é€€å‡º")
                    break

            print(f"âœ… å¸§ {i+1}/{len(frame_tensors)-1} å®Œæˆ")

        except Exception as e:
            # å•å¸§å¤±è´¥ä¸ä¸­æ–­æ•´ä½“ç¨‹åºï¼Œä»…æ‰“å°é”™è¯¯æç¤º
            print(f"âš ï¸  å¸§ {i+1} å¤±è´¥ï¼š{str(e)}")
            continue

    # é‡Šæ”¾èµ„æºï¼ˆç®€åŒ–ç‰ˆï¼‰
    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼
    plt.close()  # å…³é—­Matplotlibçª—å£
    cv2.destroyAllWindows()  # å…³é—­OpenCVçª—å£

if __name__ == "__main__":
    main()
