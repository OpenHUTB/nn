#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è½¦é“çº¿é¢„æµ‹ç¨‹åºï¼ˆæœ€ç»ˆç‰ˆÂ·æ ‡æ³¨ä¸­æ–‡æ­£å¸¸æ˜¾ç¤ºï¼‰
æ ¸å¿ƒï¼šç”¨Matplotlibç»˜åˆ¶ä¸­æ–‡æ ‡æ³¨ï¼ˆæ›¿ä»£OpenCVçš„putTextï¼‰
"""
import sys
import os
import logging
import argparse
import time
import numpy as np
import cv2
import matplotlib
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

# ===================== ç¯å¢ƒåˆå§‹åŒ–ï¼ˆæ ¸å¿ƒè§£å†³ä¸­æ–‡æ˜¾ç¤ºï¼‰ =====================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)

# è®¾ç½®Matplotlibåç«¯
matplotlib.use('Agg') if os.environ.get('DISPLAY') is None else matplotlib.use('TkAgg')

# åŠ è½½ä¸­æ–‡å­—ä½“ï¼ˆä»…ç»™Matplotlibç”¨ï¼‰
def setup_chinese_font():
    font_path = '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc'
    if os.path.exists(font_path):
        font_prop = matplotlib.font_manager.FontProperties(fname=font_path)
        plt.rcParams['font.sans-serif'] = [font_prop.get_name()]
        logger.info(f"âœ… ä¸­æ–‡å­—ä½“åŠ è½½æˆåŠŸï¼š{font_path}")
    else:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°wqy-microheiå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤è‹±æ–‡å­—ä½“")
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.dpi'] = 96
    plt.rcParams['savefig.dpi'] = 100

setup_chinese_font()

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = "/home/dacun/nn"
sys.path.append(PROJECT_ROOT)

# ä¾èµ–æ£€æµ‹
def check_dependencies():
    required_libs = {
        'numpy': np.__version__,
        'cv2': cv2.__version__,
        'matplotlib': matplotlib.__version__,
        'tensorflow': '2.x'
    }
    for lib, ver in required_libs.items():
        try:
            if lib == 'tensorflow':
                import tensorflow as tf
                assert tf.__version__.startswith('2.'), f"TensorFlowç‰ˆæœ¬éœ€â‰¥2.0ï¼Œå½“å‰ï¼š{tf.__version__}"
            logger.info(f"âœ… ä¾èµ–æ£€æµ‹é€šè¿‡ï¼š{lib} (ç‰ˆæœ¬ï¼š{ver})")
        except (ImportError, AssertionError) as e:
            logger.error(f"âŒ ä¾èµ–ç¼ºå¤±/ç‰ˆæœ¬é”™è¯¯ï¼š{lib} - {e}")
            logger.error(f"ğŸ’¡ ä¿®å¤å‘½ä»¤ï¼špip install {lib}>={ver.split('.')[0]}")
            sys.exit(1)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from common.transformations.camera import transform_img, eon_intrinsics
    from common.transformations.model import medmodel_intrinsics
    from common.tools.lib.parser import parser
    logger.info("âœ… é¡¹ç›®æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"âŒ é¡¹ç›®æ¨¡å—å¯¼å…¥å¤±è´¥ï¼š{e}")
    logger.error("ğŸ’¡ ç¡®è®¤commonæ–‡ä»¶å¤¹è·¯å¾„ï¼š/home/dacun/nn/common/")
    sys.exit(1)

# ===================== æ ¸å¿ƒå‡½æ•° =====================
def frames_to_tensor(frames: np.ndarray) -> np.ndarray:
    if frames.size == 0:
        logger.warning("è¾“å…¥å¸§ä¸ºç©ºï¼Œè¿”å›ç©ºå¼ é‡")
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    tensor[:, 4] = frames[:, H:H+H//4].reshape(-1, H//2, W//2)
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape(-1, H//2, W//2)
    return tensor / 128.0 - 1.0

def preprocess_frame(img: np.ndarray) -> np.ndarray:
    try:
        return transform_img(
            img,
            from_intr=eon_intrinsics,
            to_intr=medmodel_intrinsics,
            yuv=True,
            output_size=(512, 256)
        )
    except Exception as e:
        logger.warning(f"å•å¸§é¢„å¤„ç†å¤±è´¥ï¼š{e}ï¼Œè¿”å›ç©ºå¸§")
        return np.zeros((384, 512), dtype=np.uint8)

def preprocess_frames(imgs: list) -> np.ndarray:
    if not imgs:
        return np.array([])
    processed_frames = [preprocess_frame(img) for img in imgs]
    processed_frames = np.array(processed_frames)
    empty_frames = np.sum(np.all(processed_frames == 0, axis=(1, 2)))
    if empty_frames > 0:
        logger.warning(f"å…±{empty_frames}å¸§é¢„å¤„ç†å¤±è´¥ï¼Œå·²å¡«å……ç©ºå¸§")
    return frames_to_tensor(processed_frames)

def read_video(video_path: str, max_frames: int = 10) -> tuple:
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{video_path}")
    if not video_path.lower().endswith('.mp4'):
        raise ValueError("ä»…æ”¯æŒMP4æ ¼å¼è§†é¢‘")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼ˆè¯·å®‰è£…FFmpegï¼‰ï¼š{video_path}")
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 10
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    save_path = os.path.join(PROJECT_ROOT, "lane_pred_result.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(save_path, fourcc, fps, (width, height))
    logger.info(f"âœ… ç»“æœè§†é¢‘ä¿å­˜è·¯å¾„ï¼š{save_path}")
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    yuv_frames = []
    raw_frames = []
    for i in range(max_frames):
        ret, frame = cap.read()
        if not ret:
            logger.info(f"è§†é¢‘è¯»å–å®Œæ¯•ï¼Œå…±è¯»å–{i}å¸§ï¼ˆç›®æ ‡ï¼š{max_frames}å¸§ï¼‰")
            break
        raw_frames.append(frame)
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        yuv_resized = cv2.resize(yuv, (512, 384), interpolation=cv2.INTER_LINEAR)
        yuv_frames.append(yuv_resized)
    cap.release()
    return yuv_frames, raw_frames, video_writer

def draw_lane_lines(frame: np.ndarray, pred: dict) -> np.ndarray:
    """ä»…ç»˜åˆ¶è½¦é“çº¿ï¼ˆæ–‡å­—æ ‡æ³¨äº¤ç»™Matplotlibï¼‰"""
    h, w = frame.shape[:2]
    pred_lll = np.interp(pred["lll"][0], (0, 191), (0, h))
    pred_rll = np.interp(pred["rll"][0], (0, 191), (0, h))
    pred_path = np.interp(pred["path"][0], (0, 191), (0, h))
    x_coords = np.linspace(0, w, len(pred_lll))
    frame_copy = frame.copy()
    # å·¦è½¦é“çº¿ï¼ˆè“ï¼‰
    for i in range(len(x_coords)-1):
        cv2.line(
            frame_copy,
            (int(x_coords[i]), int(pred_lll[i])),
            (int(x_coords[i+1]), int(pred_lll[i+1])),
            (255, 0, 0), 3, cv2.LINE_AA
        )
    # å³è½¦é“çº¿ï¼ˆçº¢ï¼‰
    for i in range(len(x_coords)-1):
        cv2.line(
            frame_copy,
            (int(x_coords[i]), int(pred_rll[i])),
            (int(x_coords[i+1]), int(pred_rll[i+1])),
            (0, 0, 255), 3, cv2.LINE_AA
        )
    # é¢„æµ‹è·¯å¾„ï¼ˆç»¿ï¼‰
    for i in range(len(x_coords)-1):
        cv2.line(
            frame_copy,
            (int(x_coords[i]), int(pred_path[i])),
            (int(x_coords[i+1]), int(pred_path[i+1])),
            (0, 255, 0), 2, cv2.LINE_AA
        )
    return cv2.addWeighted(frame_copy, 0.7, frame, 0.3, 0)

# ===================== ä¸»å‡½æ•° =====================
def main():
    parser_arg = argparse.ArgumentParser(description="è½¦é“çº¿é¢„æµ‹ç¨‹åºï¼ˆæ ‡æ³¨ä¸­æ–‡æ­£å¸¸ï¼‰")
    parser_arg.add_argument("video_path", type=str, help="è§†é¢‘æ–‡ä»¶ç»å¯¹è·¯å¾„")
    parser_arg.add_argument("--max-frames", type=int, default=10, help="æœ€å¤§è¯»å–å¸§æ•°")
    parser_arg.add_argument("--save-result", action="store_true", default=True, help="ä¿å­˜ç»“æœè§†é¢‘")
    args = parser_arg.parse_args()
    
    check_dependencies()
    
    # åŠ è½½æ¨¡å‹
    model_path = os.path.join(PROJECT_ROOT, "models/supercombo.h5")
    if not os.path.exists(model_path):
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")
        sys.exit(1)
    try:
        logger.info(f"å¼€å§‹åŠ è½½æ¨¡å‹ï¼š{model_path}")
        start_time = time.time()
        model = load_model(model_path, compile=False)
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶{round(time.time()-start_time,2)}ç§’")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
        sys.exit(1)
    
    # è¯»å–è§†é¢‘
    try:
        yuv_frames, raw_frames, video_writer = read_video(args.video_path, args.max_frames)
        if not raw_frames:
            logger.error("æœªè¯»å–åˆ°æœ‰æ•ˆè§†é¢‘å¸§")
            sys.exit(1)
        logger.info(f"âœ… è§†é¢‘è¯»å–å®Œæˆï¼Œå…±{len(raw_frames)}å¸§")
    except Exception as e:
        logger.error(f"âŒ è§†é¢‘è¯»å–å¤±è´¥ï¼š{e}")
        sys.exit(1)
    
    # é¢„å¤„ç†
    frame_tensor = preprocess_frames(yuv_frames)
    if frame_tensor.size == 0:
        logger.error("å¸§é¢„å¤„ç†åæ— æœ‰æ•ˆæ•°æ®")
        sys.exit(1)
    
    # æ¨ç†åˆå§‹åŒ–
    state = np.zeros((1, 512))
    desire = np.zeros((1, 8))
    total_frames = len(frame_tensor) - 1
    logger.info(f"å¼€å§‹æ¨ç†ï¼Œå…±{total_frames}å¸§ï¼ˆæŒ‰Qé”®é€€å‡ºï¼‰")
    
    # å¯è§†åŒ–ï¼ˆç”¨Matplotlibæ·»åŠ ä¸­æ–‡æ ‡æ³¨ï¼‰
    plt.ion()
    fig, ax = plt.subplots(figsize=(10, 6))
    fig.suptitle("è½¦é“çº¿é¢„æµ‹ç»“æœï¼ˆå åŠ å¯è§†åŒ–ï¼‰", fontsize=14, fontweight='bold')
    # æ·»åŠ ä¸­æ–‡å›¾ä¾‹æ ‡æ³¨ï¼ˆMatplotlibæ”¯æŒä¸­æ–‡ï¼‰
    ax.text(
        0.02, 0.95, 
        "å·¦è½¦é“çº¿(è“) | å³è½¦é“çº¿(çº¢) | é¢„æµ‹è·¯å¾„(ç»¿)",
        transform=ax.transAxes,
        fontsize=10,
        color='white',
        bbox=dict(facecolor='black', alpha=0.5)
    )
    ax.set_axis_off()
    img_display = ax.imshow(cv2.cvtColor(raw_frames[0], cv2.COLOR_BGR2RGB))
    
    for i in range(total_frames):
        try:
            # æ¨ç†
            input_tensor = np.vstack(frame_tensor[i:i+2])[None]
            outputs = model.predict([input_tensor, desire, state], verbose=0)
            pred_result = parser(outputs)
            state = outputs[-1]
            
            # ç»˜åˆ¶è½¦é“çº¿
            result_frame = draw_lane_lines(raw_frames[i], pred_result)
            
            # æ›´æ–°æ˜¾ç¤º
            img_display.set_data(cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB))
            fig.canvas.draw()
            fig.canvas.flush_events()
            
            # ä¿å­˜ç»“æœ
            if args.save_result:
                video_writer.write(result_frame)
            
            # é€€å‡º
            if cv2.waitKey(30) & 0xFF == ord('q'):
                logger.info("ç”¨æˆ·æŒ‰Qé”®é€€å‡º")
                break
            
            logger.info(f"âœ… å®Œæˆç¬¬{i+1}/{total_frames}å¸§æ¨ç†")
        
        except Exception as e:
            logger.warning(f"âš ï¸  ç¬¬{i+1}å¸§æ¨ç†å¤±è´¥ï¼š{e}ï¼Œè·³è¿‡")
            continue
    
    # èµ„æºé‡Šæ”¾
    plt.ioff()
    plt.close(fig)
    video_writer.release()
    cv2.destroyAllWindows()
    cv2.waitKey(1)
    
    # æˆæœæç¤º
    logger.info("\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
    logger.info(f"ğŸ“ ç»“æœè§†é¢‘ï¼š{os.path.join(PROJECT_ROOT, 'lane_pred_result.mp4')}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"\nâŒ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢ï¼š{e}")
        sys.exit(1)
