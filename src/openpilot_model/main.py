#!/usr/bin/env python3
# -*- coding: utf-8 -*-  # å£°æ˜ç¼–ç ï¼Œè§£å†³ä¸­æ–‡æ³¨é‡Š/è¾“å‡ºä¹±ç 
"""
è½¦é“çº¿é¢„æµ‹ç¨‹åºï¼ˆä¼˜åŒ–ç‰ˆï¼‰
æ ¸å¿ƒåŠŸèƒ½ï¼šè¯»å–MP4è§†é¢‘å¸§ â†’ é¢„å¤„ç† â†’ æ¨¡å‹æ¨ç† â†’ è½¦é“çº¿/è·¯å¾„å¯è§†åŒ–
é€‚é…ç¯å¢ƒï¼šLinuxè™šæ‹Ÿæœºï¼ˆPython3 + TensorFlow + OpenCV + Matplotlibï¼‰
"""
import sys
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from tensorflow.keras.models import load_model

# ===================== åŸºç¡€é…ç½®ï¼ˆæ ¸å¿ƒï¼è§£å†³ä¸­æ–‡ä¹±ç +è·¯å¾„é—®é¢˜ï¼‰ =====================
# é¡¹ç›®æ ¹ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼Œé€‚é…è™šæ‹Ÿæœºï¼‰
PROJECT_ROOT = "/home/dacun/nn"
sys.path.append(PROJECT_ROOT)

# è§£å†³Matplotlibä¸­æ–‡æ˜¾ç¤ºä¹±ç ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# å¯¼å…¥é¡¹ç›®æœ¬åœ°æ¨¡å—
try:
    from common.transformations.camera import transform_img, eon_intrinsics
    from common.transformations.model import medmodel_intrinsics
    from common.tools.lib.parser import parser
except ImportError as e:
    print(f"âŒ å¯¼å…¥commonæ¨¡å—å¤±è´¥ï¼š{e}")
    print("ğŸ’¡ è¯·ç¡®ä¿commonæ–‡ä»¶å¤¹åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š/home/dacun/nn/common/")
    sys.exit(1)

# ===================== æ ¸å¿ƒå‡½æ•°ï¼ˆè§„èŒƒåŒ–+ç²¾ç®€å†—ä½™ï¼‰ =====================
def frames_to_tensor(frames):
    """
    å°†è§†é¢‘å¸§è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡
    :param frames: åŸå§‹è§†é¢‘å¸§æ•°ç»„ (N, H, W, C)
    :return: å½’ä¸€åŒ–åçš„å¼ é‡ (N, 6, H//2, W//2)
    """
    if len(frames) == 0:
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    # å¼ é‡ç»´åº¦æ˜ å°„ï¼ˆæ¨¡å‹è¾“å…¥è¦æ±‚ï¼‰
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    tensor[:, 4] = frames[:, H:H+H//4].reshape(-1, H//2, W//2)
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape(-1, H//2, W//2)
    return tensor / 128.0 - 1.0  # å½’ä¸€åŒ–åˆ°[-1, 1]

def preprocess_frames(imgs):
    """
    è§†é¢‘å¸§é¢„å¤„ç†ï¼ˆé€‚é…æ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰
    :param imgs: åŸå§‹YUVå¸§åˆ—è¡¨
    :return: é¢„å¤„ç†åçš„å¼ é‡
    """
    if not imgs:
        return np.array([])
    processed = np.zeros((len(imgs), 384, 512), dtype=np.uint8)
    # ç²¾å‡†æ•è·å¼‚å¸¸ï¼Œé¿å…é€šæ•å¯¼è‡´é—®é¢˜éšè—
    for i, img in enumerate(imgs):
        try:
            processed[i] = transform_img(
                img, 
                from_intr=eon_intrinsics, 
                to_intr=medmodel_intrinsics, 
                yuv=True, 
                output_size=(512, 256)
            )
        except (TypeError, ValueError) as e:
            print(f"âš ï¸  ç¬¬{i+1}å¸§é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}ï¼Œå¡«å……ç©ºå¸§")
            processed[i] = np.zeros((384, 512), dtype=np.uint8)
    return frames_to_tensor(processed)

def read_video_frames(video_path, max_frames=10):
    """
    è¯»å–è§†é¢‘å¸§ï¼ˆä»…æ”¯æŒMP4ï¼‰ï¼Œç®€åŒ–å‡½æ•°åæ›´ç›´è§‚
    :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    :param max_frames: æœ€å¤§è¯»å–å¸§æ•°
    :return: é¢„å¤„ç†ç”¨YUVå¸§ + åŸå§‹BGRå¸§
    """
    # ç²¾å‡†æ ¡éªŒè§†é¢‘æ ¼å¼
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{video_path}")
    if not video_path.lower().endswith('.mp4'):
        raise ValueError("ä»…æ”¯æŒMP4æ ¼å¼è§†é¢‘ï¼Œè¯·æ›´æ¢æ–‡ä»¶æ ¼å¼")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼ˆè¯·å®‰è£…FFmpegï¼‰ï¼š{video_path}")
    
    # é™ä½ç¼“å­˜ï¼Œå‡å°‘è™šæ‹Ÿæœºå†…å­˜å ç”¨
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    yuv_frames = []
    raw_frames = []
    
    # è¿›åº¦æ¡å¯è§†åŒ–ï¼ˆæ ¸å¿ƒä¿ç•™ä¼˜åŒ–ï¼‰
    for i in tqdm(range(max_frames), desc="è¯»å–è§†é¢‘å¸§", ncols=80):
        ret, frame = cap.read()
        if not ret:
            tqdm.write(f"âš ï¸  è§†é¢‘è¯»å–å®Œæ¯•ï¼Œå…±è¯»å–{i}å¸§ï¼ˆä¸è¶³{max_frames}å¸§ï¼‰")
            break
        raw_frames.append(frame)
        # BGRè½¬YUV_I420ï¼ˆæ¨¡å‹è¾“å…¥è¦æ±‚ï¼‰
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        yuv_resized = cv2.resize(yuv, (512, 384), interpolation=cv2.INTER_LINEAR)
        yuv_frames.append(yuv_resized)
    
    cap.release()
    return yuv_frames, raw_frames

# ===================== ä¸»å‡½æ•°ï¼ˆç²¾ç®€+å¯è§†åŒ–å‡çº§ï¼‰ =====================
def main():
    # 1. å‚æ•°æ ¡éªŒï¼ˆç²¾ç®€ä¸”ä¸“ä¸šï¼‰
    if len(sys.argv) != 2:
        print("ğŸš¨ ä½¿ç”¨é”™è¯¯ï¼šç¼ºå°‘è§†é¢‘æ–‡ä»¶è·¯å¾„")
        print("âœ… æ­£ç¡®ç”¨æ³•ï¼špython main.py <è§†é¢‘æ–‡ä»¶ç»å¯¹è·¯å¾„>")
        print("ğŸ’¡ ç¤ºä¾‹ï¼špython main.py /home/dacun/nn/test.mp4")
        sys.exit(1)
    video_path = sys.argv[1]

    # 2. åŠ è½½æ¨¡å‹ï¼ˆç²¾å‡†è·¯å¾„+å¼‚å¸¸æ•è·ï¼‰
    model_path = os.path.join(PROJECT_ROOT, "models/supercombo.h5")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}ï¼ˆè¯·æ”¾å…¥modelsç›®å½•ï¼‰")
    
    try:
        print(f"ğŸ“Œ åŠ è½½æ¨¡å‹ï¼š{model_path}")
        model = load_model(model_path, compile=False)
    except (IOError, ValueError) as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # 3. è¯»å–+é¢„å¤„ç†è§†é¢‘å¸§
    try:
        yuv_frames, raw_frames = read_video_frames(video_path)
        if not yuv_frames:
            raise RuntimeError("æœªè¯»å–åˆ°æœ‰æ•ˆè§†é¢‘å¸§")
        frame_tensor = preprocess_frames(yuv_frames)
        if frame_tensor.size == 0:
            raise RuntimeError("å¸§é¢„å¤„ç†åæ— æœ‰æ•ˆæ•°æ®")
    except Exception as e:
        print(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # 4. æ¨¡å‹æ¨ç†åˆå§‹åŒ–
    state = np.zeros((1, 512))  # æ¨¡å‹çŠ¶æ€åˆå§‹åŒ–
    desire = np.zeros((1, 8))   # è¡Œé©¶æ„å›¾åˆå§‹åŒ–
    total_frames = len(frame_tensor) - 1

    # 5. å¯è§†åŒ–å‡çº§ï¼ˆè§£å†³ä¹±ç +æ•ˆæœä¼˜åŒ–ï¼‰
    plt.ion()  # äº¤äº’å¼æ¨¡å¼
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))  # åˆ†å±æ˜¾ç¤ºï¼šåŸå§‹å¸§+é¢„æµ‹ç»“æœ
    fig.suptitle("è½¦é“çº¿é¢„æµ‹ç»“æœ", fontsize=14, fontweight='bold')

    # å­å›¾1ï¼šåŸå§‹è§†é¢‘å¸§
    ax1.set_title("åŸå§‹è§†é¢‘å¸§", fontsize=12)
    ax1.axis('off')  # å…³é—­åæ ‡è½´ï¼Œæ›´æ¸…æ™°
    img_display = ax1.imshow(cv2.cvtColor(raw_frames[0], cv2.COLOR_BGR2RGB))

    # å­å›¾2ï¼šè½¦é“çº¿é¢„æµ‹ï¼ˆä¼˜åŒ–çº¿æ¡+æ ‡æ³¨ï¼‰
    ax2.set_title("è½¦é“çº¿/è·¯å¾„é¢„æµ‹", fontsize=12)
    ax2.set_xlabel("æ¨ªå‘åƒç´ ", fontsize=10)
    ax2.set_ylabel("çºµå‘åƒç´ ", fontsize=10)
    ax2.set_ylim(0, 191)
    ax2.invert_xaxis()  # åŒ¹é…é©¾é©¶è§†è§’ï¼ˆå·¦/å³å¯¹é½ï¼‰
    ax2.grid(alpha=0.2, linestyle='--')  # è½»é‡åŒ–ç½‘æ ¼

    # åˆå§‹åŒ–é¢„æµ‹çº¿æ¡ï¼ˆé¢œè‰²æ ‡å‡†åŒ–+æ ‡ç­¾æ¸…æ™°ï¼‰
    left_line, = ax2.plot([], [], 'b-', linewidth=2.5, label='å·¦è½¦é“çº¿')
    right_line, = ax2.plot([], [], 'r-', linewidth=2.5, label='å³è½¦é“çº¿')
    path_line, = ax2.plot([], [], 'g-', linewidth=2, label='é¢„æµ‹è·¯å¾„')
    ax2.legend(loc='lower left', fontsize=9)  # å›¾ä¾‹ä½ç½®ä¼˜åŒ–

    # 6. é€å¸§æ¨ç†+å¯è§†åŒ–æ›´æ–°
    print(f"\nğŸš€ å¼€å§‹æ¨ç†ï¼ˆå…±{total_frames}å¸§ï¼ŒæŒ‰Qé”®é€€å‡ºï¼‰")
    try:
        for i in range(total_frames):
            # æ¨¡å‹æ¨ç†ï¼ˆæ ¸å¿ƒé€»è¾‘æ— æ”¹åŠ¨ï¼‰
            input_tensor = np.vstack(frame_tensor[i:i+2])[None]
            outputs = model.predict([input_tensor, desire, state], verbose=0)
            pred_result = parser(outputs)
            state = outputs[-1]

            # æ›´æ–°é¢„æµ‹çº¿æ¡ï¼ˆå¯¹é½ç»´åº¦ï¼‰
            left_line.set_data(pred_result["lll"][0], range(192))
            right_line.set_data(pred_result["rll"][0], range(192))
            path_line.set_data(pred_result["path"][0], range(192))

            # æ›´æ–°åŸå§‹å¸§æ˜¾ç¤º
            if i < len(raw_frames):
                img_display.set_data(cv2.cvtColor(raw_frames[i], cv2.COLOR_BGR2RGB))

            # åˆ·æ–°ç”»å¸ƒ
            fig.canvas.draw()
            fig.canvas.flush_events()

            # é”®ç›˜é€€å‡ºï¼ˆä»…ä¿ç•™Qé”®ï¼Œåˆ é™¤å†—ä½™è‡ªåŠ¨é€€å‡ºï¼‰
            if cv2.waitKey(50) & 0xFF == ord('q'):
                print("ğŸ›‘ ç”¨æˆ·æŒ‰Qé”®é€€å‡ºæ¨ç†")
                break

            print(f"âœ… å®Œæˆç¬¬{i+1}/{total_frames}å¸§æ¨ç†")

    finally:
        # èµ„æºé‡Šæ”¾ï¼ˆå½»åº•+è§„èŒƒï¼‰
        print("\nğŸ§¹ é‡Šæ”¾èµ„æºä¸­...")
        plt.ioff()
        plt.close(fig)
        cv2.destroyAllWindows()
        # å¼ºåˆ¶æ¸…é™¤CV2æ®‹ç•™
        cv2.waitKey(1)
        print("ğŸ‰ ç¨‹åºæ­£å¸¸ç»“æŸ")

if __name__ == "__main__":
    # å…¨å±€å¼‚å¸¸æ•è·ï¼ˆæ›´ä¸“ä¸šï¼‰
    try:
        main()
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢ï¼š{str(e)}")
        sys.exit(1)
