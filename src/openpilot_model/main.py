#!/usr/bin/env python3
# ç¬¬ä¸€æ­¥ï¼šä¼˜å…ˆé…ç½®Pythonæœç´¢è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°commonæ¨¡å—
import sys
import os

# é¡¹ç›®æ ¹ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼Œé€‚é…ä½ çš„è™šæ‹Ÿæœºè·¯å¾„ï¼‰
PROJECT_ROOT = "/home/dacun/nn"
# å°†æ ¹ç›®å½•åŠ å…¥Pythonæœç´¢è·¯å¾„
sys.path.append(PROJECT_ROOT)
# éªŒè¯è·¯å¾„æ˜¯å¦æ·»åŠ æˆåŠŸï¼ˆå¯é€‰ï¼Œå¯åˆ é™¤ï¼‰
print(f"âœ… é¡¹ç›®æ ¹ç›®å½•å·²æ·»åŠ åˆ°Pythonæœç´¢è·¯å¾„ï¼š{PROJECT_ROOT}")

# ç¬¬äºŒæ­¥ï¼šå¯¼å…¥ä¾èµ–åº“ï¼ˆåŒ…æ‹¬commonæ¨¡å—ï¼‰
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm  # ç”¨äºè¿›åº¦æç¤º
from tensorflow.keras.models import load_model

# ç°åœ¨èƒ½æ­£å¸¸å¯¼å…¥commonæ¨¡å—
from common.transformations.camera import transform_img, eon_intrinsics
from common.transformations.model import medmodel_intrinsics
from common.tools.lib.parser import parser

def frames_to_tensor(frames):
    if len(frames) == 0:
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    tensor[:, 4] = frames[:, H:H+H//4].reshape((-1, H//2, W//2))
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape((-1, H//2, W//2))
    return tensor / 128.0 - 1.0

def preprocess_frames(imgs):
    if not imgs:
        return np.array([])
    processed = np.zeros((len(imgs), 384, 512), dtype=np.uint8)
    for i, img in enumerate(imgs):
        try:
            processed[i] = transform_img(img, from_intr=eon_intrinsics, to_intr=medmodel_intrinsics, yuv=True, output_size=(512, 256))
        except:
            processed[i] = np.zeros((384, 512), dtype=np.uint8)
    return frames_to_tensor(processed)

def read_video_with_opencv(video_path, max_frames=10):  # å…³é”®ï¼šå¸§æ•°ä»20å‡åˆ°10ï¼Œè¿›ä¸€æ­¥é™ä½å‹åŠ›
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}ï¼Œè¯·å®‰è£…FFmpegï¼ˆsudo apt install ffmpegï¼‰")
    imgs = []
    raw_frames = []
    # ä¼˜åŒ–ç‚¹1ï¼šæ·»åŠ è§†é¢‘è¯»å–è¿›åº¦æ¡ï¼ˆtqdmï¼‰ï¼Œæ›´ç›´è§‚
    for i in tqdm(range(max_frames), desc="è¯»å–è§†é¢‘å¸§"):
        ret, frame = cap.read()
        if not ret:
            tqdm.write(f"âš ï¸  è§†é¢‘ä»…è¯»å–åˆ° {i} å¸§ï¼Œå·²è¾¾æœ«å°¾")
            break
        raw_frames.append(frame)
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        yuv_resized = cv2.resize(yuv, (512, 384), interpolation=cv2.INTER_AREA)
        imgs.append(yuv_resized)
    cap.release()
    return imgs, raw_frames

def main():
    # ä¼˜åŒ–ç‚¹2ï¼šå…¼å®¹ä¸ä¼ å‚æ•°çš„æƒ…å†µï¼Œç»™å‡ºæ›´å‹å¥½çš„æç¤ºï¼ˆè€Œéç›´æ¥é€€å‡ºï¼‰
    if len(sys.argv) != 2:
        print("âŒ ç¼ºå°‘è§†é¢‘æ–‡ä»¶è·¯å¾„å‚æ•°ï¼")
        print("âœ… æ­£ç¡®ç”¨æ³•: python main.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
        print("ğŸ’¡ ç¤ºä¾‹: python main.py /home/dacun/nn/sample.mp4")
        sys.exit(1)
    video_path = sys.argv[1]
    if not os.path.exists(video_path):
        print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ - {video_path}")
        sys.exit(1)

    model_path = "models/supercombo.h5"
    # æ‹¼æ¥æ¨¡å‹ç»å¯¹è·¯å¾„ï¼ˆé¿å…ç›¸å¯¹è·¯å¾„é—®é¢˜ï¼‰
    model_abs_path = os.path.join(PROJECT_ROOT, model_path)
    if not os.path.exists(model_abs_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_abs_path}")
        sys.exit(1)

    # åŠ è½½æ¨¡å‹
    try:
        print(f"ğŸ“Œ åŠ è½½æ¨¡å‹ï¼š{model_abs_path}")
        supercombo = load_model(model_abs_path, compile=False)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # è¯»å–è§†é¢‘ï¼ˆä»…10å¸§ï¼‰
    try:
        print(f"ğŸ“Œ è¯»å–è§†é¢‘ï¼š{video_path}ï¼ˆä»…10å¸§ï¼Œè½»é‡åŒ–æ¨¡å¼ï¼‰")
        imgs, raw_frames = read_video_with_opencv(video_path)
        if not imgs:
            print("âŒ é”™è¯¯ï¼šæœªè¯»å–åˆ°å¸§")
            sys.exit(1)
    except Exception as e:
        print(f"âŒ è§†é¢‘è¯»å–å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # é¢„å¤„ç†å¸§
    print("ğŸ“Œ é¢„å¤„ç†å¸§æ•°æ®...")
    frame_tensors = preprocess_frames(imgs)
    if frame_tensors.size == 0:
        print("âŒ é”™è¯¯ï¼šé¢„å¤„ç†æ— æœ‰æ•ˆæ•°æ®")
        sys.exit(1)

    # åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€
    state = np.zeros((1, 512))
    desire = np.zeros((1, 8))

    # -------------------------- è½»é‡åŒ–å¯è§†åŒ–ï¼ˆä»…1ä¸ªçª—å£ï¼Œåªç”»è½¦é“çº¿ï¼‰ --------------------------
    plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
    # ä¼˜åŒ–ç‚¹3ï¼šç¼©å°ç”»å¸ƒå°ºå¯¸ï¼ˆä»8,6â†’6,4ï¼‰ï¼Œè¿›ä¸€æ­¥é™ä½è™šæ‹Ÿæœºæ¸²æŸ“å‹åŠ›
    fig, ax = plt.subplots(figsize=(6, 4))  
    ax.set_title("è½¦é“çº¿é¢„æµ‹ï¼ˆè“=å·¦è½¦é“ï¼Œçº¢=å³è½¦é“ï¼Œç»¿=è·¯å¾„ï¼‰")
    ax.set_ylim(0, 191)  # å›ºå®šYè½´ï¼Œå‡å°‘é‡ç»˜è®¡ç®—
    ax.invert_xaxis()     # åŒ¹é…é©¾é©¶è§†è§’
    ax.grid(alpha=0.3)    # ç®€å•ç½‘æ ¼ï¼Œä¸å èµ„æº

    # åˆå§‹åŒ–ä¸‰æ¡çº¿ï¼ˆæå‰åˆ›å»ºï¼Œé¿å…æ¯æ¬¡é‡ç»˜æ–°å»ºï¼‰
    lll_line, = ax.plot([], [], "b-", linewidth=3, label="å·¦è½¦é“çº¿")
    rll_line, = ax.plot([], [], "r-", linewidth=3, label="å³è½¦é“çº¿")
    path_line, = ax.plot([], [], "g-", linewidth=2, label="é¢„æµ‹è·¯å¾„")
    ax.legend()
    # -------------------------------------------------------------------

    # é€å¸§æ¨ç†+è½»é‡åŒ–å¯è§†åŒ–
    total_frames = len(frame_tensors) - 1
    print(f"\nğŸš€ å¼€å§‹æ¨ç†+å¯è§†åŒ–ï¼ˆå…±{total_frames}å¸§ï¼ŒæŒ‰Qé”®é€€å‡ºï¼‰...")
    try:  # æ–°å¢tryåŒ…è£¹æ ¸å¿ƒé€»è¾‘ï¼Œç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿèƒ½é‡Šæ”¾èµ„æº
        for i in range(total_frames):
            try:
                # æ¨¡å‹æ¨ç†
                inputs = [np.vstack(frame_tensors[i:i+2])[None], desire, state]
                outs = supercombo.predict(inputs, verbose=0)
                parsed = parser(outs)
                state = outs[-1]

                # æ›´æ–°çº¿æ¡æ•°æ®
                lll_line.set_data(parsed["lll"][0], range(192))
                rll_line.set_data(parsed["rll"][0], range(192))
                path_line.set_data(parsed["path"][0], range(192))
                fig.canvas.draw()
                fig.canvas.flush_events()

                # æ˜¾ç¤ºåŸå§‹å¸§
                if i < len(raw_frames):
                    cv2.imshow("åŸå§‹å¸§", cv2.resize(raw_frames[i], (480, 270)))
                    if cv2.waitKey(100) & 0xFF == ord('q'):
                        print("ğŸ›‘ ç”¨æˆ·æŒ‰Qé”®é€€å‡º")
                        break

                print(f"âœ… å¸§ {i+1}/{total_frames} å®Œæˆ")

            except Exception as e:
                print(f"âš ï¸  å¸§ {i+1} å¤±è´¥ï¼š{str(e)}")
                continue
    finally:  # ä¼˜åŒ–ç‚¹4ï¼šæ— è®ºæ˜¯å¦å¼‚å¸¸ï¼Œéƒ½å¼ºåˆ¶é‡Šæ”¾èµ„æºï¼Œé¿å…çª—å£æ®‹ç•™
        print("\nğŸ§¹ é‡Šæ”¾èµ„æºä¸­...")
        plt.ioff()
        plt.close(fig)
        cv2.destroyAllWindows()
        print("ğŸ‰ å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
