import cv2
import numpy as np
import time
import threading
import sys
import os
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from gesture_detector_enhanced import EnhancedGestureDetector

    print("âœ… å¯¼å…¥å¢å¼ºç‰ˆæ‰‹åŠ¿æ£€æµ‹å™¨ (æœºå™¨å­¦ä¹ )")
    HAS_ENHANCED_DETECTOR = True
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ°å¢å¼ºç‰ˆæ£€æµ‹å™¨ï¼Œä½¿ç”¨åŸå§‹æ‰‹åŠ¿æ£€æµ‹å™¨")
    from gesture_detector import GestureDetector

    HAS_ENHANCED_DETECTOR = False

from drone_controller import DroneController
from simulation_3d import Drone3DViewer

# æ³¨æ„ï¼šphysics_engine.py æ˜¯å¯é€‰çš„ï¼Œå¦‚æœæ²¡æœ‰å¯ä»¥å…ˆæ³¨é‡Šæ‰
try:
    from physics_engine import PhysicsEngine

    HAS_PHYSICS_ENGINE = True
except ImportError:
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ° physics_engine.pyï¼Œä½¿ç”¨ç®€åŒ–çš„ç‰©ç†æ¨¡æ‹Ÿ")
    HAS_PHYSICS_ENGINE = False


class IntegratedDroneSimulation:
    """é›†æˆçš„æ— äººæœºä»¿çœŸç³»ç»Ÿ"""

    def __init__(self, config=None):
        # é…ç½®
        self.config = config or {}

        # ç³»ç»ŸçŠ¶æ€
        self.running = True
        self.paused = False

        # åˆå§‹åŒ–æ¨¡å—
        print("æ­£åœ¨åˆå§‹åŒ–æ‰‹åŠ¿æ£€æµ‹å™¨...")

        # æ£€æŸ¥å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        model_candidates = [
            ("dataset/models/gesture_svm.pkl", "SVMæ¨¡å‹"),
            ("dataset/models/gesture_random_forest.pkl", "éšæœºæ£®æ—æ¨¡å‹"),
            ("dataset/models/gesture_mlp.pkl", "ç¥ç»ç½‘ç»œæ¨¡å‹"),
        ]

        selected_model = None
        selected_model_name = None

        for model_path, model_name in model_candidates:
            if os.path.exists(model_path):
                file_size = os.path.getsize(model_path)
                print(f"ğŸ“ æ‰¾åˆ° {model_name}: {file_size / 1024:.1f} KB")

                # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†
                if file_size > 10 * 1024:
                    selected_model = model_path
                    selected_model_name = model_name
                    print(f"âœ… é€‰æ‹©: {model_name}")
                    break

        if selected_model:
            print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹: {selected_model_name}")

            try:
                from gesture_detector_enhanced import EnhancedGestureDetector
                print("âœ… å¯¼å…¥å¢å¼ºç‰ˆæ‰‹åŠ¿æ£€æµ‹å™¨")

                # ä½¿ç”¨å®é™…çš„æ¨¡å‹æ–‡ä»¶
                self.gesture_detector = EnhancedGestureDetector(
                    ml_model_path=selected_model,
                    use_ml=True
                )

                # éªŒè¯æ¨¡å‹æ˜¯å¦çœŸæ­£åŠ è½½æˆåŠŸ
                if hasattr(self.gesture_detector, 'ml_classifier') and self.gesture_detector.ml_classifier:
                    print(f"âœ… æœºå™¨å­¦ä¹ æ¨¡å‹åŠ è½½æˆåŠŸ ({selected_model_name})")
                    print(f"   å¯è¯†åˆ«æ‰‹åŠ¿: {self.gesture_detector.ml_classifier.gesture_classes}")
                else:
                    print("âš ï¸  æœºå™¨å­¦ä¹ æ¨¡å‹æœªåŠ è½½ï¼Œå›é€€åˆ°è§„åˆ™æ£€æµ‹")
                    self.gesture_detector = EnhancedGestureDetector(use_ml=False)

            except ImportError as e:
                print(f"âš ï¸  æ— æ³•å¯¼å…¥å¢å¼ºç‰ˆæ£€æµ‹å™¨: {e}")
                print("âœ… ä½¿ç”¨åŸå§‹æ‰‹åŠ¿æ£€æµ‹å™¨")
                from gesture_detector import GestureDetector
                self.gesture_detector = GestureDetector()

        else:
            print("âš ï¸  æœªæ‰¾åˆ°å¯ç”¨çš„æœºå™¨å­¦ä¹ æ¨¡å‹æ–‡ä»¶")
            print("âœ… ä½¿ç”¨åŸå§‹æ‰‹åŠ¿æ£€æµ‹å™¨")
            from gesture_detector import GestureDetector
            self.gesture_detector = GestureDetector()

        print("æ­£åœ¨åˆå§‹åŒ–æ— äººæœºæ§åˆ¶å™¨...")
        self.drone_controller = DroneController(simulation_mode=True)

        print("æ­£åœ¨åˆå§‹åŒ–3Dä»¿çœŸæ˜¾ç¤º...")
        self.viewer = Drone3DViewer(
            width=self.config.get('window_width', 1024),
            height=self.config.get('window_height', 768)
        )

        # åˆå§‹åŒ–ç‰©ç†å¼•æ“ï¼ˆå¯é€‰ï¼‰
        if HAS_PHYSICS_ENGINE:
            print("æ­£åœ¨åˆå§‹åŒ–ç‰©ç†å¼•æ“...")
            self.physics_engine = PhysicsEngine(
                mass=self.config.get('drone_mass', 1.0),
                gravity=self.config.get('gravity', 9.81)
            )
        else:
            self.physics_engine = None

        # çº¿ç¨‹
        self.gesture_thread = None
        self.simulation_thread = None

        # æ•°æ®å…±äº«
        self.current_frame = None
        self.current_gesture = None
        self.gesture_confidence = 0.0
        self.hand_landmarks = None

        # æ§åˆ¶å‚æ•°ï¼ˆé™ä½é˜ˆå€¼ä»¥æé«˜è¯†åˆ«ç‡ï¼‰
        self.control_intensity = 1.0
        self.last_command_time = time.time()
        self.command_cooldown = 1.5  # å‘½ä»¤å†·å´æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œä»2.0é™ä½åˆ°1.5

        # æ‰‹åŠ¿è¯†åˆ«é˜ˆå€¼ï¼ˆé™ä½ä»¥æé«˜çµæ•åº¦ï¼‰
        # å¦‚æœæ˜¯æœºå™¨å­¦ä¹ æ¨¡å¼ï¼Œé˜ˆå€¼å¯ä»¥è¿›ä¸€æ­¥é™ä½
        if HAS_ENHANCED_DETECTOR and hasattr(self.gesture_detector, 'use_ml') and self.gesture_detector.use_ml:
            print("âœ… ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å¼ï¼Œç½®ä¿¡åº¦é˜ˆå€¼æ›´ä½")
            base_threshold = 0.55  # æœºå™¨å­¦ä¹ å¯ä»¥æ›´ä½
        else:
            base_threshold = 0.6  # è§„åˆ™æ£€æµ‹éœ€è¦é«˜ä¸€ç‚¹

        self.gesture_thresholds = {
            'open_palm': base_threshold,
            'closed_fist': base_threshold + 0.05,
            'victory': base_threshold + 0.05,
            'thumb_up': base_threshold + 0.05,
            'thumb_down': base_threshold + 0.05,
            'pointing_up': base_threshold,
            'pointing_down': base_threshold,
            'ok_sign': base_threshold + 0.1,
            'default': base_threshold
        }

        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.cap = self._initialize_camera()

        # æ•°æ®è®°å½•
        self.data_log = []
        self.log_file = "flight_log.json"

        print("æ— äººæœºåˆå§‹åŒ–å®Œæˆï¼Œç­‰å¾…æ‰‹åŠ¿æŒ‡ä»¤...")

        print("æ— äººæœºä»¿çœŸç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ âœ“")

        if HAS_ENHANCED_DETECTOR and hasattr(self.gesture_detector, 'use_ml'):
            if self.gesture_detector.use_ml:
                print("ğŸ“Š å½“å‰æ¨¡å¼: æœºå™¨å­¦ä¹ æ‰‹åŠ¿è¯†åˆ«")
            else:
                print("ğŸ“Š å½“å‰æ¨¡å¼: è§„åˆ™æ‰‹åŠ¿è¯†åˆ«")

    def _initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        # å°è¯•å¤šä¸ªæ‘„åƒå¤´IDï¼Œä¼˜å…ˆä½¿ç”¨1ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•0
        camera_ids = [1, 0]  # ä¼˜å…ˆä½¿ç”¨æ‘„åƒå¤´1

        for camera_id in camera_ids:
            print(f"å°è¯•æ‰“å¼€æ‘„åƒå¤´ {camera_id}...")
            cap = cv2.VideoCapture(camera_id)

            if cap.isOpened():
                # è®¾ç½®æ‘„åƒå¤´å‚æ•°
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_FPS, 30)

                # å°è¯•è¯»å–ä¸€å¸§æµ‹è¯•
                ret, test_frame = cap.read()
                if ret:
                    # è·å–å®é™…å‚æ•°
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    fps = cap.get(cv2.CAP_PROP_FPS)

                    print(f"âœ… æ‘„åƒå¤´ {camera_id} åˆå§‹åŒ–æˆåŠŸ: {width}x{height} @ {fps:.1f}fps")
                    return cap
                else:
                    cap.release()
                    print(f"æ‘„åƒå¤´ {camera_id} èƒ½æ‰“å¼€ä½†æ— æ³•è¯»å–å¸§")
            else:
                print(f"æ‘„åƒå¤´ {camera_id} æ— æ³•æ‰“å¼€")

        print("âŒ æ‰€æœ‰æ‘„åƒå¤´å°è¯•å¤±è´¥ï¼Œä½¿ç”¨è™šæ‹Ÿæ¨¡å¼")
        return None

    def _gesture_recognition_loop(self):
        """æ‰‹åŠ¿è¯†åˆ«å¾ªç¯"""
        print("æ‰‹åŠ¿è¯†åˆ«çº¿ç¨‹å¯åŠ¨...")

        # æ˜¾ç¤ºå½“å‰æ£€æµ‹æ¨¡å¼
        if HAS_ENHANCED_DETECTOR and hasattr(self.gesture_detector, 'use_ml'):
            if self.gesture_detector.use_ml:
                mode_text = "æœºå™¨å­¦ä¹ æ¨¡å¼"
            else:
                mode_text = "è§„åˆ™æ£€æµ‹æ¨¡å¼"
        else:
            mode_text = "è§„åˆ™æ£€æµ‹æ¨¡å¼"

        # æ˜¾ç¤ºè™šæ‹Ÿæ¨¡å¼æç¤ºï¼ˆå¦‚æœæ‘„åƒå¤´æœªè¿æ¥ï¼‰
        if self.cap is None:
            print("âš ï¸ ä½¿ç”¨è™šæ‹Ÿæ‘„åƒå¤´æ¨¡å¼ï¼Œè¯·è¿æ¥æ‘„åƒå¤´è¿›è¡ŒçœŸå®æ‰‹åŠ¿è¯†åˆ«")

        while self.running:
            if self.paused:
                time.sleep(0.1)
                continue

            # è·å–å›¾åƒå¸§
            if self.cap and self.cap.isOpened():
                ret, frame = self.cap.read()
                if ret:
                    frame = cv2.flip(frame, 1)  # é•œåƒï¼Œæ›´è‡ªç„¶
                else:
                    # åˆ›å»ºè™šæ‹Ÿå¸§
                    frame = np.ones((480, 640, 3), dtype=np.uint8) * 255
                    cv2.putText(frame, "Camera Error - Virtual Mode", (50, 50),
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                    cv2.putText(frame, f"Connect camera for real gesture detection", (50, 100),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
                    cv2.putText(frame, f"Mode: {mode_text}", (50, 140),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 100, 0), 1)
            else:
                # è™šæ‹Ÿæ¨¡å¼
                frame = np.ones((480, 640, 3), dtype=np.uint8) * 255
                cv2.putText(frame, "è™šæ‹Ÿæ‘„åƒå¤´æ¨¡å¼", (50, 50),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                cv2.putText(frame, f"æ‰‹åŠ¿æŒ‡ä»¤ ({mode_text}):", (50, 100),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 100, 0), 2)
                cv2.putText(frame, "å¼ å¼€æ‰‹æŒ - èµ·é£", (50, 140),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "æ¡æ‹³ - é™è½", (50, 170),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "èƒœåˆ©æ‰‹åŠ¿ - å‰è¿›", (50, 200),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "å¤§æ‹‡æŒ‡ - åé€€", (50, 230),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "é£ŸæŒ‡ä¸ŠæŒ‡ - ä¸Šå‡", (50, 260),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "é£ŸæŒ‡å‘ä¸‹ - ä¸‹é™", (50, 290),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "OKæ‰‹åŠ¿ - æ‚¬åœ", (50, 320),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "å¤§æ‹‡æŒ‡å‘ä¸‹ - åœæ­¢", (50, 350),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
                cv2.putText(frame, "æŒ‰ 'q' é”®é€€å‡º", (50, 400),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

            # æ‰‹åŠ¿æ£€æµ‹
            try:
                processed_frame, gesture, confidence, landmarks = \
                    self.gesture_detector.detect_gestures(frame, simulation_mode=True)

                # æ›´æ–°å…±äº«æ•°æ®
                self.current_frame = processed_frame
                self.current_gesture = gesture
                self.gesture_confidence = confidence
                self.hand_landmarks = landmarks

                # å¤„ç†æ‰‹åŠ¿å‘½ä»¤ï¼ˆä½¿ç”¨é™ä½çš„é˜ˆå€¼ï¼‰
                self._process_gesture_command(gesture, confidence)

                # æ˜¾ç¤ºæ‰‹åŠ¿è¯†åˆ«çª—å£
                cv2.imshow('Gesture Control', processed_frame)

            except Exception as e:
                print(f"æ‰‹åŠ¿æ£€æµ‹é”™è¯¯: {e}")
                self.current_frame = frame
                self.current_gesture = None

                # æ£€æŸ¥é€€å‡º
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("æ”¶åˆ°é€€å‡ºæŒ‡ä»¤...")
                self.running = False
                break
            elif key == ord('c'):
                # åˆ‡æ¢æ‘„åƒå¤´åŠŸèƒ½
                self._switch_camera()
            elif key == ord('d'):  # è°ƒè¯•æ¨¡å¼
                self._debug_gesture_detection()
            elif key == ord('m'):  # åˆ‡æ¢æ¨¡å¼ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼‰
                self._switch_detection_mode()

        print("æ‰‹åŠ¿è¯†åˆ«çº¿ç¨‹ç»“æŸ")

    def _switch_detection_mode(self):
        """åˆ‡æ¢æ£€æµ‹æ¨¡å¼ï¼ˆå¦‚æœæœ‰å¤šä¸ªå¯ç”¨æ¨¡å‹ï¼‰"""
        if not HAS_ENHANCED_DETECTOR:
            print("å½“å‰åªæœ‰è§„åˆ™æ£€æµ‹å™¨å¯ç”¨")
            return

        # æ£€æŸ¥å¯ç”¨çš„æ¨¡å‹
        model_files = [
            ("dataset/models/gesture_ensemble.pkl", "é›†æˆæ¨¡å‹"),
            ("dataset/models/gesture_svm.pkl", "SVMæ¨¡å‹"),
            ("dataset/models/gesture_random_forest.pkl", "éšæœºæ£®æ—æ¨¡å‹"),
            ("dataset/models/gesture_mlp.pkl", "ç¥ç»ç½‘ç»œæ¨¡å‹"),
        ]

        available_models = []
        for path, name in model_files:
            if os.path.exists(path):
                available_models.append((path, name))

        if len(available_models) == 0:
            print("æœªæ‰¾åˆ°ä»»ä½•æœºå™¨å­¦ä¹ æ¨¡å‹")
            return
        elif len(available_models) == 1:
            print(f"åªæœ‰ {available_models[0][1]} å¯ç”¨")
            return

        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        print("\nå¯ç”¨çš„æ‰‹åŠ¿è¯†åˆ«æ¨¡å‹:")
        for i, (path, name) in enumerate(available_models, 1):
            print(f"  {i}. {name}")

        print("æŒ‰æ•°å­—é”®é€‰æ‹©æ¨¡å‹ï¼Œæˆ–æŒ‰å…¶ä»–é”®å–æ¶ˆ")

        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦æ›´å¤æ‚çš„äº¤äº’
        # æš‚æ—¶åªè®°å½•ä¸€ä¸‹
        print("æ³¨æ„: éœ€è¦é‡å¯ç¨‹åºåˆ‡æ¢æ¨¡å‹")

    def _switch_camera(self):
        """åˆ‡æ¢æ‘„åƒå¤´"""
        if self.cap:
            self.cap.release()
            print("é‡Šæ”¾å½“å‰æ‘„åƒå¤´...")

        # è·å–å½“å‰æ‘„åƒå¤´ID
        current_id = 1 if self.cap is None else 0

        print(f"åˆ‡æ¢åˆ°æ‘„åƒå¤´ {current_id}...")
        self.cap = cv2.VideoCapture(current_id)

        if self.cap.isOpened():
            print(f"âœ… åˆ‡æ¢åˆ°æ‘„åƒå¤´ {current_id} æˆåŠŸ")
        else:
            print(f"âŒ åˆ‡æ¢åˆ°æ‘„åƒå¤´ {current_id} å¤±è´¥")
            self.cap = None

    def _debug_gesture_detection(self):
        """è°ƒè¯•æ‰‹åŠ¿æ£€æµ‹"""
        print("\n[æ‰‹åŠ¿è°ƒè¯•ä¿¡æ¯]")
        print(f"å½“å‰æ‰‹åŠ¿: {self.current_gesture}")
        print(f"ç½®ä¿¡åº¦: {self.gesture_confidence:.2f}")
        print(f"å†·å´æ—¶é—´: {time.time() - self.last_command_time:.1f}s")
        print(f"æ— äººæœºè§£é”: {self.drone_controller.state['armed']}")
        print(f"æ— äººæœºæ¨¡å¼: {self.drone_controller.state['mode']}")
        print(f"æ— äººæœºä½ç½®: ({self.drone_controller.state['position'][0]:.1f}, "
              f"{self.drone_controller.state['position'][1]:.1f}, "
              f"{self.drone_controller.state['position'][2]:.1f})")

    def _process_gesture_command(self, gesture, confidence):
        """å¤„ç†æ‰‹åŠ¿å‘½ä»¤ï¼ˆä½¿ç”¨é™ä½çš„é˜ˆå€¼ï¼‰"""
        current_time = time.time()

        # è·å–è¯¥æ‰‹åŠ¿çš„é˜ˆå€¼ï¼ˆé™ä½ä»¥æé«˜è¯†åˆ«ç‡ï¼‰
        threshold = self.gesture_thresholds.get(gesture, self.gesture_thresholds['default'])

        # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
        in_cooldown = current_time - self.last_command_time <= self.command_cooldown

        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤æ‰‹åŠ¿ï¼ˆé¿å…é¢‘ç¹å¤„ç†åŒä¸€ä¸ªæ‰‹åŠ¿ï¼‰
        same_gesture = (gesture == self.current_gesture and
                        hasattr(self, 'last_processed_gesture') and
                        gesture == self.last_processed_gesture and
                        current_time - getattr(self, 'last_processed_time', 0) < 2.0)

        # åªå¤„ç†ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼çš„æ‰‹åŠ¿ä¸”ä¸åœ¨å†·å´æœŸ
        if (gesture not in ["no_hand", "hand_detected"] and
                confidence > threshold and
                not in_cooldown and
                not same_gesture):

            # è·å–æ§åˆ¶å‘½ä»¤
            command = self.gesture_detector.get_command(gesture)

            if command != "none":
                # è®¡ç®—æ‰‹åŠ¿å¼ºåº¦ï¼ˆå¦‚æœæœ‰æ‰‹éƒ¨å…³é”®ç‚¹ï¼‰
                intensity = 1.0
                if self.hand_landmarks:
                    intensity = self.gesture_detector.get_gesture_intensity(
                        self.hand_landmarks, gesture
                    )

                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                print(
                    f"ğŸ¯ æ£€æµ‹åˆ°æ‰‹åŠ¿: {gesture} (ç½®ä¿¡åº¦: {confidence:.2f}, é˜ˆå€¼: {threshold}) -> æ‰§è¡Œ: {command} (å¼ºåº¦: {intensity:.2f})")

                # å‘é€å‘½ä»¤åˆ°æ§åˆ¶å™¨
                self.drone_controller.send_command(command, intensity)

                # è®°å½•å‘½ä»¤
                self._log_command(gesture, command, confidence, intensity)

                # æ›´æ–°æœ€åå‘½ä»¤æ—¶é—´å’Œæ‰‹åŠ¿çŠ¶æ€
                self.last_command_time = current_time
                self.last_processed_gesture = gesture
                self.last_processed_time = current_time
        elif gesture not in ["no_hand", "hand_detected"] and confidence > 0.3:
            # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºæ£€æµ‹åˆ°ä½†æœªè§¦å‘çš„æƒ…å†µ
            debug_mode = False  # å¯ä»¥è®¾ä¸ºTrueå¯ç”¨è¯¦ç»†è°ƒè¯•
            if debug_mode:
                if in_cooldown:
                    print(
                        f"  [å†·å´ä¸­] {gesture} å†·å´æ—¶é—´å‰©ä½™: {self.command_cooldown - (current_time - self.last_command_time):.1f}s")
                elif same_gesture:
                    print(f"  [é‡å¤æ‰‹åŠ¿] {gesture} å·²å¤„ç†è¿‡ï¼Œå†·å´ä¸­")
                elif confidence < threshold:
                    print(f"  [ç½®ä¿¡åº¦ä¸è¶³] {gesture} ç½®ä¿¡åº¦: {confidence:.2f} < é˜ˆå€¼: {threshold}")

    def _simulation_loop(self):
        """ä»¿çœŸä¸»å¾ªç¯"""
        print("3Dä»¿çœŸçº¿ç¨‹å¯åŠ¨...")

        last_time = time.time()
        frame_count = 0
        last_status_print = time.time()

        # å¸§ç‡æ§åˆ¶
        target_fps = 60
        frame_delay = 1.0 / target_fps

        print("\nğŸ® é”®ç›˜æç¤ºï¼šæŒ‰ 'R' é”®é‡ç½®æ— äººæœºä½ç½®åˆ°åŸç‚¹")
        print("           æŒ‰ 'T' é”®æ‰‹åŠ¨èµ·é£")
        print("           æŒ‰ 'L' é”®æ‰‹åŠ¨é™è½")
        print("           æŒ‰ 'H' é”®æ‚¬åœ")

        # æŒ‰é”®é˜²æŠ–è®°å½•
        self._last_key_press = {}

        while self.running:
            start_time = time.time()
            current_time = time.time()
            dt = current_time - last_time
            last_time = current_time

            if dt <= 0:
                dt = frame_delay
            elif dt > 0.1:
                dt = 0.1

            # æ¯3ç§’æ‰“å°ä¸€æ¬¡çŠ¶æ€
            if current_time - last_status_print > 3:
                status = self.drone_controller.get_status_string()
                print(f"[çŠ¶æ€ç›‘æ§] {status}")
                if self.current_gesture:
                    print(f"[çŠ¶æ€ç›‘æ§] å½“å‰æ‰‹åŠ¿: {self.current_gesture} (ç½®ä¿¡åº¦: {self.gesture_confidence:.2f})")
                last_status_print = current_time

            if self.paused:
                if not self.viewer.handle_events():
                    self.running = False
                time.sleep(0.01)
                continue

            keys = pygame.key.get_pressed()

            # æ£€æŸ¥é‡ç½®é”® R
            if keys[pygame.K_r]:
                if ('r' not in self._last_key_press or
                        current_time - self._last_key_press['r'] > 1.0):
                    print("ğŸ® é”®ç›˜ï¼šé‡ç½®æ— äººæœºä½ç½®")
                    self.drone_controller.reset()
                    print("  æ— äººæœºå·²é‡ç½®åˆ°åŸç‚¹ä½ç½®")
                    self._last_key_press['r'] = current_time

            # æ£€æŸ¥èµ·é£é”® T
            if keys[pygame.K_t]:
                if ('t' not in self._last_key_press or
                        current_time - self._last_key_press['t'] > 1.0):
                    print("ğŸ® é”®ç›˜ï¼šèµ·é£")
                    self.drone_controller.send_command("takeoff", 0.8)
                    self._last_key_press['t'] = current_time

            # æ£€æŸ¥é™è½é”® L
            if keys[pygame.K_l]:
                if ('l' not in self._last_key_press or
                        current_time - self._last_key_press['l'] > 1.0):
                    print("ğŸ® é”®ç›˜ï¼šé™è½")
                    self.drone_controller.send_command("land", 0.5)
                    self._last_key_press['l'] = current_time

            # æ£€æŸ¥æ‚¬åœé”® H
            if keys[pygame.K_h]:
                if ('h' not in self._last_key_press or
                        current_time - self._last_key_press['h'] > 1.0):
                    print("ğŸ® é”®ç›˜ï¼šæ‚¬åœ")
                    self.drone_controller.send_command("hover")
                    self._last_key_press['h'] = current_time

            # æ£€æŸ¥åœæ­¢é”® S
            if keys[pygame.K_s]:
                if ('s' not in self._last_key_press or
                        current_time - self._last_key_press['s'] > 1.0):
                    print("ğŸ® é”®ç›˜ï¼šåœæ­¢")
                    self.drone_controller.send_command("stop")
                    self._last_key_press['s'] = current_time

            if not self.viewer.handle_events():
                self.running = False
                break

            if not self.running:
                break

            drone_state = self.drone_controller.get_state()
            self.drone_controller.update_physics(dt)

            if self.physics_engine and self.drone_controller.state['armed']:
                control_input = self._get_control_input_from_state(drone_state)
                physics_state = self.physics_engine.update(dt, control_input)

            trajectory = self.drone_controller.get_trajectory()

            drone_state_with_gesture = drone_state.copy()
            if self.current_gesture:
                drone_state_with_gesture['current_gesture'] = self.current_gesture
                drone_state_with_gesture['gesture_confidence'] = self.gesture_confidence

            self.viewer.render(drone_state_with_gesture, trajectory)

            # æ§åˆ¶å¸§ç‡ï¼Œé¿å…CPUå ç”¨è¿‡é«˜
            elapsed = time.time() - start_time
            sleep_time = frame_delay - elapsed
            if sleep_time > 0:
                time.sleep(sleep_time)

            frame_count += 1
            if frame_count % 120 == 0:
                fps = 1.0 / (time.time() - start_time) if start_time > 0 else 0
                print(f"3Dä»¿çœŸå¸§ç‡: {fps:.1f} FPS")

        print("3Dä»¿çœŸçº¿ç¨‹ç»“æŸ")

    def _get_control_input_from_state(self, drone_state):
        """ä»æ— äººæœºçŠ¶æ€ç”Ÿæˆæ§åˆ¶è¾“å…¥"""
        control_input = {
            'throttle': 0.5,  # é»˜è®¤æ²¹é—¨
            'roll': 0.0,
            'pitch': 0.0,
            'yaw_rate': 0.0
        }

        # å¦‚æœæ£€æµ‹åˆ°æ‰‹éƒ¨å…³é”®ç‚¹ï¼Œå¯ä»¥ç”¨äºç²¾ç»†æ§åˆ¶
        if self.hand_landmarks and self.current_gesture:
            # ç®€å•ç¤ºä¾‹ï¼šæ ¹æ®æ‰‹åŠ¿è°ƒæ•´æ§åˆ¶
            if self.current_gesture == "pointing_up":
                control_input['throttle'] = 0.8
            elif self.current_gesture == "pointing_down":
                control_input['throttle'] = 0.2
            elif self.current_gesture == "victory":
                control_input['pitch'] = 0.3  # è½»å¾®å‰å€¾
            elif self.current_gesture == "thumb_up":
                control_input['pitch'] = -0.3  # è½»å¾®åå€¾

        return control_input

    def _log_command(self, gesture, command, confidence, intensity):
        """è®°å½•å‘½ä»¤åˆ°æ—¥å¿—"""
        log_entry = {
            'timestamp': time.time(),
            'gesture': gesture,
            'command': command,
            'confidence': confidence,
            'intensity': intensity,
            'position': self.drone_controller.state['position'].tolist(),
            'battery': self.drone_controller.state['battery'],
            'armed': self.drone_controller.state['armed'],
            'mode': self.drone_controller.state['mode']
        }
        self.data_log.append(log_entry)

        # å®æ—¶æ˜¾ç¤º
        pos = self.drone_controller.state['position']
        print(f"  ä½ç½®: ({pos[0]:.1f}, {pos[1]:.1f}, {pos[2]:.1f}) | "
              f"ç”µæ± : {self.drone_controller.state['battery']:.1f}%")

    def _save_log(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        if self.data_log:
            try:
                with open(self.log_file, 'w', encoding='utf-8') as f:
                    json.dump(self.data_log, f, indent=2, ensure_ascii=False)
                print(f"é£è¡Œæ—¥å¿—å·²ä¿å­˜åˆ°: {self.log_file} ({len(self.data_log)}æ¡è®°å½•)")
            except Exception as e:
                print(f"ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
        else:
            print("æ²¡æœ‰é£è¡Œè®°å½•éœ€è¦ä¿å­˜")

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("=" * 60)
        print("     æ‰‹åŠ¿æ§åˆ¶æ— äººæœºä»¿çœŸç³»ç»Ÿï¼ˆæœºå™¨å­¦ä¹ å¢å¼ºç‰ˆï¼‰")
        print("=" * 60)

        # æ˜¾ç¤ºå½“å‰æ£€æµ‹æ¨¡å¼
        if HAS_ENHANCED_DETECTOR and hasattr(self.gesture_detector, 'use_ml'):
            if self.gesture_detector.use_ml:
                mode_info = "æœºå™¨å­¦ä¹ æ¨¡å¼ (æ›´é«˜ç²¾åº¦)"
            else:
                mode_info = "è§„åˆ™æ£€æµ‹æ¨¡å¼ (åŸºç¡€)"
        else:
            mode_info = "è§„åˆ™æ£€æµ‹æ¨¡å¼"

        print(f"æ£€æµ‹æ¨¡å¼: {mode_info}")

        print("ç³»ç»ŸåŠŸèƒ½:")
        print("  1. å®æ—¶æ‰‹åŠ¿è¯†åˆ« (8ç§æ‰‹åŠ¿)")
        print("  2. æ— äººæœºæ§åˆ¶ä»¿çœŸ")
        print("  3. 3Då¯è§†åŒ– (OpenGLæ¸²æŸ“)")
        print("  4. é£è¡Œæ•°æ®è®°å½•")
        print("=" * 60)
        print("æ‰‹åŠ¿æŒ‡ä»¤:")
        print("  å¼ å¼€æ‰‹æŒ - èµ·é£")
        print("  æ¡æ‹³ - é™è½")
        print("  èƒœåˆ©æ‰‹åŠ¿ - å‰è¿›")
        print("  å¤§æ‹‡æŒ‡ - åé€€")
        print("  é£ŸæŒ‡ä¸ŠæŒ‡ - ä¸Šå‡")
        print("  é£ŸæŒ‡å‘ä¸‹ - ä¸‹é™")
        print("  OKæ‰‹åŠ¿ - æ‚¬åœ")
        print("  å¤§æ‹‡æŒ‡å‘ä¸‹ - åœæ­¢")
        print("=" * 60)
        print("ä½¿ç”¨è¯´æ˜:")
        print("  æ‰‹åŠ¿æ§åˆ¶çª—å£: æŒ‰ 'q' é€€å‡º")
        print("  æ‰‹åŠ¿æ§åˆ¶çª—å£: æŒ‰ 'c' åˆ‡æ¢æ‘„åƒå¤´")
        print("  æ‰‹åŠ¿æ§åˆ¶çª—å£: æŒ‰ 'd' æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯")
        print("  3Dä»¿çœŸçª—å£: æŒ‰ 'ESC' é€€å‡º")
        print("  3Dçª—å£æŒ‰é”®æ§åˆ¶:")
        print("    G - åˆ‡æ¢ç½‘æ ¼æ˜¾ç¤º")
        print("    T - åˆ‡æ¢è½¨è¿¹æ˜¾ç¤º")
        print("    A - åˆ‡æ¢åæ ‡è½´æ˜¾ç¤º")
        print("    â†‘â†“â†â†’ - æ—‹è½¬è§†è§’")
        print("    +/- - ç¼©æ”¾è§†è§’")
        print("    ç©ºæ ¼ - é‡ç½®è§†è§’")
        print("=" * 60)
        print("æç¤º:")
        print("  1. æ— äººæœºåˆå§‹åœ¨åœ°é¢ï¼Œç­‰å¾…æ‰‹åŠ¿æŒ‡ä»¤")
        print("  2. æ‰‹åŠ¿è¯†åˆ«é˜ˆå€¼å·²é™ä½ï¼Œæ›´å®¹æ˜“è§¦å‘")
        print("  3. åšæ‰‹åŠ¿æ—¶ä¿æŒæ‰‹åœ¨æ‘„åƒå¤´ä¸­å¿ƒ")
        print("  4. æ¯ä¸ªæ‰‹åŠ¿ä¿æŒ1.5ç§’ä»¥ä¸Š")
        print("=" * 60)
        print("ç³»ç»Ÿå¯åŠ¨ä¸­...")

        try:
            # å¯åŠ¨æ‰‹åŠ¿è¯†åˆ«çº¿ç¨‹
            self.gesture_thread = threading.Thread(
                target=self._gesture_recognition_loop,
                name="GestureThread",
                daemon=True
            )
            self.gesture_thread.start()

            print("æ‰‹åŠ¿è¯†åˆ«çº¿ç¨‹å·²å¯åŠ¨")
            print("3Dä»¿çœŸçª—å£å³å°†æ‰“å¼€...")
            time.sleep(1)  # ç»™æ‰‹åŠ¿çª—å£ä¸€ç‚¹æ—¶é—´æ˜¾ç¤º

            # ä¸»çº¿ç¨‹è¿è¡Œä»¿çœŸ
            self._simulation_loop()

            # ç­‰å¾…æ‰‹åŠ¿çº¿ç¨‹ç»“æŸ
            if self.gesture_thread.is_alive():
                self.gesture_thread.join(timeout=2.0)

        except KeyboardInterrupt:
            print("\nç³»ç»Ÿè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # æ¸…ç†èµ„æº
            self.running = False

            if self.cap:
                self.cap.release()
                print("æ‘„åƒå¤´å·²é‡Šæ”¾")

            cv2.destroyAllWindows()
            print("OpenCVçª—å£å·²å…³é—­")

            # ä¿å­˜æ—¥å¿—
            self._save_log()

            print("æ— äººæœºä»¿çœŸç³»ç»Ÿå·²å®‰å…¨å…³é—­ âœ“")


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = {
        'camera_id': 1,  # é»˜è®¤ä½¿ç”¨æ‘„åƒå¤´1
        'window_width': 1024,
        'window_height': 768,
        'drone_mass': 1.0,
        'gravity': 9.81,
        'simulation_fps': 60,
        'gesture_threshold': 0.6  # é™ä½é»˜è®¤é˜ˆå€¼
    }
    return config


if __name__ == "__main__":
    print("æ‰‹åŠ¿æ§åˆ¶æ— äººæœºä»¿çœŸç³»ç»Ÿ")
    print("=" * 60)

    # æ£€æŸ¥å¿…è¦çš„æ¨¡å—
    try:
        import pygame

        print("âœ… Pygame å·²å®‰è£…")
    except ImportError:
        print("âŒ é”™è¯¯: Pygame æœªå®‰è£…!")
        print("è¯·è¿è¡Œ: pip install pygame")
        sys.exit(1)

    try:
        import OpenGL

        print("âœ… PyOpenGL å·²å®‰è£…")
    except ImportError:
        print("âŒ é”™è¯¯: PyOpenGL æœªå®‰è£…!")
        print("è¯·è¿è¡Œ: pip install PyOpenGL PyOpenGL-accelerate")
        sys.exit(1)

    # åŠ è½½é…ç½®
    config = load_config()

    # åˆ›å»ºå¹¶è¿è¡Œä»¿çœŸç³»ç»Ÿ
    try:
        simulation = IntegratedDroneSimulation(config)
        simulation.run()
    except Exception as e:
        print(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()