import cv2
import numpy as np
import time
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from gesture_detector import GestureDetector
from drone_controller import DroneController


def create_test_frame(message="Gesture Drone Control - VM Mode"):
    """åˆ›å»ºæµ‹è¯•å¸§"""
    frame = np.ones((480, 640, 3), dtype=np.uint8) * 255

    # æ·»åŠ æ ‡é¢˜
    cv2.putText(frame, message, (50, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

    # æ·»åŠ æ‰‹åŠ¿è¯´æ˜
    gestures = [
        "Gesture Commands:",
        "Open Palm - Takeoff",
        "Closed Fist - Land",
        "Victory - Forward",
        "Thumb Up - Backward",
        "Point Up - Up",
        "Point Down - Down",
        "OK Sign - Hover",
        "Thumb Down - Stop"
    ]

    for i, text in enumerate(gestures):
        y_pos = 90 + i * 25
        color = (0, 0, 255) if i == 0 else (0, 100, 0)
        cv2.putText(frame, text, (50, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

    cv2.putText(frame, "Press 'q' to quit", (50, 430),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

    return frame


def main():
    print("=" * 60)
    print("  æ‰‹åŠ¿æ§åˆ¶æ— äººæœºç³»ç»Ÿ - è™šæ‹Ÿæœºç‰ˆæœ¬")
    print("=" * 60)
    print("ç¨‹åºå·²å¯åŠ¨ï¼Œæ­£åœ¨å°è¯•æ˜¾ç¤ºçª—å£...")
    print("å¦‚æœçœ‹ä¸åˆ°çª—å£ï¼Œè¯·æ£€æŸ¥è™šæ‹Ÿæœºæ˜¾ç¤ºè®¾ç½®")
    print("=" * 60)

    detector = GestureDetector()
    controller = DroneController(simulation_mode=True)

    # æµ‹è¯•æ˜¾ç¤º
    test_frame = create_test_frame("Testing Display...")
    cv2.imshow('Gesture Drone - VM', test_frame)
    cv2.waitKey(1000)  # æ˜¾ç¤º1ç§’

    # å°è¯•æ‰“å¼€æ‘„åƒå¤´
    cap = None
    for cam_id in [0, 1, 2]:
        cap = cv2.VideoCapture(cam_id)
        if cap.isOpened():
            print(f"æ‘„åƒå¤´ {cam_id} æ‰“å¼€æˆåŠŸ")
            break
        else:
            cap = None

    if cap is None:
        print("ä½¿ç”¨è™šæ‹Ÿæ‘„åƒå¤´æ¨¡å¼")

    last_command_time = time.time()
    frame_count = 0

    while True:
        frame_count += 1

        # è·å–å¸§
        if cap and cap.isOpened():
            ret, frame = cap.read()
            if ret:
                frame = cv2.flip(frame, 1)
            else:
                frame = create_test_frame("Camera Error - Virtual Mode")
        else:
            # è™šæ‹Ÿæ¨¡å¼ - åˆ›å»ºåŠ¨æ€æµ‹è¯•å¸§
            if frame_count % 30 == 0:  # æ¯30å¸§åˆ‡æ¢æ¶ˆæ¯
                messages = [
                    "Virtual Camera Mode - Make gestures",
                    "Hand Detection Active - VM",
                    "Gesture Recognition Ready"
                ]
                message = messages[(frame_count // 30) % len(messages)]
                frame = create_test_frame(message)
            else:
                frame = create_test_frame("Virtual Camera Mode - Make gestures")

        # æ‰‹åŠ¿æ£€æµ‹
        try:
            processed_frame, gesture, confidence = detector.detect_gestures(frame)
        except Exception as e:
            print(f"æ‰‹åŠ¿æ£€æµ‹é”™è¯¯: {e}")
            processed_frame = frame
            gesture = "no_hand"

        # å¤„ç†å‘½ä»¤
        current_time = time.time()
        if (gesture not in ["no_hand", "hand_detected"] and
                current_time - last_command_time > 2.0):

            command = detector.get_command(gesture)
            if command != "none":
                print(f"ğŸ¯ æ£€æµ‹åˆ°æ‰‹åŠ¿: {gesture} -> æ‰§è¡Œ: {command}")
                controller.send_command(command)
                last_command_time = current_time

        # æ˜¾ç¤ºå¸§
        cv2.imshow('Gesture Drone Control - VM', processed_frame)

        # é€€å‡ºæ£€æµ‹
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('c'):
            print("åˆ‡æ¢æ‘„åƒå¤´...")
            if cap:
                cap.release()
            cap = None

    # æ¸…ç†
    if cap:
        cap.release()
    cv2.destroyAllWindows()
    print("ç¨‹åºé€€å‡º")


if __name__ == "__main__":
    main()
