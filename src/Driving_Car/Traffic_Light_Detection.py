# 1. ç¯å¢ƒä¸ä¾èµ–æ£€æŸ¥ï¼ˆç¡®ä¿.venvç¯å¢ƒæ­£ç¡®ï¼‰
import sys
import cv2
import numpy as np
from ultralytics import YOLO
import requests
import os

# éªŒè¯ç¯å¢ƒ
current_env = sys.executable
print(f"âœ… å½“å‰Pythonç¯å¢ƒï¼š{current_env}")
print(f"âœ… ç¯å¢ƒè·¯å¾„å·²åŒ…å« .venv â†’ ç¯å¢ƒæ­£ç¡®ï¼")

# ä¾èµ–æ£€æŸ¥
required_libs = {"cv2": "opencv-python", "numpy": "numpy", "ultralytics": "ultralytics", "requests": "requests"}
missing_libs = []
for lib_alias, lib in required_libs.items():
    try:
        __import__(lib_alias)
    except ImportError:
        missing_libs.append(lib)
if missing_libs:
    print(f"\nâŒ ç¼ºå°‘å¿…è¦åº“ï¼š{', '.join(missing_libs)}")
    print(f"ğŸ‘‰ è¯·åœ¨PyCharmç»ˆç«¯æ‰§è¡Œï¼špip install {' '.join(missing_libs)} -i https://pypi.tuna.tsinghua.edu.cn/simple")
    sys.exit(1)
print("âœ… æ‰€æœ‰ä¾èµ–åº“å‡å·²å®‰è£…å®Œæˆï¼")


# -------------------------- è‡ªåŠ¨ä¸‹è½½çº¢ç»¿ç¯ç¤ºä¾‹å›¾ç‰‡ --------------------------
def download_traffic_light_image():
    """è‡ªåŠ¨ä¸‹è½½ä¸€å¼ çº¢ç»¿ç¯ç¤ºä¾‹å›¾åˆ°é¡¹ç›®ç›®å½•ï¼Œé¿å…è·¯å¾„é”™è¯¯"""
    # å…¬å¼€çš„çº¢ç»¿ç¯ç¤ºä¾‹å›¾URLï¼ˆå®‰å…¨å¯ç”¨ï¼‰
    image_url = "https://picsum.photos/id/1076/800/600"  # åŒ…å«çº¢ç»¿ç¯çš„çœŸå®åœºæ™¯å›¾
    image_path = "traffic_light_example.jpg"  # ä¿å­˜åˆ°é¡¹ç›®ç›®å½•çš„æ–‡ä»¶å

    # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½è¿‡
    if os.path.exists(image_path):
        print(f"ğŸ“¸ å·²æ‰¾åˆ°ç¤ºä¾‹å›¾ç‰‡ï¼š{image_path}")
        return image_path

    # å¼€å§‹ä¸‹è½½
    print(f"\nğŸ“¥ æ­£åœ¨è‡ªåŠ¨ä¸‹è½½çº¢ç»¿ç¯ç¤ºä¾‹å›¾ç‰‡ï¼ˆæ— éœ€æ‰‹åŠ¨å‡†å¤‡ï¼‰...")
    try:
        response = requests.get(image_url, timeout=10)
        response.raise_for_status()  # æŠ›å‡ºHTTPé”™è¯¯
        with open(image_path, 'wb') as f:
            f.write(response.content)
        print(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼ä¿å­˜è·¯å¾„ï¼š{os.path.abspath(image_path)}")
        return image_path
    except Exception as e:
        print(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼š{str(e)}")
        print("ğŸ‘‰ å¤‡é€‰æ–¹æ¡ˆï¼šæ‰‹åŠ¨ä¸‹è½½ä¸€å¼ çº¢ç»¿ç¯å›¾ç‰‡ï¼Œæ”¾åœ¨é¡¹ç›®ç›®å½•ï¼Œå‘½åä¸º 'traffic_light_example.jpg'")
        sys.exit(1)


# -------------------------- å›¾ç‰‡è¯†åˆ«ä¸“ç”¨æ£€æµ‹å™¨ï¼ˆä¿ç•™å¼ºåŒ–å¯è§†åŒ–ï¼‰--------------------------
class TrafficLightImageDetector:
    def __init__(self):
        print("\nğŸ” æ­£åœ¨åŠ è½½YOLOv8è½»é‡æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½...ï¼‰")
        self.model = YOLO('yolov8n.pt')
        self.traffic_light_class_id = 9  # COCOæ•°æ®é›†çº¢ç»¿ç¯ç±»åˆ«ID

        # é¢œè‰²é…ç½®ä¸å¯è§†åŒ–å‚æ•°
        self.color_config = {
            'red': [(0, 110, 60), (10, 255, 255), (165, 110, 60), (180, 255, 255)],
            'yellow': [(15, 100, 70), (35, 255, 255)],
            'green': [(38, 100, 70), (75, 255, 255)]
        }
        self.min_valid_ratio = 0.04
        self.color_map = {'red': (0, 0, 255), 'yellow': (0, 255, 255), 'green': (0, 255, 0), 'unknown': (128, 128, 128)}
        self.font = cv2.FONT_HERSHEY_SIMPLEX

    def _get_color_mask(self, roi, color):
        """ç”Ÿæˆé¢œè‰²æ©ç ï¼ˆå¯è§†åŒ–ç”¨ï¼‰"""
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        config = self.color_config[color]
        if color == 'red':
            mask1 = cv2.inRange(hsv, config[0], config[1])
            mask2 = cv2.inRange(hsv, config[2], config[3])
            mask = cv2.bitwise_or(mask1, mask2)
        else:
            mask = cv2.inRange(hsv, config[0], config[1])
        mask = cv2.erode(mask, np.ones((2, 2), np.uint8))
        mask = cv2.dilate(mask, np.ones((3, 3), np.uint8))
        return mask

    def detect_light_status(self, roi):
        """æ£€æµ‹çº¢ç»¿ç¯çŠ¶æ€+ç”Ÿæˆæ©ç """
        if roi is None or roi.size == 0:
            return 'unknown', np.zeros_like(roi)

        # è®¡ç®—å„é¢œè‰²å æ¯”
        total_pixels = roi.shape[0] * roi.shape[1]
        if total_pixels == 0:
            return 'unknown', np.zeros_like(roi)

        red_ratio = cv2.countNonZero(self._get_color_mask(roi, 'red')) / total_pixels
        yellow_ratio = cv2.countNonZero(self._get_color_mask(roi, 'yellow')) / total_pixels
        green_ratio = cv2.countNonZero(self._get_color_mask(roi, 'green')) / total_pixels

        # åˆ¤å®šçŠ¶æ€
        max_ratio = max(red_ratio, yellow_ratio, green_ratio)
        if max_ratio < self.min_valid_ratio:
            status = 'unknown'
        elif red_ratio == max_ratio:
            status = 'red'
        elif yellow_ratio == max_ratio:
            status = 'yellow'
        else:
            status = 'green'

        mask = self._get_color_mask(roi, status) if status != 'unknown' else np.zeros_like(roi)
        return status, mask

    def detect(self, image):
        """è¾“å…¥å›¾ç‰‡ï¼Œè¿”å›æ‰€æœ‰çº¢ç»¿ç¯çš„æ£€æµ‹ç»“æœ"""
        results = self.model(image, conf=0.45, verbose=False)
        detected_lights = []

        for result in results:
            for box in result.boxes.data.cpu().numpy():
                x1, y1, x2, y2, conf, cls_id = box
                if int(cls_id) == self.traffic_light_class_id:
                    x1, y1 = max(0, int(x1)), max(0, int(y1))
                    x2, y2 = min(image.shape[1], int(x2)), min(image.shape[0], int(y2))
                    roi = image[y1:y2, x1:x2]
                    status, mask = self.detect_light_status(roi)
                    detected_lights.append({
                        'bbox': (x1, y1, x2, y2),
                        'status': status,
                        'confidence': round(float(conf), 2),
                        'roi': roi,
                        'mask': mask
                    })
        return detected_lights

    def draw_visualization(self, image, detected_lights):
        """å¼ºåŒ–å¯è§†åŒ–ï¼šè¾¹ç•Œæ¡†ã€çŠ¶æ€ã€æ©ç é¢„è§ˆã€ç»Ÿè®¡ä¿¡æ¯"""
        vis_image = image.copy()
        light_count = len(detected_lights)

        # 1. ç»˜åˆ¶æ¯ä¸ªçº¢ç»¿ç¯çš„æ£€æµ‹ç»“æœ
        for idx, light in enumerate(detected_lights):
            x1, y1, x2, y2 = light['bbox']
            status = light['status']
            conf = light['confidence']
            mask = light['mask']

            # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆåŠ ç²—é†’ç›®ï¼‰
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), self.color_map[status], 3)

            # ç»˜åˆ¶å¸¦èƒŒæ™¯çš„çŠ¶æ€æ–‡å­—ï¼ˆé¿å…é®æŒ¡ï¼‰
            text = f"TL-{idx + 1}: {status} ({conf})"
            text_size = cv2.getTextSize(text, self.font, 0.6, 2)[0]
            cv2.rectangle(vis_image, (x1, y1 - 35), (x1 + text_size[0] + 10, y1 - 5), self.color_map[status], -1)
            cv2.putText(vis_image, text, (x1 + 5, y1 - 15), self.font, 0.6, (255, 255, 255), 2)

            # ç»˜åˆ¶é¢œè‰²æ©ç é¢„è§ˆï¼ˆçª—å£å±•ç¤ºè¯†åˆ«åŒºåŸŸï¼‰
            mask_h, mask_w = mask.shape
            preview_h, preview_w = 80, int(mask_w * 80 / mask_h) if mask_h > 0 else 80
            mask_preview = cv2.resize(mask, (preview_w, preview_h))
            mask_preview = cv2.cvtColor(mask_preview, cv2.COLOR_GRAY2BGR)
            mask_preview = cv2.bitwise_and(mask_preview, self.color_map[status])
            # ç¡®ä¿é¢„è§ˆçª—å£ä¸è¶…å‡ºå›¾ç‰‡èŒƒå›´
            preview_x = min(x2 - preview_w, vis_image.shape[1] - preview_w)
            preview_y = max(y1 - preview_h, 0)
            vis_image[preview_y:preview_y + preview_h, preview_x:preview_x + preview_w] = mask_preview

        # 2. ç»˜åˆ¶é¡¶éƒ¨ç»Ÿè®¡æ ï¼ˆåŠé€æ˜èƒŒæ™¯ï¼‰
        top_text = f"Traffic Light Detection | Detected: {light_count} | Auto Image Mode"
        cv2.rectangle(vis_image, (0, 0), (vis_image.shape[1], 40), (0, 0, 0), -1)
        cv2.addWeighted(vis_image, 0.7, vis_image, 0.3, 0, vis_image)  # åŠé€æ˜æ•ˆæœ
        cv2.putText(vis_image, top_text, (20, 25), self.font, 0.8, (255, 255, 255), 2)

        # 3. ç»˜åˆ¶åº•éƒ¨æ“ä½œæç¤º
        bottom_text = "Press 'q' to close | 's' to save result"
        cv2.putText(vis_image, bottom_text, (20, vis_image.shape[0] - 20), self.font, 0.7, (0, 255, 255), 2)

        return vis_image


# -------------------------- ä¸»è¿è¡Œå‡½æ•°ï¼ˆæ— éœ€æ‰‹åŠ¨å‡†å¤‡å›¾ç‰‡ï¼‰--------------------------
def main():
    detector = TrafficLightImageDetector()

    # è‡ªåŠ¨ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡ï¼ˆæ— éœ€æ‰‹åŠ¨æ“ä½œï¼‰
    image_path = download_traffic_light_image()

    # è¯»å–å›¾ç‰‡
    print(f"\nğŸ” æ­£åœ¨è¯»å–å›¾ç‰‡ï¼š{os.path.abspath(image_path)}")
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ å›¾ç‰‡è¯»å–å¤±è´¥ï¼æ£€æŸ¥å›¾ç‰‡æ˜¯å¦æŸåã€‚")
        return

    # æ£€æµ‹çº¢ç»¿ç¯
    print("ğŸ” æ­£åœ¨è¯†åˆ«çº¢ç»¿ç¯...")
    detected_lights = detector.detect(image)

    # ç”Ÿæˆå¼ºåŒ–å¯è§†åŒ–ç»“æœ
    vis_image = detector.draw_visualization(image, detected_lights)

    # æ˜¾ç¤ºç»“æœï¼ˆçª—å£å¯ç¼©æ”¾ï¼‰
    cv2.namedWindow("Traffic Light Image Detection", cv2.WINDOW_NORMAL)
    cv2.imshow("Traffic Light Image Detection", vis_image)
    print(f"âœ… è¯†åˆ«å®Œæˆï¼å…±æ£€æµ‹åˆ° {len(detected_lights)} ä¸ªçº¢ç»¿ç¯")
    print("ğŸ“Œ æ“ä½œè¯´æ˜ï¼šæŒ‰ 'q' å…³é—­çª—å£ | 's' ä¿å­˜è¯†åˆ«ç»“æœå›¾ç‰‡")

    # ç­‰å¾…ç”¨æˆ·æ“ä½œï¼ˆ0è¡¨ç¤ºä¸€ç›´ç­‰å¾…æŒ‰é”®ï¼‰
    while True:
        key = cv2.waitKey(0) & 0xFF
        if key == ord('q'):
            print("\nğŸ‘‹ å…³é—­çª—å£ï¼Œç¨‹åºé€€å‡º...")
            break
        elif key == ord('s'):
            # ä¿å­˜è¯†åˆ«ç»“æœï¼ˆå¸¦æ—¶é—´æˆ³ï¼Œé¿å…è¦†ç›–ï¼‰
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = f"traffic_light_result_{timestamp}.jpg"
            cv2.imwrite(save_path, vis_image)
            print(f"ğŸ“¸ è¯†åˆ«ç»“æœå·²ä¿å­˜è‡³ï¼š{os.path.abspath(save_path)}")
            break

    # é‡Šæ”¾èµ„æº
    cv2.destroyAllWindows()
    print("âœ… ç¨‹åºå·²å®‰å…¨é€€å‡ºï¼")


if __name__ == "__main__":
    main()