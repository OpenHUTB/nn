"""
æ‰‹åŠ¿è½¨è¿¹è®°å½•å™¨æ¨¡å—
è´Ÿè´£å½•åˆ¶ã€ä¿å­˜ã€åŠ è½½å’Œå›æ”¾æ‰‹åŠ¿è½¨è¿¹
ä½œè€…: xiaoshiyuan888
"""

import os
import time
import pickle
import cv2
from datetime import datetime


class GestureTrajectoryRecorder:
    """æ‰‹åŠ¿è½¨è¿¹è®°å½•å™¨ - è®°å½•ã€ä¿å­˜ã€åŠ è½½å’Œå›æ”¾æ‰‹åŠ¿è½¨è¿¹"""

    def __init__(self, speech_manager=None, config=None):
        self.speech_manager = speech_manager
        self.config = config
        self.trajectory_data = []
        self.is_recording = False
        self.is_playing = False
        self.playback_index = 0
        self.playback_paused = False
        self.max_trajectory_points = 1000
        self.recording_start_time = 0
        self.last_save_time = 0
        self.save_interval = 5

        # è½¨è¿¹æ–‡ä»¶è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.trajectory_dir = os.path.join(current_dir, 'trajectories')
        if not os.path.exists(self.trajectory_dir):
            os.makedirs(self.trajectory_dir)

        # é»˜è®¤è½¨è¿¹æ–‡ä»¶å
        self.default_filename = os.path.join(self.trajectory_dir,
                                             f'trajectory_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pkl')

        # è½¨è¿¹å¯è§†åŒ–è®¾ç½®
        self.trajectory_colors = [
            (255, 0, 0),  # çº¢è‰² - èµ·ç‚¹
            (0, 255, 0),  # ç»¿è‰² - æ­£å¸¸ç‚¹
            (0, 0, 255),  # è“è‰² - ç»ˆç‚¹
            (255, 255, 0),  # é’è‰² - ç‰¹æ®Šç‚¹
            (255, 0, 255)  # ç´«è‰² - ç‰¹æ®Šç‚¹
        ]

        self.show_trajectory = True
        self.trajectory_thickness = 2
        self.trajectory_max_length = 100

        print("âœ“ æ‰‹åŠ¿è½¨è¿¹è®°å½•å™¨å·²åˆå§‹åŒ–")

    def start_recording(self):
        """å¼€å§‹å½•åˆ¶æ‰‹åŠ¿è½¨è¿¹"""
        if self.is_recording:
            return False

        self.trajectory_data = []
        self.is_recording = True
        self.recording_start_time = time.time()
        self.last_save_time = time.time()

        print("ğŸ¬ å¼€å§‹å½•åˆ¶æ‰‹åŠ¿è½¨è¿¹")

        # è¯­éŸ³æç¤º
        if self.speech_manager and self.speech_manager.enabled:
            self.speech_manager.speak('recording_start', immediate=True)

        return True

    def stop_recording(self):
        """åœæ­¢å½•åˆ¶æ‰‹åŠ¿è½¨è¿¹"""
        if not self.is_recording:
            return False

        self.is_recording = False
        recording_duration = time.time() - self.recording_start_time

        print(f"â¹ï¸ åœæ­¢å½•åˆ¶æ‰‹åŠ¿è½¨è¿¹")
        print(f"   å½•åˆ¶æ—¶é•¿: {recording_duration:.1f}ç§’")
        print(f"   è½¨è¿¹ç‚¹æ•°: {len(self.trajectory_data)}")

        # è¯­éŸ³æç¤º
        if self.speech_manager and self.speech_manager.enabled:
            self.speech_manager.speak('recording_stop', immediate=True)
            if len(self.trajectory_data) > 0:
                self.speech_manager.speak_direct(f"å½•åˆ¶äº†{len(self.trajectory_data)}ä¸ªè½¨è¿¹ç‚¹")

        return True

    def add_trajectory_point(self, hand_data, gesture, confidence, frame_shape):
        """æ·»åŠ è½¨è¿¹ç‚¹"""
        if not self.is_recording or len(self.trajectory_data) >= self.max_trajectory_points:
            return False

        if hand_data is None:
            return False

        # åˆ›å»ºè½¨è¿¹ç‚¹æ•°æ®
        trajectory_point = {
            'timestamp': time.time(),
            'hand_position': hand_data['position'] if 'position' in hand_data else (0.5, 0.5),
            'hand_center': hand_data['center'] if 'center' in hand_data else (0, 0),
            'gesture': gesture,
            'confidence': confidence,
            'fingertips': hand_data.get('fingertips', []),
            'frame_shape': frame_shape
        }

        self.trajectory_data.append(trajectory_point)

        # è‡ªåŠ¨ä¿å­˜æ£€æŸ¥
        current_time = time.time()
        if current_time - self.last_save_time >= self.save_interval and len(self.trajectory_data) > 10:
            self.auto_save()
            self.last_save_time = current_time

        return True

    def auto_save(self):
        """è‡ªåŠ¨ä¿å­˜è½¨è¿¹ï¼ˆä¸´æ—¶æ–‡ä»¶ï¼‰"""
        if len(self.trajectory_data) == 0:
            return

        temp_file = os.path.join(self.trajectory_dir, 'trajectory_temp.pkl')
        try:
            with open(temp_file, 'wb') as f:
                pickle.dump(self.trajectory_data, f)
            print(f"ğŸ’¾ è‡ªåŠ¨ä¿å­˜è½¨è¿¹åˆ°ä¸´æ—¶æ–‡ä»¶ ({len(self.trajectory_data)}ä¸ªç‚¹)")
        except Exception as e:
            print(f"âš  è‡ªåŠ¨ä¿å­˜è½¨è¿¹å¤±è´¥: {e}")

    def save_trajectory(self, filename=None):
        """ä¿å­˜è½¨è¿¹åˆ°æ–‡ä»¶"""
        if len(self.trajectory_data) == 0:
            print("âš  æ²¡æœ‰è½¨è¿¹æ•°æ®å¯ä¿å­˜")
            return False

        if filename is None:
            filename = self.default_filename

        try:
            with open(filename, 'wb') as f:
                pickle.dump(self.trajectory_data, f)

            print(f"ğŸ’¾ è½¨è¿¹å·²ä¿å­˜åˆ°: {filename}")
            print(f"   è½¨è¿¹ç‚¹æ•°: {len(self.trajectory_data)}")

            # è¯­éŸ³æç¤º
            if self.speech_manager and self.speech_manager.enabled:
                self.speech_manager.speak('recording_saved', immediate=True)
                self.speech_manager.speak_direct(f"ä¿å­˜äº†{len(self.trajectory_data)}ä¸ªè½¨è¿¹ç‚¹")

            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜è½¨è¿¹å¤±è´¥: {e}")
            return False

    def load_trajectory(self, filename):
        """ä»æ–‡ä»¶åŠ è½½è½¨è¿¹"""
        try:
            if not os.path.exists(filename):
                print(f"âŒ è½¨è¿¹æ–‡ä»¶ä¸å­˜åœ¨: {filename}")

                # è¯­éŸ³æç¤º
                if self.speech_manager and self.speech_manager.enabled:
                    self.speech_manager.speak('recording_not_found', immediate=True)

                return False

            with open(filename, 'rb') as f:
                self.trajectory_data = pickle.load(f)

            print(f"ğŸ“‚ è½¨è¿¹å·²ä»æ–‡ä»¶åŠ è½½: {filename}")
            print(f"   è½¨è¿¹ç‚¹æ•°: {len(self.trajectory_data)}")

            # è¯­éŸ³æç¤º
            if self.speech_manager and self.speech_manager.enabled:
                self.speech_manager.speak('recording_loaded', immediate=True)
                self.speech_manager.speak_direct(f"åŠ è½½äº†{len(self.trajectory_data)}ä¸ªè½¨è¿¹ç‚¹")

            return True
        except Exception as e:
            print(f"âŒ åŠ è½½è½¨è¿¹å¤±è´¥: {e}")
            return False

    def start_playback(self):
        """å¼€å§‹å›æ”¾è½¨è¿¹"""
        if len(self.trajectory_data) == 0:
            print("âš  æ²¡æœ‰è½¨è¿¹æ•°æ®å¯å›æ”¾")

            # è¯­éŸ³æç¤º
            if self.speech_manager and self.speech_manager.enabled:
                self.speech_manager.speak('recording_not_found', immediate=True)

            return False

        self.is_playing = True
        self.playback_index = 0
        self.playback_paused = False

        print(f"â–¶ï¸ å¼€å§‹å›æ”¾æ‰‹åŠ¿è½¨è¿¹")
        print(f"   æ€»å¸§æ•°: {len(self.trajectory_data)}")

        # è¯­éŸ³æç¤º
        if self.speech_manager and self.speech_manager.enabled:
            self.speech_manager.speak('recording_playback_start', immediate=True)

        return True

    def stop_playback(self):
        """åœæ­¢å›æ”¾è½¨è¿¹"""
        if not self.is_playing:
            return False

        self.is_playing = False
        self.playback_paused = False

        print("â¹ï¸ åœæ­¢å›æ”¾æ‰‹åŠ¿è½¨è¿¹")

        # è¯­éŸ³æç¤º
        if self.speech_manager and self.speech_manager.enabled:
            self.speech_manager.speak('recording_playback_stop', immediate=True)

        return True

    def pause_playback(self):
        """æš‚åœ/ç»§ç»­å›æ”¾"""
        self.playback_paused = not self.playback_paused

        status = "æš‚åœ" if self.playback_paused else "ç»§ç»­"
        print(f"â¸ï¸ å›æ”¾å·²{status}")

        # è¯­éŸ³æç¤º
        if self.speech_manager and self.speech_manager.enabled:
            if self.playback_paused:
                self.speech_manager.speak('recording_paused', immediate=True)
            else:
                self.speech_manager.speak('recording_resumed', immediate=True)

        return self.playback_paused

    def get_next_playback_point(self):
        """è·å–ä¸‹ä¸€ä¸ªå›æ”¾ç‚¹"""
        if not self.is_playing or self.playback_paused or len(self.trajectory_data) == 0:
            return None

        if self.playback_index >= len(self.trajectory_data):
            self.stop_playback()
            return None

        point = self.trajectory_data[self.playback_index]
        self.playback_index += 1

        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æœ«å°¾
        if self.playback_index >= len(self.trajectory_data):
            self.stop_playback()

        return point

    def clear_trajectory(self):
        """æ¸…é™¤è½¨è¿¹æ•°æ®"""
        self.trajectory_data = []
        self.is_recording = False
        self.is_playing = False
        self.playback_index = 0

        print("ğŸ—‘ï¸ è½¨è¿¹æ•°æ®å·²æ¸…é™¤")

        # è¯­éŸ³æç¤º
        if self.speech_manager and self.speech_manager.enabled:
            self.speech_manager.speak('recording_cleared', immediate=True)

        return True

    def draw_trajectory(self, frame):
        """åœ¨å¸§ä¸Šç»˜åˆ¶è½¨è¿¹"""
        if not self.show_trajectory or len(self.trajectory_data) == 0:
            return frame

        h, w = frame.shape[:2]

        # é™åˆ¶æ˜¾ç¤ºçš„è½¨è¿¹ç‚¹æ•°
        display_points = min(len(self.trajectory_data), self.trajectory_max_length)
        start_idx = max(0, len(self.trajectory_data) - display_points)

        # ç»˜åˆ¶è½¨è¿¹çº¿
        for i in range(start_idx, len(self.trajectory_data) - 1):
            point1 = self.trajectory_data[i]
            point2 = self.trajectory_data[i + 1]

            # è·å–æ‰‹éƒ¨ä¸­å¿ƒä½ç½®
            if 'hand_center' in point1 and 'hand_center' in point2:
                x1, y1 = point1['hand_center']
                x2, y2 = point2['hand_center']

                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(w - 1, x1))
                y1 = max(0, min(h - 1, y1))
                x2 = max(0, min(w - 1, x2))
                y2 = max(0, min(h - 1, y2))

                # æ ¹æ®ç´¢å¼•è®¡ç®—é¢œè‰²
                color_idx = int((i - start_idx) / display_points * (len(self.trajectory_colors) - 1))
                color = self.trajectory_colors[color_idx]

                # ç»˜åˆ¶çº¿æ¡
                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)),
                         color, self.trajectory_thickness)

        # ç»˜åˆ¶å½“å‰ç‚¹
        if self.is_recording or self.is_playing:
            current_idx = len(self.trajectory_data) - 1 if self.is_recording else self.playback_index - 1
            if 0 <= current_idx < len(self.trajectory_data):
                point = self.trajectory_data[current_idx]
                if 'hand_center' in point:
                    x, y = point['hand_center']
                    x = max(0, min(w - 1, x))
                    y = max(0, min(h - 1, y))

                    # ç»˜åˆ¶å½“å‰ç‚¹
                    cv2.circle(frame, (int(x), int(y)), 8, (0, 255, 255), -1)
                    cv2.circle(frame, (int(x), int(y)), 8, (0, 0, 0), 2)

        return frame

    def get_status(self):
        """è·å–å½•åˆ¶çŠ¶æ€"""
        return {
            'is_recording': self.is_recording,
            'is_playing': self.is_playing,
            'playback_paused': self.playback_paused,
            'trajectory_points': len(self.trajectory_data),
            'playback_index': self.playback_index,
            'playback_total': len(self.trajectory_data),
            'recording_duration': time.time() - self.recording_start_time if self.is_recording else 0
        }

    def list_saved_trajectories(self):
        """åˆ—å‡ºä¿å­˜çš„è½¨è¿¹æ–‡ä»¶"""
        try:
            files = [f for f in os.listdir(self.trajectory_dir) if f.endswith('.pkl')]
            return sorted(files, reverse=True)
        except:
            return []