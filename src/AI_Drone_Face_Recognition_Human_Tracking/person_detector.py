# äººç‰©æ£€æµ‹æ¨¡å—ï¼ˆYOLOv8ï¼‰
import cv2
import sys
import os
import numpy as np

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))

try:
    from person_detector import PersonDetector

    print("âœ… æˆåŠŸå¯¼å…¥ PersonDetector")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ’¡ è¯·ç¡®ä¿ modules/person_detector.py å­˜åœ¨")
    sys.exit(1)


def test_with_camera():
    """ä½¿ç”¨æ‘„åƒå¤´æµ‹è¯•äººç‰©æ£€æµ‹"""
    print("ğŸ¥ æ­£åœ¨æ‰“å¼€æ‘„åƒå¤´...")

    # åˆå§‹åŒ–æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)  # 0 = é»˜è®¤æ‘„åƒå¤´

    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        print("ğŸ’¡ å°è¯•ä½¿ç”¨ä¸åŒçš„æ‘„åƒå¤´ç´¢å¼•: cv2.VideoCapture(1)")
        return

    # åˆå§‹åŒ–äººç‰©æ£€æµ‹å™¨
    print("ğŸ”„ æ­£åœ¨åŠ è½½YOLOv8æ¨¡å‹...")
    detector = PersonDetector()

    print("âœ… å¼€å§‹æ£€æµ‹ï¼ŒæŒ‰ 'q' é”®é€€å‡º")
    print("   's' é”®: ä¿å­˜å½“å‰å¸§")
    print("   'p' é”®: æš‚åœ/ç»§ç»­")

    paused = False

    while True:
        if not paused:
            # è¯»å–æ‘„åƒå¤´å¸§
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                break

            # æ£€æµ‹äººç‰©
            persons, annotated_frame = detector.detect(frame)

            # æ˜¾ç¤ºç»“æœ
            cv2.putText(annotated_frame, f'Persons: {len(persons)}', (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            # æ˜¾ç¤ºæ¯ä¸ªæ£€æµ‹åˆ°çš„äººçš„ä¿¡æ¯
            for i, person in enumerate(persons):
                bbox = person['bbox']
                confidence = person['confidence']
                cv2.putText(annotated_frame, f'Person {i + 1}: {confidence:.2f}',
                            (10, 70 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

                # åœ¨æ§åˆ¶å°è¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼ˆæ¯10å¸§è¾“å‡ºä¸€æ¬¡ï¼‰
                if cv2.getTickCount() % 10 == 0:
                    print(f"ğŸ‘¤ Person {i + 1}: bbox={bbox}, confidence={confidence:.2f}")

            # æ˜¾ç¤ºå›¾åƒ
            cv2.imshow('Person Detection - YOLOv8', annotated_frame)

        # é”®ç›˜æ§åˆ¶
        key = cv2.waitKey(1) & 0xFF

        if key == ord('q'):  # é€€å‡º
            break
        elif key == ord('p'):  # æš‚åœ/ç»§ç»­
            paused = not paused
            print(f"{'â¸ï¸ æš‚åœ' if paused else 'â–¶ï¸ ç»§ç»­'}")
        elif key == ord('s'):  # ä¿å­˜å›¾åƒ
            timestamp = cv2.getTickCount()
            filename = f'detection_{timestamp}.jpg'
            cv2.imwrite(filename, annotated_frame)
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {filename}")

    # æ¸…ç†
    cap.release()
    cv2.destroyAllWindows()
    print("âœ… æµ‹è¯•å®Œæˆ")


def test_with_image(image_path=None):
    """ä½¿ç”¨å›¾ç‰‡æµ‹è¯•äººç‰©æ£€æµ‹"""
    if image_path is None or not os.path.exists(image_path):
        print("ğŸ“¸ æœªæä¾›æœ‰æ•ˆå›¾ç‰‡è·¯å¾„ï¼Œä½¿ç”¨æµ‹è¯•å›¾ç‰‡...")
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
        image = np.zeros((400, 600, 3), dtype=np.uint8)
        # ç”»ä¸€ä¸ª"äººç‰©"ï¼ˆç®€å•çš„çŸ©å½¢ï¼‰
        cv2.rectangle(image, (200, 100), (400, 300), (255, 255, 255), -1)
        cv2.putText(image, "Test Person", (220, 180),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        image_path = "test_generated.jpg"
        cv2.imwrite(image_path, image)
        print(f"ğŸ–¼ï¸ åˆ›å»ºæµ‹è¯•å›¾ç‰‡: {image_path}")

    print(f"ğŸ–¼ï¸ æ­£åœ¨æµ‹è¯•å›¾ç‰‡: {image_path}")

    # è¯»å–å›¾ç‰‡
    frame = cv2.imread(image_path)
    if frame is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return

    # åˆå§‹åŒ–äººç‰©æ£€æµ‹å™¨
    print("ğŸ”„ æ­£åœ¨åŠ è½½YOLOv8æ¨¡å‹...")
    detector = PersonDetector()

    # æ£€æµ‹äººç‰©
    persons, annotated_frame = detector.detect(frame)

    print(f"âœ… æ£€æµ‹åˆ° {len(persons)} ä¸ªäººç‰©")

    # æ˜¾ç¤ºæ¯ä¸ªæ£€æµ‹åˆ°çš„äººçš„ä¿¡æ¯
    for i, person in enumerate(persons):
        bbox = person['bbox']
        confidence = person['confidence']
        print(f"ğŸ‘¤ Person {i + 1}:")
        print(f"   Bounding Box: {bbox}")
        print(f"   Confidence: {confidence:.4f}")
        print(f"   Class: {person['class_name']}")

        # åœ¨å›¾åƒä¸Šæ ‡æ³¨
        x1, y1, x2, y2 = bbox
        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(annotated_frame, f'Person {i + 1}: {confidence:.2f}',
                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # æ˜¾ç¤ºç»“æœ
    cv2.imshow('Person Detection Result', annotated_frame)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    # ä¿å­˜ç»“æœ
    output_path = 'detection_result.jpg'
    cv2.imwrite(output_path, annotated_frame)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

    return len(persons)


def test_yolov8_model():
    """æµ‹è¯•YOLOv8æ¨¡å‹åŠ è½½å’ŒåŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•YOLOv8æ¨¡å‹åŠ è½½...")

    try:
        # åˆ›å»ºæ£€æµ‹å™¨ï¼ˆè¿™ä¼šä¸‹è½½æ¨¡å‹ï¼‰
        print("ğŸ“¥ åˆ›å»ºPersonDetectorå®ä¾‹...")
        detector = PersonDetector()
        print("âœ… PersonDetectoråˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
        print("ğŸ“¸ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        test_image = np.zeros((300, 300, 3), dtype=np.uint8)
        test_image[:, :, 0] = 255  # è“è‰²èƒŒæ™¯
        cv2.rectangle(test_image, (100, 100), (200, 200), (255, 255, 255), -1)  # ç™½è‰²çŸ©å½¢ä½œä¸º"äººç‰©"

        # æµ‹è¯•æ£€æµ‹
        print("ğŸ” è¿›è¡Œäººç‰©æ£€æµ‹...")
        persons, result = detector.detect(test_image)

        print(f"âœ… æ£€æµ‹å®Œæˆ")
        print(f"   å›¾åƒå¤§å°: {test_image.shape}")
        print(f"   æ£€æµ‹åˆ°äººç‰©æ•°é‡: {len(persons)}")

        if persons:
            for i, person in enumerate(persons):
                print(f"   Person {i + 1}: bbox={person['bbox']}, conf={person['confidence']:.2f}")
        else:
            print("   â„¹ï¸  æœªæ£€æµ‹åˆ°äººç‰©ï¼ˆæ­£å¸¸ï¼Œå› ä¸ºæ˜¯ç®€å•æµ‹è¯•å›¾åƒï¼‰")

        # æ˜¾ç¤ºç»“æœ
        cv2.imshow('Model Test Result', result)
        cv2.waitKey(1000)  # æ˜¾ç¤º1ç§’
        cv2.destroyAllWindows()

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def quick_test():
    """å¿«é€Ÿæµ‹è¯•ï¼ˆæ— éœ€ç”¨æˆ·äº¤äº’ï¼‰"""
    print("âš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    print("1. æµ‹è¯•æ¨¡å‹åŠ è½½...")
    if test_yolov8_model():
        print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡")

        print("\n2. æµ‹è¯•å›¾ç‰‡æ£€æµ‹...")
        num_persons = test_with_image()
        print(f"âœ… å›¾ç‰‡æ£€æµ‹å®Œæˆï¼Œæ‰¾åˆ° {num_persons} ä¸ªäººç‰©")

        print("\n3. æ˜¯å¦æµ‹è¯•æ‘„åƒå¤´? (y/n)")
        choice = input().strip().lower()
        if choice == 'y':
            print("\nğŸ¥ å¼€å§‹æ‘„åƒå¤´æµ‹è¯•...")
            test_with_camera()
        else:
            print("ğŸ“Š å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    else:
        print("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("ğŸ§ª YOLOv8 äººç‰©æ£€æµ‹æ¨¡å—æµ‹è¯•")
    print("=" * 50)

    print("\né€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. ä½¿ç”¨æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
    print("2. ä½¿ç”¨å›¾ç‰‡æ–‡ä»¶æµ‹è¯•")
    print("3. æµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†")
    print("4. å¿«é€Ÿæµ‹è¯•ï¼ˆè‡ªåŠ¨æµç¨‹ï¼‰")
    print("5. é€€å‡º")

    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()

        if choice == "1":
            test_with_camera()
        elif choice == "2":
            image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨æµ‹è¯•å›¾ç‰‡): ").strip()
            if not image_path:
                image_path = None
            test_with_image(image_path)
        elif choice == "3":
            test_yolov8_model()
        elif choice == "4":
            quick_test()
        elif choice == "5":
            print("ğŸ‘‹ é€€å‡ºæµ‹è¯•")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œå¿«é€Ÿæµ‹è¯•")
            quick_test()

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")


if __name__ == "__main__":
    main()