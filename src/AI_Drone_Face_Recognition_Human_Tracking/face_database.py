from ultralytics import YOLO
import cv2
import numpy as np
import os
import json
from typing import Optional, Tuple, List, Dict


class FaceDatabase:
    # ã€å¤ç”¨ä¹‹å‰çš„FaceDatabaseç±»ä»£ç ï¼Œæ­¤å¤„çœç•¥ï¼ˆä¿æŒä¸å˜ï¼‰ã€‘
    def __init__(self, data_dir: str = "face_database", threshold: float = 0.6):
        self.data_dir = data_dir
        self.feat_dir = os.path.join(data_dir, "features")
        self.meta_dir = os.path.join(data_dir, "metadata")
        self.threshold = threshold
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(self.feat_dir, exist_ok=True)
        os.makedirs(self.meta_dir, exist_ok=True)
        self.face_features: Dict[str, np.ndarray] = {}
        self.face_metadata: Dict[str, dict] = {}

    @staticmethod
    def preprocess_face(face_roi: np.ndarray) -> Optional[np.ndarray]:
        if face_roi.size == 0:
            return None
        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        gray = cv2.resize(gray, (128, 128))
        gray = cv2.equalizeHist(gray)
        feature = gray.flatten() / 255.0
        return feature

    def save_face(self, name: str, face_roi: np.ndarray, remark: str = "", overwrite: bool = True) -> bool:
        feature = self.preprocess_face(face_roi)
        if feature is None:
            print(f"âŒ äººè„¸é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ä¿å­˜{name}")
            return False
        feat_path = os.path.join(self.feat_dir, f"{name}.npy")
        meta_path = os.path.join(self.meta_dir, f"{name}.json")
        if os.path.exists(feat_path) and not overwrite:
            print(f"âš ï¸ {name}å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜ï¼ˆå¦‚éœ€è¦†ç›–è¯·è®¾ç½®overwrite=Trueï¼‰")
            return False
        np.save(feat_path, feature)
        metadata = {
            "name": name,
            "remark": remark,
            "feature_shape": feature.shape,
            "add_time": str(np.datetime64('now')),
            "version": "1.0"
        }
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        self.face_features[name] = feature
        self.face_metadata[name] = metadata
        print(f"âœ… {name}äººè„¸æ•°æ®ä¿å­˜æˆåŠŸ")
        return True

    def load_face(self, name: str) -> bool:
        feat_path = os.path.join(self.feat_dir, f"{name}.npy")
        meta_path = os.path.join(self.meta_dir, f"{name}.json")
        if not os.path.exists(feat_path) or not os.path.exists(meta_path):
            print(f"âŒ {name}äººè„¸æ•°æ®ä¸å­˜åœ¨")
            return False
        feature = np.load(feat_path)
        with open(meta_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        self.face_features[name] = feature
        self.face_metadata[name] = metadata
        print(f"âœ… åŠ è½½{name}äººè„¸æ•°æ®æˆåŠŸ")
        return True

    def load_all_faces(self) -> int:
        loaded_count = 0
        for feat_file in os.listdir(self.feat_dir):
            if not feat_file.endswith(".npy"):
                continue
            name = os.path.splitext(feat_file)[0]
            if self.load_face(name):
                loaded_count += 1
        print(f"ğŸ“Š æ‰¹é‡åŠ è½½å®Œæˆï¼Œå…±åŠ è½½{loaded_count}ä¸ªäººè„¸æ•°æ®")
        return loaded_count

    def delete_face(self, name: str) -> bool:
        feat_path = os.path.join(self.feat_dir, f"{name}.npy")
        meta_path = os.path.join(self.meta_dir, f"{name}.json")
        for path in [feat_path, meta_path]:
            if os.path.exists(path):
                os.remove(path)
        if name in self.face_features:
            del self.face_features[name]
        if name in self.face_metadata:
            del self.face_metadata[name]
        print(f"ğŸ—‘ï¸ {name}äººè„¸æ•°æ®å·²åˆ é™¤")
        return True

    def list_faces(self) -> List[str]:
        face_list = [os.path.splitext(f)[0] for f in os.listdir(self.feat_dir) if f.endswith(".npy")]
        print(f"ğŸ“‹ å·²ä¿å­˜çš„äººè„¸åˆ—è¡¨ï¼š{face_list}")
        return face_list

    @staticmethod
    def calculate_similarity(feature1: np.ndarray, feature2: np.ndarray) -> float:
        if len(feature1) != len(feature2):
            return 0.0
        dot = np.dot(feature1, feature2)
        norm1 = np.linalg.norm(feature1)
        norm2 = np.linalg.norm(feature2)
        return dot / (norm1 * norm2) if (norm1 * norm2) != 0 else 0.0

    def match_face(self, face_roi: np.ndarray) -> Optional[str]:
        query_feat = self.preprocess_face(face_roi)
        if query_feat is None or not self.face_features:
            return None
        max_sim = 0.0
        matched_name = None
        for name, feat in self.face_features.items():
            sim = self.calculate_similarity(query_feat, feat)
            if sim > max_sim and sim > self.threshold:
                max_sim = sim
                matched_name = name
        return matched_name


class DetectionEngine:
    # ã€å¤ç”¨ä¹‹å‰çš„DetectionEngineç±»ä»£ç ï¼Œæ­¤å¤„çœç•¥ï¼ˆä¿æŒä¸å˜ï¼‰ã€‘
    def __init__(self,
                 model_path: str = "yolov8n.pt",
                 conf_thres: float = 0.5,
                 track_thres: float = 0.4,
                 is_face_model: bool = False):
        self.model = YOLO(model_path)
        self.conf_thres = conf_thres
        self.track_thres = track_thres
        self.class_names = self.model.names
        self.human_class_id = 0
        self.face_class_id = 0 if is_face_model else None

    def detect(self, frame: np.ndarray) -> List:
        if frame is None or frame.size == 0:
            return []
        results = self.model(
            frame,
            conf=self.conf_thres,
            iou=self.track_thres,
            show=False,
            verbose=False
        )
        return results

    def get_largest_human(self, results: List) -> Optional[Tuple[int, int, int, int]]:
        largest_bbox = None
        max_area = 0
        for r in results:
            if not hasattr(r, 'boxes') or r.boxes is None:
                continue
            for box in r.boxes:
                cls = int(box.cls[0])
                if cls == self.human_class_id:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    x1 = max(0, x1)
                    y1 = max(0, y1)
                    x2 = min(frame.shape[1], x2)
                    y2 = min(frame.shape[0], y2)
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area and area > 100:
                        max_area = area
                        largest_bbox = (x1, y1, x2, y2)
        return largest_bbox

    def match_faces(self, frame: np.ndarray, results: List, face_db: FaceDatabase) -> np.ndarray:
        frame_copy = frame.copy()
        h, w = frame_copy.shape[:2]
        for r in results:
            if not hasattr(r, 'boxes') or r.boxes is None:
                continue
            for box in r.boxes:
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                x1 = max(0, x1)
                y1 = max(0, y1)
                x2 = min(w, x2)
                y2 = min(h, y2)
                if self.face_class_id is not None and cls == self.face_class_id:
                    face_roi = frame_copy[y1:y2, x1:x2]
                    name = face_db.match_face(face_roi) or "æœªçŸ¥äººè„¸"
                    frame_copy = self.draw_detection_box(frame_copy, (x1, y1, x2, y2), name, conf)
                elif cls == self.human_class_id:
                    frame_copy = self.draw_detection_box(frame_copy, (x1, y1, x2, y2), "äººä½“", conf)
        return frame_copy

    @staticmethod
    def draw_detection_box(frame: np.ndarray,
                           bbox: Tuple[int, int, int, int],
                           label: str,
                           confidence: float) -> np.ndarray:
        x1, y1, x2, y2 = bbox
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        label_text = f"{label} ({confidence:.2f})"
        font = cv2.FONT_HERSHEY_SIMPLEX
        text_size, _ = cv2.getTextSize(label_text, font, 0.6, 1)
        text_w, text_h = text_size
        bg_x1, bg_y1 = x1, max(y1 - text_h - 10, 0)
        bg_x2, bg_y2 = x1 + text_w, y1
        cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 255, 0), -1)
        cv2.putText(frame, label_text, (x1, bg_y1 + text_h + 2),
                    font, 0.6, (255, 255, 255), 1)
        return frame


# ------------------------------
# ä¸»ç¨‹åºï¼ˆé›†æˆæŒ‰é”®æ“ä½œï¼‰
# ------------------------------
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–ç»„ä»¶
    engine = DetectionEngine(model_path="yolov8n.pt", is_face_model=False)  # å¦‚éœ€äººè„¸æ£€æµ‹ï¼Œåˆ‡æ¢ä¸ºyolov8n-face.pt
    face_db = FaceDatabase(data_dir="my_face_db", threshold=0.6)
    face_db.load_all_faces()  # å¯åŠ¨æ—¶åŠ è½½æ‰€æœ‰å·²ä¿å­˜çš„äººè„¸

    # 2. åˆå§‹åŒ–çŠ¶æ€å˜é‡
    cap = cv2.VideoCapture(0)
    is_paused = False  # æš‚åœçŠ¶æ€
    show_visual = True  # å¯è§†åŒ–æ£€æµ‹æ¡†
    screenshot_dir = "screenshots"
    os.makedirs(screenshot_dir, exist_ok=True)

    # 3. æ‰“å°æ“ä½œæç¤º
    print("=" * 50)
    print("ğŸ“± æ“ä½œæŒ‰é”®è¯´æ˜ï¼š")
    print("   q - é€€å‡ºç¨‹åº")
    print("   s - ä¿å­˜å½“å‰æœ€å¤§äººè„¸åˆ°åº“ï¼ˆéœ€å…ˆæ£€æµ‹åˆ°äººè„¸ï¼‰")
    print("   d - åˆ é™¤æŒ‡å®šå§“åçš„äººè„¸æ•°æ®")
    print("   l - é‡æ–°åŠ è½½æ‰€æœ‰äººè„¸æ•°æ®")
    print("   v - åˆ‡æ¢æ£€æµ‹æ¡†å¯è§†åŒ–ï¼ˆæ˜¾ç¤º/éšè—ï¼‰")
    print("   p - æš‚åœ/ç»§ç»­å®æ—¶æ£€æµ‹")
    print("   f - ä¿å­˜å½“å‰å¸§æˆªå›¾åˆ°screenshotsç›®å½•")
    print("   t - è°ƒæ•´äººè„¸åŒ¹é…é˜ˆå€¼ï¼ˆ0~1ï¼‰")
    print("=" * 50)

    while cap.isOpened():
        # æš‚åœçŠ¶æ€ä¸‹åªå¤„ç†æŒ‰é”®ï¼Œä¸è¯»å–å¸§
        if not is_paused:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢ï¼Œç¨‹åºé€€å‡º")
                break

            # æ‰§è¡Œæ£€æµ‹
            results = engine.detect(frame)
            largest_human_bbox = engine.get_largest_human(results)
            if largest_human_bbox:
                print(f"ğŸ” æ£€æµ‹åˆ°æœ€å¤§äººä½“ï¼š{largest_human_bbox}", end="\r")  # å®æ—¶æ‰“å°ï¼ˆè¦†ç›–è¡Œï¼‰

            # ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆæ ¹æ®å¯è§†åŒ–çŠ¶æ€ï¼‰
            if show_visual:
                frame_display = engine.match_faces(frame, results, face_db)
            else:
                frame_display = frame.copy()
        else:
            frame_display = frame.copy()  # æš‚åœæ—¶ä¿æŒæœ€åä¸€å¸§

        # æ˜¾ç¤ºç”»é¢
        cv2.imshow("ğŸ¤– äººä½“/äººè„¸æ£€æµ‹ç³»ç»Ÿ", frame_display)

        # æŒ‰é”®å“åº”ï¼ˆéé˜»å¡ï¼Œç­‰å¾…1msï¼‰
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            # é€€å‡ºç¨‹åº
            print("\nğŸ‘‹ ç¨‹åºæ­£å¸¸é€€å‡º")
            break
        elif key == ord('p'):
            # æš‚åœ/ç»§ç»­
            is_paused = not is_paused
            status = "æš‚åœ" if is_paused else "ç»§ç»­"
            print(f"\nâ¸ï¸  æ£€æµ‹å·²{status}")
        elif key == ord('v'):
            # åˆ‡æ¢å¯è§†åŒ–
            show_visual = not show_visual
            status = "æ˜¾ç¤º" if show_visual else "éšè—"
            print(f"\nğŸ¨ æ£€æµ‹æ¡†å·²{status}")
        elif key == ord('f'):
            # ä¿å­˜æˆªå›¾
            screenshot_path = os.path.join(screenshot_dir, f"screenshot_{np.datetime64('now').astype(str)}.png")
            cv2.imwrite(screenshot_path, frame_display)
            print(f"\nğŸ“¸ æˆªå›¾å·²ä¿å­˜ï¼š{screenshot_path}")
        elif key == ord('l'):
            # é‡æ–°åŠ è½½äººè„¸
            face_db.load_all_faces()
        elif key == ord('d'):
            # åˆ é™¤äººè„¸ï¼ˆæ§åˆ¶å°è¾“å…¥å§“åï¼‰
            del_name = input("\nğŸ—‘ï¸  è¯·è¾“å…¥è¦åˆ é™¤çš„äººè„¸å§“åï¼š")
            face_db.delete_face(del_name)
        elif key == ord('t'):
            # è°ƒæ•´é˜ˆå€¼
            try:
                new_thresh = float(input("\nğŸ›ï¸  è¯·è¾“å…¥æ–°çš„äººè„¸åŒ¹é…é˜ˆå€¼ï¼ˆ0~1ï¼‰ï¼š"))
                if 0 <= new_thresh <= 1:
                    face_db.threshold = new_thresh
                    print(f"âœ… é˜ˆå€¼å·²æ›´æ–°ä¸ºï¼š{new_thresh}")
                else:
                    print("âŒ é˜ˆå€¼éœ€åœ¨0~1ä¹‹é—´")
            except ValueError:
                print("âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ•°å­—")
        elif key == ord('s'):
            # ä¿å­˜å½“å‰æœ€å¤§äººè„¸ï¼ˆä¼˜å…ˆäººè„¸æ£€æµ‹ï¼Œæ— åˆ™å–äººä½“æ¡†å†…çš„äººè„¸åŒºåŸŸï¼‰
            save_name = input("\nğŸ’¾ è¯·è¾“å…¥è¦ä¿å­˜çš„äººè„¸å§“åï¼š")
            save_remark = input("ğŸ“ è¯·è¾“å…¥å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰ï¼š")

            # å°è¯•è·å–äººè„¸ROIï¼ˆä¼˜å…ˆæ£€æµ‹åˆ°çš„äººè„¸ï¼Œæ— åˆ™å–æœ€å¤§äººä½“çš„ä¸­é—´åŒºåŸŸï¼‰
            face_roi = None
            results = engine.detect(frame)
            # æ–¹å¼1ï¼šå¦‚æœç”¨äº†äººè„¸æ¨¡å‹ï¼Œæå–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
            if engine.face_class_id is not None:
                for r in results:
                    if hasattr(r, 'boxes') and r.boxes is not None:
                        for box in r.boxes:
                            if int(box.cls[0]) == engine.face_class_id:
                                x1, y1, x2, y2 = map(int, box.xyxy[0])
                                face_roi = frame[y1:y2, x1:x2]
                                break
            # æ–¹å¼2ï¼šæ— æ£€æµ‹äººè„¸æ—¶ï¼Œå–æœ€å¤§äººä½“çš„ä¸ŠåŠéƒ¨åˆ†ï¼ˆäººè„¸åŒºåŸŸï¼‰
            if face_roi is None:
                largest_human = engine.get_largest_human(results)
                if largest_human:
                    x1, y1, x2, y2 = largest_human
                    # æˆªå–äººä½“ä¸ŠåŠéƒ¨åˆ†ä½œä¸ºäººè„¸ROIï¼ˆéœ€æ‰‹åŠ¨è°ƒæ•´æ¯”ä¾‹ï¼‰
                    face_h = int((y2 - y1) * 0.3)
                    face_roi = frame[y1:y1 + face_h, x1:x2]

            if face_roi is not None and face_roi.size > 0:
                face_db.save_face(save_name, face_roi, save_remark, overwrite=True)
            else:
                print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆäººè„¸åŒºåŸŸï¼Œä¿å­˜å¤±è´¥")

    # é‡Šæ”¾èµ„æº
    cap.release()
    cv2.destroyAllWindows()