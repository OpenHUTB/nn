import numpy as np
import random
import math
import matplotlib.pyplot as plt

# ===================== å…¨å±€é…ç½®ï¼ˆè§£å†³PyCharmä¸­æ–‡æ˜¾ç¤º/å›¾ç‰‡æ ·å¼ï¼‰ =====================
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']  # å…¼å®¹ä¸åŒç³»ç»Ÿä¸­æ–‡
plt.rcParams['axes.unicode_minus'] = False    # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
plt.rcParams['figure.figsize'] = (14, 9)      # å›¾ç‰‡é»˜è®¤å°ºå¯¸
plt.rcParams['savefig.dpi'] = 300             # ä¿å­˜å›¾ç‰‡çš„åˆ†è¾¨ç‡
plt.rcParams['figure.dpi'] = 100              # æ˜¾ç¤ºå›¾ç‰‡çš„åˆ†è¾¨ç‡

# ===================== 1.11 ç”Ÿæˆæ— äººè½¦åˆ¹è½¦åœºæ™¯æ•°æ® 111=====================
def generate_vehicle_data(n_samples=8000):
    """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆçº¯Pythonå®ç°ï¼Œå«ç‰©ç†æ¨¡å‹+å™ªå£°ï¼‰"""
    random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°
    features = []
    labels = []

    for _ in range(n_samples):
        # æ ¸å¿ƒç‰¹å¾ï¼ˆæ— äººè½¦æ„ŸçŸ¥æ•°æ®ï¼‰
        vehicle_speed = random.uniform(0, 120)       # è½¦é€Ÿ(km/h)
        obstacle_distance = random.uniform(0, 200)   # éšœç¢ç‰©è·ç¦»(m)
        obstacle_speed = random.uniform(-50, 50)     # éšœç¢ç‰©ç›¸å¯¹é€Ÿåº¦(km/h)
        road_friction = random.uniform(0.1, 1.0)     # è·¯é¢æ‘©æ“¦ç³»æ•°ï¼ˆé›¨é›ªå¤©ä½/å¹²ç‡¥é«˜ï¼‰
        weather_visibility = random.uniform(50, 1000)# èƒ½è§åº¦(m)
        brake_delay = random.uniform(0.05, 0.2)      # åˆ¹è½¦ç³»ç»Ÿå»¶è¿Ÿ(s)

        # åˆ¹è½¦æ—¶é—´æ ¸å¿ƒå…¬å¼ï¼ˆç‰©ç†æ¨¡å‹ï¼‰
        base_time = (obstacle_distance / (vehicle_speed/3.6)) * (1/road_friction) - brake_delay
        # ç¯å¢ƒä¿®æ­£é¡¹
        vis_correction = 0.5 if weather_visibility < 200 else 0.1  # ä½èƒ½è§åº¦éœ€æ›´æ—©åˆ¹è½¦
        obs_correction = obstacle_speed / 100                      # éšœç¢ç‰©é€Ÿåº¦ä¿®æ­£
        noise = random.gauss(0, 0.15)                             # é«˜æ–¯å™ªå£°æ¨¡æ‹ŸçœŸå®è¯¯å·®

        # é™åˆ¶åˆ¹è½¦æ—¶é—´åˆç†èŒƒå›´ï¼ˆ0.1~5ç§’ï¼‰
        brake_time = max(0.1, min(base_time + vis_correction + obs_correction + noise, 5.0))

        features.append([vehicle_speed, obstacle_distance, obstacle_speed, road_friction, weather_visibility, brake_delay])
        labels.append(brake_time)

    return np.array(features), np.array(labels)

# ===================== 2. ç‰¹å¾å½’ä¸€åŒ–ï¼ˆçº¯Pythonå®ç°ï¼‰ =====================
class StandardScaler:
    """å‡å€¼-æ ‡å‡†å·®å½’ä¸€åŒ–ï¼Œé€‚é…PyCharmè¿è¡Œ"""
    def __init__(self):
        self.feature_mean = None
        self.feature_std = None

    def fit(self, X):
        """è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®"""
        n_features = X.shape[1]
        self.feature_mean = np.zeros(n_features)
        self.feature_std = np.zeros(n_features)

        for i in range(n_features):
            col_data = X[:, i]
            self.feature_mean[i] = np.mean(col_data)
            self.feature_std[i] = np.std(col_data) + 1e-8  # é¿å…é™¤ä»¥0

    def transform(self, X):
        """åº”ç”¨å½’ä¸€åŒ–"""
        return (X - self.feature_mean) / self.feature_std

# ===================== 3. ç®€åŒ–ç‰ˆå†³ç­–æ ‘å›å½’ï¼ˆæ ¸å¿ƒé¢„æµ‹æ¨¡å‹ï¼‰ =====================
class SimpleDecisionTree:
    """è½»é‡çº§å†³ç­–æ ‘ï¼Œé€‚é…PyCharmä½èµ„æºè¿è¡Œ"""
    def __init__(self, max_depth=3, min_samples=5):
        self.max_depth = max_depth
        self.min_samples = min_samples
        self.tree = {}
        self.feat_importance = np.zeros(6)  # ç‰¹å¾é‡è¦æ€§ï¼ˆ6ä¸ªç‰¹å¾ï¼‰

    def _mse(self, y):
        """è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆå›å½’æŸå¤±ï¼‰"""
        if len(y) == 0:
            return 0.0
        mean_y = np.mean(y)
        return np.mean((y - mean_y) ** 2)

    def _best_split(self, X, y):
        """å¯»æ‰¾æœ€ä¼˜åˆ†å‰²ç‰¹å¾å’Œé˜ˆå€¼"""
        best_feat = -1
        best_thresh = None
        best_mse = self._mse(y)
        n_features = X.shape[1]

        for feat_idx in range(n_features):
            # å»é‡é˜ˆå€¼ï¼Œå‡å°‘è®¡ç®—é‡
            thresholds = np.unique(X[:, feat_idx])[:20]  # é™åˆ¶é˜ˆå€¼æ•°é‡ï¼ŒåŠ é€ŸPyCharmè¿è¡Œ
            for thresh in thresholds:
                # åˆ†å‰²æ•°æ®é›†
                left_mask = X[:, feat_idx] <= thresh
                right_mask = ~left_mask

                # è·³è¿‡æ ·æœ¬æ•°ä¸è¶³çš„åˆ†å‰²
                if len(y[left_mask]) < self.min_samples or len(y[right_mask]) < self.min_samples:
                    continue

                # è®¡ç®—åˆ†å‰²åçš„æ€»MSE
                mse_left = self._mse(y[left_mask])
                mse_right = self._mse(y[right_mask])
                total_mse = (len(y[left_mask]) * mse_left + len(y[right_mask]) * mse_right) / len(y)

                # æ›´æ–°æœ€ä¼˜åˆ†å‰²
                if total_mse < best_mse:
                    best_mse = total_mse
                    best_feat = feat_idx
                    best_thresh = thresh

        # ç´¯è®¡ç‰¹å¾é‡è¦æ€§
        if best_feat != -1:
            self.feat_importance[best_feat] += (self._mse(y) - best_mse) * len(y)
        return best_feat, best_thresh

    def _build_tree(self, X, y, depth):
        """é€’å½’æ„å»ºå†³ç­–æ ‘"""
        # ç»ˆæ­¢æ¡ä»¶ï¼šæ·±åº¦è¾¾æ ‡/æŸå¤±è¶³å¤Ÿå°
        if depth >= self.max_depth or self._mse(y) < 1e-5:
            return {"value": np.mean(y)}

        # å¯»æ‰¾æœ€ä¼˜åˆ†å‰²
        feat_idx, thresh = self._best_split(X, y)
        if feat_idx == -1:
            return {"value": np.mean(y)}

        # åˆ†å‰²æ•°æ®é›†å¹¶é€’å½’æ„å»ºå­æ ‘
        left_mask = X[:, feat_idx] <= thresh
        right_mask = ~left_mask
        left_tree = self._build_tree(X[left_mask], y[left_mask], depth + 1)
        right_tree = self._build_tree(X[right_mask], y[right_mask], depth + 1)

        return {
            "feature": feat_idx,
            "threshold": thresh,
            "left": left_tree,
            "right": right_tree
        }

    def fit(self, X, y):
        """è®­ç»ƒå†³ç­–æ ‘"""
        self.tree = self._build_tree(X, y, depth=0)
        # å½’ä¸€åŒ–ç‰¹å¾é‡è¦æ€§
        self.feat_importance = self.feat_importance / np.sum(self.feat_importance) if np.sum(self.feat_importance) > 0 else self.feat_importance

    def _predict_single(self, x):
        """é¢„æµ‹å•ä¸ªæ ·æœ¬"""
        tree_node = self.tree
        while "feature" in tree_node:
            if x[tree_node["feature"]] <= tree_node["threshold"]:
                tree_node = tree_node["left"]
            else:
                tree_node = tree_node["right"]
        return tree_node["value"]

    def predict(self, X):
        """æ‰¹é‡é¢„æµ‹"""
        return np.array([self._predict_single(x) for x in X])

# ===================== 4. æ¢¯åº¦æå‡å›å½’ï¼ˆé›†æˆæ¨¡å‹ï¼‰ =====================
class GradientBoostRegressor:
    """ç®€åŒ–ç‰ˆæ¢¯åº¦æå‡ï¼Œé€‚é…PyCharmå¿«é€Ÿè¿è¡Œ"""
    def __init__(self, n_trees=80, lr=0.1, max_depth=3):
        self.n_trees = n_trees       # æ ‘çš„æ•°é‡ï¼ˆå‡å°‘æ•°é‡åŠ é€Ÿè¿è¡Œï¼‰
        self.lr = lr                 # å­¦ä¹ ç‡
        self.max_depth = max_depth   # æ ‘æ·±åº¦
        self.trees = []              # ä¿å­˜æ‰€æœ‰æ ‘
        self.base_pred = None        # åˆå§‹é¢„æµ‹å€¼
        self.total_feat_importance = np.zeros(6)  # æ€»ç‰¹å¾é‡è¦æ€§

    def fit(self, X, y):
        """è®­ç»ƒæ¢¯åº¦æå‡æ¨¡å‹"""
        # åˆå§‹é¢„æµ‹ï¼šæ‰€æœ‰æ ·æœ¬çš„å‡å€¼
        self.base_pred = np.mean(y)
        y_pred = np.full(len(y), self.base_pred)

        print("æ¨¡å‹è®­ç»ƒè¿›åº¦ï¼š")
        for i in range(self.n_trees):
            # è®¡ç®—æ®‹å·®ï¼ˆè´Ÿæ¢¯åº¦ï¼‰
            residual = y - y_pred

            # è®­ç»ƒä¸€æ£µå†³ç­–æ ‘æ‹Ÿåˆæ®‹å·®
            tree = SimpleDecisionTree(max_depth=self.max_depth)
            tree.fit(X, residual)

            # ç´¯åŠ ç‰¹å¾é‡è¦æ€§
            self.total_feat_importance += tree.feat_importance

            # æ›´æ–°é¢„æµ‹å€¼
            tree_pred = tree.predict(X)
            y_pred += self.lr * tree_pred
            self.trees.append(tree)

            # æ‰“å°è®­ç»ƒè¿›åº¦ï¼ˆPyCharmæ§åˆ¶å°å¯è§ï¼‰
            if (i + 1) % 20 == 0:
                mse = np.mean((y - y_pred) ** 2)
                print(f"  å®Œæˆ {i+1}/{self.n_trees} æ£µæ ‘ï¼Œå½“å‰MSEï¼š{mse:.4f}")

        # å½’ä¸€åŒ–æ€»ç‰¹å¾é‡è¦æ€§
        self.total_feat_importance = self.total_feat_importance / np.sum(self.total_feat_importance) if np.sum(self.total_feat_importance) > 0 else self.total_feat_importance

    def predict(self, X):
        """é¢„æµ‹åˆ¹è½¦æ—¶é—´"""
        y_pred = np.full(len(X), self.base_pred)
        for tree in self.trees:
            y_pred += self.lr * tree.predict(X)
        return y_pred

# ===================== 5. å¯è§†åŒ–ç»˜å›¾å‡½æ•°ï¼ˆPyCharmä¸“ç”¨ï¼‰ =====================
def plot_results(y_true, y_pred, feat_importance, X_test):
    """ç”Ÿæˆ4å¼ å­å›¾ï¼Œåœ¨PyCharmä¸­æ˜¾ç¤ºå¹¶ä¿å­˜"""
    # åˆ›å»º2x2å­å›¾å¸ƒå±€
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 9))

    # å­å›¾1ï¼šçœŸå®å€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾
    ax1.scatter(y_true, y_pred, color="#2E86AB", alpha=0.6, s=8)
    ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], "r--", linewidth=2, label="å®Œç¾é¢„æµ‹çº¿")
    ax1.set_xlabel("çœŸå®åˆ¹è½¦æ—¶é—´ (ç§’)", fontsize=10)
    ax1.set_ylabel("é¢„æµ‹åˆ¹è½¦æ—¶é—´ (ç§’)", fontsize=10)
    ax1.set_title("åˆ¹è½¦æ—¶é—´ï¼šçœŸå®å€¼ vs é¢„æµ‹å€¼", fontsize=12, fontweight="bold")
    ax1.legend()
    ax1.grid(alpha=0.3)

    # å­å›¾2ï¼šç‰¹å¾é‡è¦æ€§æŸ±çŠ¶å›¾
    feat_names = ["è½¦é€Ÿ", "éšœç¢ç‰©è·ç¦»", "éšœç¢ç‰©é€Ÿåº¦", "è·¯é¢æ‘©æ“¦", "èƒ½è§åº¦", "åˆ¹è½¦å»¶è¿Ÿ"]
    ax2.bar(feat_names, feat_importance, color="#A23B72", alpha=0.8)
    ax2.set_xlabel("ç‰¹å¾åç§°", fontsize=10)
    ax2.set_ylabel("é‡è¦æ€§æƒé‡", fontsize=10)
    ax2.set_title("ç‰¹å¾é‡è¦æ€§æ’å", fontsize=12, fontweight="bold")
    ax2.tick_params(axis="x", rotation=30)  # æ—‹è½¬xè½´æ ‡ç­¾ï¼Œé¿å…é‡å 
    ax2.grid(alpha=0.3, axis="y")

    # å­å›¾3ï¼šé¢„æµ‹è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
    error = y_true - y_pred
    ax3.hist(error, bins=40, color="#F18F01", alpha=0.7, edgecolor="black", linewidth=0.5)
    ax3.axvline(x=0, color="red", linestyle="--", linewidth=2, label="æ— è¯¯å·®çº¿")
    ax3.set_xlabel("é¢„æµ‹è¯¯å·® (ç§’)", fontsize=10)
    ax3.set_ylabel("æ ·æœ¬æ•°é‡", fontsize=10)
    ax3.set_title("é¢„æµ‹è¯¯å·®åˆ†å¸ƒ", fontsize=12, fontweight="bold")
    ax3.legend()
    ax3.grid(alpha=0.3)

    # å­å›¾4ï¼šä¸åŒè·¯é¢æ‘©æ“¦ç³»æ•°çš„åˆ¹è½¦æ—¶é—´ç®±çº¿å›¾
    friction_bins = [0.1, 0.4, 0.7, 1.0]
    friction_labels = ["ä½æ‘©æ“¦(é›¨é›ª)", "ä¸­æ‘©æ“¦", "é«˜æ‘©æ“¦(å¹²ç‡¥)"]
    friction_groups = []
    for i in range(3):
        mask = (X_test[:, 3] >= friction_bins[i]) & (X_test[:, 3] < friction_bins[i+1])
        friction_groups.append(y_true[mask])

    box_plot = ax4.boxplot(friction_groups, labels=friction_labels, patch_artist=True)
    for patch in box_plot["boxes"]:
        patch.set_facecolor("#C73E1D")
        patch.set_alpha(0.7)
    ax4.set_xlabel("è·¯é¢æ‘©æ“¦ç³»æ•°åŒºé—´", fontsize=10)
    ax4.set_ylabel("åˆ¹è½¦æ—¶é—´ (ç§’)", fontsize=10)
    ax4.set_title("ä¸åŒè·¯é¢æ‘©æ“¦çš„åˆ¹è½¦æ—¶é—´åˆ†å¸ƒ", fontsize=12, fontweight="bold")
    ax4.grid(alpha=0.3, axis="y")

    # è°ƒæ•´å­å›¾é—´è·ï¼ˆé¿å…æ ‡ç­¾é‡å ï¼‰
    plt.tight_layout(pad=2.0)

    # å…³é”®ï¼šåœ¨PyCharmä¸­æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå†…ç½®Plotçª—å£ï¼‰
    plt.show()

    # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°ï¼ˆä»£ç åŒçº§ç›®å½•ï¼‰
    fig.savefig("æ— äººè½¦åˆ¹è½¦æ—¶é—´åˆ†æå›¾.png", dpi=300, bbox_inches="tight")
    print("\nâœ… åˆ†æå›¾ç‰‡å·²ä¿å­˜ä¸ºï¼šæ— äººè½¦åˆ¹è½¦æ—¶é—´åˆ†æå›¾.png")

# ===================== 6. ä¸»å‡½æ•°ï¼ˆPyCharmè¿è¡Œå…¥å£ï¼‰ =====================
if __name__ == "__main__":
    print("="*50)
    print("        æ— äººè½¦ç´§æ€¥åˆ¹è½¦æ—¶é—´é¢„æµ‹æ¨¡å‹ï¼ˆPyCharmä¸“ç”¨ï¼‰        ")
    print("="*50)

    # 1. ç”Ÿæˆæ•°æ®é›†
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†...")
    X, y = generate_vehicle_data(n_samples=8000)  # å‡å°‘æ ·æœ¬æ•°åŠ é€Ÿè¿è¡Œ

    # 2. åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆ8:2ï¼‰
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›†{len(X_train)}æ¡ï¼Œæµ‹è¯•é›†{len(X_test)}æ¡")

    # 3. ç‰¹å¾å½’ä¸€åŒ–
    print("\nğŸ”§ æ­£åœ¨è¿›è¡Œç‰¹å¾å½’ä¸€åŒ–...")
    scaler = StandardScaler()
    scaler.fit(X_train)
    X_train_scaled = scaler.transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # 4. è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ æ­£åœ¨è®­ç»ƒæ¢¯åº¦æå‡æ¨¡å‹...")
    model = GradientBoostRegressor(n_trees=80, lr=0.1, max_depth=3)
    model.fit(X_train_scaled, y_train)

    # 5. æ¨¡å‹è¯„ä¼°
    print("\nğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
    y_pred = model.predict(X_test_scaled)
    mae = np.mean(np.abs(y_test - y_pred))  # å¹³å‡ç»å¯¹è¯¯å·®
    r2 = 1 - (np.sum((y_test - y_pred)**2) / np.sum((y_test - np.mean(y_test))**2))  # å†³å®šç³»æ•°
    print(f"  å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ï¼š{mae:.4f} ç§’ï¼ˆè¶Šå°è¶Šå¥½ï¼‰")
    print(f"  å†³å®šç³»æ•°ï¼ˆRÂ²ï¼‰ï¼š{r2:.4f}ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰")

    # 6. ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡ï¼ˆPyCharmæ˜¾ç¤º+æœ¬åœ°ä¿å­˜ï¼‰
    print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆåˆ†æå›¾ç‰‡...")
    plot_results(y_test, y_pred, model.total_feat_importance, X_test)

    # 7. å®æ—¶é¢„æµ‹ç¤ºä¾‹ï¼ˆæ¨¡æ‹Ÿæ— äººè½¦å®æ—¶æ„ŸçŸ¥æ•°æ®ï¼‰
    print("\nğŸ” å®æ—¶åˆ¹è½¦æ—¶é—´é¢„æµ‹ç¤ºä¾‹ï¼š")
    def predict_brake_time(vehicle_state):
        """è¾“å…¥è½¦è¾†çŠ¶æ€ï¼Œé¢„æµ‹åˆ¹è½¦æ—¶é—´"""
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        state_arr = np.array([list(vehicle_state.values())])
        state_scaled = scaler.transform(state_arr)
        # é¢„æµ‹å¹¶é™åˆ¶èŒƒå›´a
        brake_time = model.predict(state_scaled)[0]
        return max(0.1, min(brake_time, 5.0))

    # æ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼šé«˜é€Ÿ+å¹²ç‡¥è·¯é¢+è¿‘è·ç¦»éšœç¢ç‰©
    test_state = {
        "vehicle_speed": 90.0,       # è½¦é€Ÿ90km/h
        "obstacle_distance": 70.0,   # éšœç¢ç‰©è·ç¦»70m
        "obstacle_speed": 8.0,       # éšœç¢ç‰©åŒå‘8km/h
        "road_friction": 0.8,        # å¹²ç‡¥è·¯é¢æ‘©æ“¦ç³»æ•°
        "weather_visibility": 600.0, # èƒ½è§åº¦600m
        "brake_delay": 0.12          # åˆ¹è½¦ç³»ç»Ÿå»¶è¿Ÿ0.12s
    }

    # é¢„æµ‹å¹¶è¾“å‡ºç»“æœ
    pred_time = predict_brake_time(test_state)
    print("ğŸ“Œ æµ‹è¯•åœºæ™¯ï¼šé«˜é€Ÿå¹²ç‡¥è·¯é¢+è¿‘è·ç¦»éšœç¢ç‰©")
    for k, v in test_state.items():
        print(f"  {k}ï¼š{v}")
    print(f"âœ… é¢„æµ‹ç´§æ€¥åˆ¹è½¦æ—¶é—´ï¼š{pred_time:.2f} ç§’")
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")