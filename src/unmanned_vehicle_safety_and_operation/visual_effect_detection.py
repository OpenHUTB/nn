import numpy as np
import matplotlib.pyplot as plt
import os
import warnings
from PIL import Image, ImageFilter, ImageStat

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆè§£å†³PyCharmä¸­matplotlibä¸­æ–‡æ˜¾ç¤ºä¹±ç ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei']  # é»‘ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜


# ===================== 1. ç‰¹å¾æå–å‡½æ•°ï¼ˆä¿ç•™ï¼Œå…¼å®¹çœŸå®å›¾åƒï¼‰ =====================
class RainFogFeatureExtractor:
    def __init__(self):
        pass

    def calculate_fog_density(self, img):
        gray = img.convert('L')
        min_filtered = gray.filter(ImageFilter.MinFilter(size=15))
        gray_array = np.array(min_filtered)
        fog_density = np.mean(gray_array) / 255.0
        return fog_density

    def calculate_contrast(self, img):
        gray = img.convert('L')
        stat = ImageStat.Stat(gray)
        contrast = stat.stddev[0]
        return contrast

    def calculate_edge_density(self, img):
        gray = img.convert('L')
        edges = gray.filter(ImageFilter.FIND_EDGES)
        edge_array = np.array(edges)
        edge_density = np.sum(edge_array > 0) / (img.width * img.height)
        return edge_density

    def calculate_color_saturation(self, img):
        hsv = img.convert('HSV')
        sat_band = hsv.getchannel(1)
        sat_array = np.array(sat_band)
        sat_mean = np.mean(sat_array) / 255.0
        return sat_mean

    def extract_all_features(self, img_path):
        try:
            with Image.open(img_path) as img:
                img = img.resize((640, 480))
                if img.mode != 'RGB':
                    img = img.convert('RGB')

                features = [
                    self.calculate_fog_density(img),
                    self.calculate_contrast(img),
                    self.calculate_edge_density(img),
                    self.calculate_color_saturation(img)
                ]
                features = np.array(features)
                features[1] = features[1] / 255.0
                return features
        except Exception as e:
            return None


# ===================== 2. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›† =====================
def build_dataset():
    """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆæ— éœ€çœŸå®å›¾åƒï¼‰"""
    np.random.seed(42)
    n_samples_per_class = 100  # æ¯ç±»100ä¸ªæ ·æœ¬

    # æ¸…æ™°æ ·æœ¬ï¼ˆæ ‡ç­¾0ï¼‰
    clear_fog = np.random.normal(0.1, 0.05, n_samples_per_class)
    clear_contrast = np.random.normal(0.8, 0.1, n_samples_per_class)
    clear_edge = np.random.normal(0.2, 0.05, n_samples_per_class)
    clear_sat = np.random.normal(0.8, 0.1, n_samples_per_class)
    clear_features = np.column_stack([clear_fog, clear_contrast, clear_edge, clear_sat])
    clear_labels = np.zeros(n_samples_per_class)

    # è½»åº¦é›¨é›¾ï¼ˆæ ‡ç­¾1ï¼‰
    light_fog = np.random.normal(0.3, 0.05, n_samples_per_class)
    light_contrast = np.random.normal(0.6, 0.1, n_samples_per_class)
    light_edge = np.random.normal(0.15, 0.05, n_samples_per_class)
    light_sat = np.random.normal(0.6, 0.1, n_samples_per_class)
    light_features = np.column_stack([light_fog, light_contrast, light_edge, light_sat])
    light_labels = np.ones(n_samples_per_class)

    # ä¸­åº¦é›¨é›¾ï¼ˆæ ‡ç­¾2ï¼‰
    medium_fog = np.random.normal(0.5, 0.05, n_samples_per_class)
    medium_contrast = np.random.normal(0.4, 0.1, n_samples_per_class)
    medium_edge = np.random.normal(0.1, 0.05, n_samples_per_class)
    medium_sat = np.random.normal(0.4, 0.1, n_samples_per_class)
    medium_features = np.column_stack([medium_fog, medium_contrast, medium_edge, medium_sat])
    medium_labels = np.ones(n_samples_per_class) * 2

    # é‡åº¦é›¨é›¾ï¼ˆæ ‡ç­¾3ï¼‰
    heavy_fog = np.random.normal(0.8, 0.05, n_samples_per_class)
    heavy_contrast = np.random.normal(0.2, 0.1, n_samples_per_class)
    heavy_edge = np.random.normal(0.05, 0.05, n_samples_per_class)
    heavy_sat = np.random.normal(0.2, 0.1, n_samples_per_class)
    heavy_features = np.column_stack([heavy_fog, heavy_contrast, heavy_edge, heavy_sat])
    heavy_labels = np.ones(n_samples_per_class) * 3

    # åˆå¹¶æ•°æ®å¹¶é™åˆ¶èŒƒå›´
    X = np.vstack([clear_features, light_features, medium_features, heavy_features])
    y = np.hstack([clear_labels, light_labels, medium_labels, heavy_labels])
    X = np.clip(X, 0, 1)
    feature_names = ['é›¾åº¦', 'å¯¹æ¯”åº¦', 'è¾¹ç¼˜å¯†åº¦', 'é¥±å’Œåº¦']

    print(f"æ¨¡æ‹Ÿæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼šæ€»æ ·æœ¬æ•°={len(X)}, ç‰¹å¾æ•°={X.shape[1]}")
    return X, y, feature_names


# ===================== 3. ç®€æ˜“Kè¿‘é‚»åˆ†ç±»å™¨ =====================
class SimpleKNNClassifier:
    def __init__(self, k=5):
        self.k = k
        self.X_train = None
        self.y_train = None

    def fit(self, X, y):
        self.X_train = X
        self.y_train = y

    def _euclidean_distance(self, x1, x2):
        return np.sqrt(np.sum((x1 - x2) ** 2))

    def predict(self, X):
        predictions = []
        for x in X:
            distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]
            k_indices = np.argsort(distances)[:self.k]
            k_nearest_labels = [self.y_train[i] for i in k_indices]
            pred_label = max(set(k_nearest_labels), key=k_nearest_labels.count)
            predictions.append(pred_label)
        return np.array(predictions)

    def predict_proba(self, X):
        probas = []
        for x in X:
            distances = [self._euclidean_distance(x, x_train) for x_train in self.X_train]
            k_indices = np.argsort(distances)[:self.k]
            k_nearest_labels = [self.y_train[i] for i in k_indices]

            label_counts = {0: 0, 1: 0, 2: 0, 3: 0}
            for label in k_nearest_labels:
                label_counts[label] += 1
            total = sum(label_counts.values())
            proba = [label_counts[i] / total for i in range(4)]
            probas.append(proba)
        return np.array(probas)


# ===================== 4. æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–ï¼ˆæ ¸å¿ƒï¼šç”Ÿæˆå›¾ç‰‡ï¼‰ =====================
def evaluate_and_visualize(model, X_train, X_test, y_train, y_test, feature_names):
    """è¯„ä¼°æ¨¡å‹å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡"""
    # 1. è®¡ç®—è®­ç»ƒ/æµ‹è¯•å‡†ç¡®ç‡
    train_pred = model.predict(X_train)
    train_acc = np.sum(train_pred == y_train) / len(y_train)
    test_pred = model.predict(X_test)
    test_acc = np.sum(test_pred == y_test) / len(y_test)

    # 2. ç”Ÿæˆå›¾1ï¼šè®­ç»ƒ/æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”å›¾
    plt.figure(figsize=(8, 5))
    plt.bar(['è®­ç»ƒé›†å‡†ç¡®ç‡', 'æµ‹è¯•é›†å‡†ç¡®ç‡'], [train_acc, test_acc], color=['#2E86AB', '#A23B72'])
    plt.ylim(0, 1.1)
    plt.title('æ— äººè½¦é›¨é›¾æ£€æµ‹æ¨¡å‹å‡†ç¡®ç‡', fontsize=14)
    plt.ylabel('å‡†ç¡®ç‡', fontsize=12)
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    plt.text(0, train_acc + 0.02, f'{train_acc:.4f}', ha='center', fontsize=12)
    plt.text(1, test_acc + 0.02, f'{test_acc:.4f}', ha='center', fontsize=12)
    plt.tight_layout()
    plt.savefig('./rainfog_acc.png', dpi=150, bbox_inches='tight')  # ä¿å­˜å›¾ç‰‡
    print("âœ… å‡†ç¡®ç‡å¯¹æ¯”å›¾å·²ä¿å­˜ï¼šrainfog_acc.png")

    # 3. ç”Ÿæˆå›¾2ï¼šç‰¹å¾åˆ†å¸ƒæ•£ç‚¹å›¾ï¼ˆé›¾åº¦ vs å¯¹æ¯”åº¦ï¼‰
    plt.figure(figsize=(10, 8))
    colors = ['#F18F01', '#C73E1D', '#8B0000', '#000000']  # æ¸…æ™°/è½»åº¦/ä¸­åº¦/é‡åº¦é¢œè‰²
    labels = ['æ¸…æ™°', 'è½»åº¦é›¨é›¾', 'ä¸­åº¦é›¨é›¾', 'é‡åº¦é›¨é›¾']
    for i in range(4):
        mask = y_train == i
        plt.scatter(X_train[mask, 0], X_train[mask, 1], c=colors[i], label=labels[i], alpha=0.7)
    plt.xlabel('é›¾åº¦', fontsize=12)
    plt.ylabel('å¯¹æ¯”åº¦', fontsize=12)
    plt.title('é›¨é›¾å¤©å›¾åƒç‰¹å¾åˆ†å¸ƒï¼ˆé›¾åº¦ vs å¯¹æ¯”åº¦ï¼‰', fontsize=14)
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig('./rainfog_feature_dist.png', dpi=150, bbox_inches='tight')
    print("âœ… ç‰¹å¾åˆ†å¸ƒå›¾å·²ä¿å­˜ï¼šrainfog_feature_dist.png")

    # 4. ç”Ÿæˆå›¾3ï¼šå„åˆ†ç±»å‡†ç¡®ç‡è¯¦æƒ…
    plt.figure(figsize=(10, 6))
    class_acc = []
    for label in range(4):
        mask = y_test == label
        if np.sum(mask) == 0:
            class_acc.append(0)
            continue
        acc = np.sum((test_pred == label) & mask) / np.sum(mask)
        class_acc.append(acc)

    plt.bar(labels, class_acc, color=['#F18F01', '#C73E1D', '#8B0000', '#000000'])
    plt.ylim(0, 1.1)
    plt.title('å„é›¨é›¾ç­‰çº§æ£€æµ‹å‡†ç¡®ç‡', fontsize=14)
    plt.ylabel('å‡†ç¡®ç‡', fontsize=12)
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, acc in enumerate(class_acc):
        plt.text(i, acc + 0.02, f'{acc:.4f}', ha='center', fontsize=12)
    plt.tight_layout()
    plt.savefig('./rainfog_class_acc.png', dpi=150, bbox_inches='tight')
    print("âœ… åˆ†ç±»å‡†ç¡®ç‡å›¾å·²ä¿å­˜ï¼šrainfog_class_acc.png")

    # è¾“å‡ºè¯„ä¼°ç»“æœ
    print("\n===== æ¨¡å‹è¯„ä¼°ç»“æœ =====")
    print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc:.4f}")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f}")
    print("\nå„ç­‰çº§æ£€æµ‹å‡†ç¡®ç‡ï¼š")
    for i, label in enumerate(labels):
        print(f"  {label}: {class_acc[i]:.4f}")

    return train_acc, test_acc


# ===================== 5. æ¨¡æ‹Ÿå•å¼ å›¾åƒé¢„æµ‹ =====================
def predict_simulated_image(feature_type, model):
    """æ¨¡æ‹Ÿå•å¼ å›¾åƒé¢„æµ‹"""
    np.random.seed(42)
    feature_map = {
        'clear': np.array([0.12, 0.78, 0.21, 0.82]),
        'light': np.array([0.28, 0.62, 0.16, 0.61]),
        'medium': np.array([0.52, 0.41, 0.09, 0.39]),
        'heavy': np.array([0.79, 0.22, 0.04, 0.18])
    }
    features = feature_map.get(feature_type, feature_map['heavy'])

    X = features.reshape(1, -1)
    pred_label = model.predict(X)[0]
    pred_proba = model.predict_proba(X)[0]

    label_map = {0: 'æ¸…æ™°', 1: 'è½»åº¦é›¨é›¾', 2: 'ä¸­åº¦é›¨é›¾', 3: 'é‡åº¦é›¨é›¾'}
    result = {
        'é¢„æµ‹ç­‰çº§': label_map[pred_label],
        'ç½®ä¿¡åº¦': {
            'æ¸…æ™°': f"{pred_proba[0]:.4f}",
            'è½»åº¦é›¨é›¾': f"{pred_proba[1]:.4f}",
            'ä¸­åº¦é›¨é›¾': f"{pred_proba[2]:.4f}",
            'é‡åº¦é›¨é›¾': f"{pred_proba[3]:.4f}"
        },
        'åŸå§‹ç‰¹å¾': {
            'é›¾åº¦': features[0],
            'å¯¹æ¯”åº¦': features[1],
            'è¾¹ç¼˜å¯†åº¦': features[2],
            'é¥±å’Œåº¦': features[3]
        }
    }
    return result


# ===================== ä¸»å‡½æ•°ï¼ˆPyCharmå…¥å£ï¼‰ =====================
if __name__ == "__main__":
    # åˆ›å»ºä¿å­˜å›¾ç‰‡çš„ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.path.exists('./'):
        os.makedirs('./')

    try:
        print("===== æ— äººè½¦é›¨é›¾å¤©è§†è§‰æ•ˆæœæ£€æµ‹ç¨‹åºï¼ˆPyCharmç‰ˆï¼‰ =====")

        # 1. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†
        print("\nã€1/4ã€‘ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†...")
        X, y, feature_names = build_dataset()

        # 2. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
        print("\nã€2/4ã€‘åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†...")
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        print(f"è®­ç»ƒé›†ï¼š{len(X_train)} æ ·æœ¬ï¼Œæµ‹è¯•é›†ï¼š{len(X_test)} æ ·æœ¬")

        # 3. è®­ç»ƒKNNæ¨¡å‹11
        print("\nã€3/4ã€‘è®­ç»ƒé›¨é›¾æ£€æµ‹æ¨¡å‹...")
        model = SimpleKNNClassifier(k=5)
        model.fit(X_train, y_train)

        # 4. è¯„ä¼°æ¨¡å‹å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡1112
        print("\nã€4/4ã€‘è¯„ä¼°æ¨¡å‹å¹¶ç”Ÿæˆå›¾ç‰‡...")
        train_acc, test_acc = evaluate_and_visualize(model, X_train, X_test, y_train, y_test, feature_names)

        # 5. æ¨¡æ‹Ÿé¢„æµ‹ï¼ˆé‡åº¦é›¨é›¾ï¼‰11
        print("\n===== å•å¼ å›¾åƒé¢„æµ‹ç¤ºä¾‹ï¼ˆé‡åº¦é›¨é›¾ï¼‰ =====")
        result = predict_simulated_image('heavy', model)
        for k, v in result.items():
            print(f"  {k}: {v}")

        # é¢å¤–æµ‹è¯•ï¼šé¢„æµ‹è½»åº¦é›¨é›¾
        print("\n===== å•å¼ å›¾åƒé¢„æµ‹ç¤ºä¾‹ï¼ˆè½»åº¦é›¨é›¾ï¼‰ =====")
        result_light = predict_simulated_image('light', model)
        for k, v in result_light.items():
            print(f"  {k}: {v}")

        print("\nğŸ‰ ç¨‹åºè¿è¡Œå®Œæˆï¼ç”Ÿæˆçš„å›¾ç‰‡ï¼š")
        print("  - rainfog_acc.pngï¼ˆå‡†ç¡®ç‡å¯¹æ¯”å›¾ï¼‰")
        print("  - rainfog_feature_dist.pngï¼ˆç‰¹å¾åˆ†å¸ƒå›¾ï¼‰")
        print("  - rainfog_class_acc.pngï¼ˆåˆ†ç±»å‡†ç¡®ç‡å›¾ï¼‰")

    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™ï¼š{e}")
        # æ‰“å°è¯¦ç»†é”™è¯¯æ ˆï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
        import traceback

        traceback.print_exc()