import numpy as np
import os
import matplotlib.pyplot as plt
from PIL import Image
import warnings

warnings.filterwarnings('ignore')

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆé€‚é…PyCharmå·¥ä½œç›®å½•ï¼‰ =====================
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆPyCharmä¸­ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_PATH = os.path.join(BASE_DIR, "traffic_signs")  # æ•°æ®é›†è·¯å¾„
TEST_IMG_PATH = os.path.join(BASE_DIR, "test_sign.png")  # æµ‹è¯•å›¾ç‰‡è·¯å¾„
CONFUSION_MATRIX_PATH = os.path.join(BASE_DIR, "confusion_matrix.png")  # æ··æ·†çŸ©é˜µä¿å­˜è·¯å¾„


# ===================== 1. è‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†ï¼ˆPyCharmå‹å¥½ï¼‰ =====================
def create_simulated_dataset():
    """
    è‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿäº¤é€šæ ‡å¿—æ•°æ®é›†
    è·¯å¾„ï¼šå½“å‰è„šæœ¬ç›®å½•/traffic_signs/
    """
    # åˆ›å»ºæ•°æ®é›†æ ¹ç›®å½•
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
        print(f"åˆ›å»ºæ•°æ®é›†ç›®å½•ï¼š{DATA_PATH}")

    # å®šä¹‰3ç±»äº¤é€šæ ‡å¿—
    categories = ["stop_sign", "speed_limit_50", "yield_sign"]
    n_samples_per_class = 50  # æ¯ç±»ç”Ÿæˆ50å¼ å›¾ç‰‡

    # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆå›¾ç‰‡
    for cat in categories:
        cat_dir = os.path.join(DATA_PATH, cat)
        if not os.path.exists(cat_dir):
            os.makedirs(cat_dir)

        # ç”Ÿæˆä¸åŒç‰¹å¾çš„æ¨¡æ‹Ÿç°åº¦å›¾ï¼ˆåŒºåˆ†ä¸åŒç±»åˆ«ï¼‰
        for i in range(n_samples_per_class):
            # ä¸åŒç±»åˆ«è®¾ç½®ä¸åŒçš„åƒç´ åˆ†å¸ƒï¼ˆä¾¿äºæ¨¡å‹åŒºåˆ†ï¼‰
            if cat == "stop_sign":
                img_arr = np.random.normal(0.8, 0.08, (64, 64))  # åäº®
            elif cat == "speed_limit_50":
                img_arr = np.random.normal(0.4, 0.08, (64, 64))  # ä¸­ç­‰äº®åº¦
            else:  # yield_sign
                img_arr = np.random.normal(0.2, 0.08, (64, 64))  # åæš—

            # å½’ä¸€åŒ–åˆ°0-255å¹¶è½¬ä¸ºuint8æ ¼å¼
            img_arr = np.clip(img_arr * 255, 0, 255).astype(np.uint8)
            # ä¿å­˜å›¾ç‰‡ï¼ˆPNGæ ¼å¼ï¼Œå…¼å®¹PILï¼‰
            img = Image.fromarray(img_arr, mode='L')
            img.save(os.path.join(cat_dir, f"{cat}_{i}.png"))

    print(f"\nâœ… æ¨¡æ‹Ÿæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“‚ æ•°æ®é›†è·¯å¾„ï¼š{DATA_PATH}")
    print(f"ğŸ“Š åŒ…å«ç±»åˆ«ï¼š{categories}ï¼ˆæ¯ç±»{n_samples_per_class}å¼ ï¼‰")


# ===================== 2. çº¯Numpyå®ç°HOGç‰¹å¾æå– =====================
def hog_feature_extract(img):
    """
    è¾“å…¥ï¼š64x64å½’ä¸€åŒ–ç°åº¦å›¾ï¼ˆ0-1ï¼‰
    è¾“å‡ºï¼šHOGç‰¹å¾å‘é‡
    """
    # 1. è®¡ç®—x/yæ–¹å‘æ¢¯åº¦
    gx = np.zeros_like(img, dtype=np.float32)
    gy = np.zeros_like(img, dtype=np.float32)
    gx[:, :-1] = img[:, 1:] - img[:, :-1]
    gy[:-1, :] = img[1:, :] - img[:-1, :]

    # 2. è®¡ç®—æ¢¯åº¦å¹…å€¼å’Œæ–¹å‘ï¼ˆ0-180åº¦ï¼‰
    magnitude = np.sqrt(gx ** 2 + gy ** 2)
    orientation = np.arctan2(gy, gx) * (180 / np.pi) % 180

    # 3. åˆ†Cellè®¡ç®—æ¢¯åº¦ç›´æ–¹å›¾ï¼ˆ8x8åƒç´ /Cellï¼Œ9ä¸ªæ–¹å‘ï¼‰
    cell_size = 8
    orientations = 9
    orient_bin = 180 / orientations
    n_cells = 64 // cell_size  # 8ä¸ªCellï¼ˆ64/8ï¼‰

    cell_hist = np.zeros((n_cells, n_cells, orientations), dtype=np.float32)
    for y in range(n_cells):
        for x in range(n_cells):
            # æå–å½“å‰Cellçš„æ¢¯åº¦
            cell_mag = magnitude[y * cell_size:(y + 1) * cell_size, x * cell_size:(x + 1) * cell_size]
            cell_orient = orientation[y * cell_size:(y + 1) * cell_size, x * cell_size:(x + 1) * cell_size]

            # ç»Ÿè®¡æ¯ä¸ªæ–¹å‘çš„æ¢¯åº¦å’Œ
            for bin_idx in range(orientations):
                bin_min = bin_idx * orient_bin
                bin_max = (bin_idx + 1) * orient_bin
                mask = (cell_orient >= bin_min) & (cell_orient < bin_max)
                cell_hist[y, x, bin_idx] = np.sum(cell_mag[mask])

    # 4. åˆ†Blockå½’ä¸€åŒ–ï¼ˆ2x2 Cell/Blockï¼ŒL2-Hyså½’ä¸€åŒ–ï¼‰
    block_size = 2
    n_blocks = n_cells - block_size + 1  # 7ä¸ªBlock
    hog_feat = []

    for y in range(n_blocks):
        for x in range(n_blocks):
            block = cell_hist[y:y + block_size, x:x + block_size, :].flatten()
            # L2å½’ä¸€åŒ–ï¼ˆåŠ å°å€¼é¿å…é™¤é›¶ï¼‰
            norm = np.sqrt(np.sum(block ** 2) + 1e-6)
            block = block / norm
            # Hysæˆªæ–­ï¼ˆé™åˆ¶æœ€å¤§å€¼0.2ï¼‰
            block = np.clip(block, 0, 0.2)
            # å†æ¬¡å½’ä¸€åŒ–
            norm = np.sqrt(np.sum(block ** 2) + 1e-6)
            block = block / norm
            hog_feat.extend(block)

    return np.array(hog_feat, dtype=np.float32)


# ===================== 3. ç®€åŒ–ç‰ˆSVMåˆ†ç±»å™¨ï¼ˆå¤šåˆ†ç±»ï¼‰ =====================
class SimpleSVM:
    def __init__(self, lr=0.001, lambda_param=0.01, n_iters=800):
        self.lr = lr  # å­¦ä¹ ç‡
        self.lambda_param = lambda_param  # æ­£åˆ™åŒ–ç³»æ•°
        self.n_iters = n_iters  # è¿­ä»£æ¬¡æ•°
        self.weights = None  # ç±»åˆ«æƒé‡
        self.biases = None  # ç±»åˆ«åç½®
        self.classes = None  # ç±»åˆ«åˆ—è¡¨

    def fit(self, X, y):
        """è®­ç»ƒå¤šåˆ†ç±»SVMï¼ˆä¸€å¯¹å…¶ä½™ç­–ç•¥ï¼‰"""
        self.classes = np.unique(y)
        n_classes = len(self.classes)
        n_samples, n_feat = X.shape

        # åˆå§‹åŒ–æƒé‡å’Œåç½®
        self.weights = np.zeros((n_classes, n_feat))
        self.biases = np.zeros(n_classes)

        print("\nğŸš€ å¼€å§‹è®­ç»ƒSVMæ¨¡å‹...")
        # ä¸ºæ¯ä¸ªç±»åˆ«è®­ç»ƒäºŒåˆ†ç±»SVM
        for idx, c in enumerate(self.classes):
            # æ„å»ºäºŒåˆ†ç±»æ ‡ç­¾ï¼ˆå½“å‰ç±»=1ï¼Œå…¶ä»–ç±»=-1ï¼‰
            y_bin = np.where(y == c, 1, -1)
            w = np.zeros(n_feat)
            b = 0

            # æ¢¯åº¦ä¸‹é™ä¼˜åŒ–
            for iter in range(self.n_iters):
                if iter % 200 == 0:
                    print(f"  ç±»åˆ«{c}ï¼šè¿­ä»£{iter}/{self.n_iters}")

                for i in range(n_samples):
                    z = np.dot(X[i], w) + b
                    if y_bin[i] * z < 1:
                        # è¯¯åˆ†ç±»æ ·æœ¬ï¼šæ›´æ–°æƒé‡å’Œåç½®
                        w -= self.lr * (2 * self.lambda_param * w - y_bin[i] * X[i])
                        b -= self.lr * (-y_bin[i])
                    else:
                        # æ­£ç¡®åˆ†ç±»æ ·æœ¬ï¼šä»…æ­£åˆ™åŒ–
                        w -= self.lr * 2 * self.lambda_param * w

            self.weights[idx] = w
            self.biases[idx] = b

        print("âœ… SVMæ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    def predict(self, X):
        """é¢„æµ‹ç±»åˆ«ï¼ˆè¿”å›ç±»åˆ«ç´¢å¼•ï¼‰"""
        pred = []
        for x in X:
            # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å¾—åˆ†
            scores = [np.dot(x, self.weights[idx]) + self.biases[idx] for idx in range(len(self.classes))]
            pred.append(self.classes[np.argmax(scores)])
        return np.array(pred)

    def predict_proba(self, X):
        """é¢„æµ‹æ¦‚ç‡ï¼ˆSoftmaxè½¬æ¢ï¼‰"""
        probs = []
        for x in X:
            scores = [np.dot(x, self.weights[idx]) + self.biases[idx] for idx in range(len(self.classes))]
            # Softmaxå½’ä¸€åŒ–ï¼ˆé˜²æ­¢æ•°å€¼æº¢å‡ºï¼‰
            exp_scores = np.exp(scores - np.max(scores))
            prob = exp_scores / np.sum(exp_scores)
            probs.append(prob)
        return np.array(probs)


# ===================== 4. æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ï¼ˆçº¯æ‰‹åŠ¨å®ç°ï¼‰ =====================
class Metrics:
    @staticmethod
    def train_test_split(X, y, test_size=0.2, seed=42):
        """åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†"""
        np.random.seed(seed)
        idx = np.arange(len(X))
        np.random.shuffle(idx)
        X, y = X[idx], y[idx]

        split_idx = int(len(X) * (1 - test_size))
        return X[:split_idx], X[split_idx:], y[:split_idx], y[split_idx:]

    @staticmethod
    def accuracy(y_true, y_pred):
        """è®¡ç®—å‡†ç¡®ç‡"""
        return np.sum(y_true == y_pred) / len(y_true)

    @staticmethod
    def confusion_matrix(y_true, y_pred, classes):
        """è®¡ç®—æ··æ·†çŸ©é˜µ"""
        n_classes = len(classes)
        cm = np.zeros((n_classes, n_classes), dtype=int)
        cat2idx = {c: i for i, c in enumerate(classes)}

        for t, p in zip(y_true, y_pred):
            cm[cat2idx[t], cat2idx[p]] += 1
        return cm

    @staticmethod
    def classification_report(y_true, y_pred, classes):
        """ç”Ÿæˆåˆ†ç±»æŠ¥å‘Šï¼ˆç²¾ç¡®ç‡/å¬å›ç‡/F1ï¼‰"""
        report = []
        report.append("=" * 50)
        report.append("            åˆ†ç±»æŠ¥å‘Šï¼ˆç²¾ç¡®ç‡/å¬å›ç‡/F1ï¼‰")
        report.append("=" * 50)
        report.append(f"{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'æ ·æœ¬æ•°':<8}")
        report.append("-" * 50)

        total_support = 0
        avg_precision = 0
        avg_recall = 0
        avg_f1 = 0

        for c in classes:
            # è®¡ç®—TP/FN/FP
            tp = np.sum((y_true == c) & (y_pred == c))
            fn = np.sum((y_true == c) & (y_pred != c))
            fp = np.sum((y_true != c) & (y_pred == c))

            support = tp + fn
            total_support += support

            # è®¡ç®—æŒ‡æ ‡ï¼ˆé¿å…é™¤é›¶ï¼‰
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

            avg_precision += precision * support
            avg_recall += recall * support
            avg_f1 += f1 * support

            report.append(f"{c:<12} {precision:.2f}      {recall:.2f}      {f1:.2f}      {support}")

        # åŠ æƒå¹³å‡
        avg_precision /= total_support
        avg_recall /= total_support
        avg_f1 /= total_support

        report.append("-" * 50)
        report.append(
            f"{'åŠ æƒå¹³å‡':<12} {avg_precision:.2f}      {avg_recall:.2f}      {avg_f1:.2f}      {total_support}")
        report.append("=" * 50)

        return "\n".join(report)


# ===================== 5. äº¤é€šæ ‡å¿—è¯†åˆ«ä¸»ç³»ç»Ÿ =====================
class TrafficSignDetector:
    def __init__(self):
        self.X = []  # ç‰¹å¾é›†
        self.y = []  # æ ‡ç­¾é›†
        self.categories = []  # ç±»åˆ«åˆ—è¡¨
        self.svm = SimpleSVM()
        self.mean = None  # ç‰¹å¾å‡å€¼ï¼ˆæ ‡å‡†åŒ–ï¼‰
        self.std = None  # ç‰¹å¾æ ‡å‡†å·®ï¼ˆæ ‡å‡†åŒ–ï¼‰

    def load_data(self):
        """åŠ è½½æ•°æ®é›†å¹¶æå–HOGç‰¹å¾"""
        print("\nğŸ“¥ å¼€å§‹åŠ è½½æ•°æ®é›†...")
        # è·å–ç±»åˆ«åˆ—è¡¨
        self.categories = [d for d in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, d))]

        # éå†æ‰€æœ‰å›¾ç‰‡
        for label, cat in enumerate(self.categories):
            cat_dir = os.path.join(DATA_PATH, cat)
            img_files = [f for f in os.listdir(cat_dir) if f.endswith(('.png', '.jpg'))]

            for img_file in img_files:
                img_path = os.path.join(cat_dir, img_file)
                # é¢„å¤„ç†å›¾ç‰‡
                img = self._preprocess(img_path)
                if img is None:
                    continue
                # æå–HOGç‰¹å¾
                hog_feat = hog_feature_extract(img)
                self.X.append(hog_feat)
                self.y.append(cat)  # ç›´æ¥å­˜å‚¨ç±»åˆ«åç§°ï¼ˆæ›´ç›´è§‚ï¼‰

        # è½¬æ¢ä¸ºNumpyæ•°ç»„
        self.X = np.array(self.X)
        self.y = np.array(self.y)

        # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
        X_train, X_test, y_train, y_test = Metrics.train_test_split(self.X, self.y)

        # ç‰¹å¾æ ‡å‡†åŒ–
        self.mean = np.mean(X_train, axis=0)
        self.std = np.std(X_train, axis=0) + 1e-6
        X_train = (X_train - self.mean) / self.std
        X_test = (X_test - self.mean) / self.std

        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°ï¼š{len(self.X)} | è®­ç»ƒé›†ï¼š{len(X_train)} | æµ‹è¯•é›†ï¼š{len(X_test)}")
        return X_train, X_test, y_train, y_test

    def _preprocess(self, img_path):
        """å›¾ç‰‡é¢„å¤„ç†ï¼šç°åº¦åŒ–â†’ç¼©æ”¾â†’å½’ä¸€åŒ–"""
        try:
            with Image.open(img_path) as img:
                # ç°åº¦åŒ–+ç¼©æ”¾è‡³64x64
                img_gray = img.convert('L')
                img_resized = img_gray.resize((64, 64), Image.Resampling.LANCZOS)
                # å½’ä¸€åŒ–åˆ°0-1
                img_arr = np.array(img_resized, dtype=np.float32) / 255.0
                return img_arr
        except Exception as e:
            print(f"âš ï¸ å›¾ç‰‡é¢„å¤„ç†å¤±è´¥ {img_path}ï¼š{e}")
            return None

    def evaluate(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹å¹¶ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š"""
        # é¢„æµ‹æµ‹è¯•é›†
        y_pred = self.svm.predict(X_test)
        y_pred_proba = self.svm.predict_proba(X_test)

        # 1. æ•´ä½“å‡†ç¡®ç‡
        acc = Metrics.accuracy(y_test, y_pred)
        print(f"\nğŸ“ˆ æ•´ä½“è¯†åˆ«å‡†ç¡®ç‡ï¼š{acc:.4f} ({acc * 100:.2f}%)")

        # 2. åˆ†ç±»æŠ¥å‘Š
        report = Metrics.classification_report(y_test, y_pred, self.categories)
        print(report)

        # 3. æ··æ·†çŸ©é˜µï¼ˆå¯è§†åŒ–+ä¿å­˜ï¼‰
        cm = Metrics.confusion_matrix(y_test, y_pred, self.categories)
        self._plot_confusion_matrix(cm)

        # 4. å„ç±»åˆ«å‡†ç¡®ç‡
        print("\nğŸ“‹ å„ç±»åˆ«è¯†åˆ«å‡†ç¡®ç‡ï¼š")
        for i, cat in enumerate(self.categories):
            total = cm[i].sum()
            correct = cm[i, i]
            acc_cat = correct / total if total > 0 else 0
            print(f"  {cat}ï¼š{acc_cat:.4f} ({correct}/{total})")

        # 5. ä½ç½®ä¿¡åº¦æ£€æµ‹
        low_conf_idx = np.where(np.max(y_pred_proba, axis=1) < 0.8)[0]
        print(f"\nâš ï¸ ä½ç½®ä¿¡åº¦é¢„æµ‹ï¼ˆæ¦‚ç‡<0.8ï¼‰ï¼š{len(low_conf_idx)} ä¸ªæ ·æœ¬")
        if len(low_conf_idx) > 0:
            for idx in low_conf_idx[:3]:  # å±•ç¤ºå‰3ä¸ª
                true_cat = y_test[idx]
                pred_cat = y_pred[idx]
                conf = np.max(y_pred_proba[idx])
                print(f"  æ ·æœ¬{idx}ï¼šçœŸå®={true_cat} | é¢„æµ‹={pred_cat} | ç½®ä¿¡åº¦={conf:.4f}")

    def _plot_confusion_matrix(self, cm):
        """ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µ"""
        plt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ˜¾ç¤º
        plt.figure(figsize=(8, 6))
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title('äº¤é€šæ ‡å¿—è¯†åˆ« - æ··æ·†çŸ©é˜µ', fontsize=12)
        plt.colorbar()
        # è®¾ç½®åæ ‡è½´
        tick_marks = np.arange(len(self.categories))
        plt.xticks(tick_marks, self.categories, rotation=45)
        plt.yticks(tick_marks, self.categories)
        # æ ‡æ³¨æ•°å€¼
        thresh = cm.max() / 2.
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                plt.text(j, i, cm[i, j], ha="center", va="center",
                         color="white" if cm[i, j] > thresh else "black")
        # æ ‡ç­¾
        plt.ylabel('çœŸå®ç±»åˆ«', fontsize=10)
        plt.xlabel('é¢„æµ‹ç±»åˆ«', fontsize=10)
        plt.tight_layout()
        # ä¿å­˜å›¾ç‰‡ï¼ˆPyCharmä¸­å¯ç›´æ¥æŸ¥çœ‹ï¼‰
        plt.savefig(CONFUSION_MATRIX_PATH, dpi=150, bbox_inches='tight')
        print(f"\nğŸ–¼ï¸ æ··æ·†çŸ©é˜µå·²ä¿å­˜ï¼š{CONFUSION_MATRIX_PATH}")
        # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆPyCharmä¼šå¼¹å‡ºçª—å£ï¼‰
        plt.show()

    def predict_single(self):
        """é¢„æµ‹å•å¼ æµ‹è¯•å›¾ç‰‡"""
        # ç”Ÿæˆæµ‹è¯•å›¾ç‰‡ï¼ˆæ¨¡æ‹Ÿstop_signï¼‰
        test_img_arr = np.random.normal(0.8, 0.08, (64, 64))
        test_img_arr = np.clip(test_img_arr * 255, 0, 255).astype(np.uint8)
        test_img = Image.fromarray(test_img_arr, mode='L')
        test_img.save(TEST_IMG_PATH)
        print(f"\nğŸ“¸ ç”Ÿæˆæµ‹è¯•å›¾ç‰‡ï¼š{TEST_IMG_PATH}")

        # é¢„å¤„ç†+æå–ç‰¹å¾
        img = self._preprocess(TEST_IMG_PATH)
        hog_feat = hog_feature_extract(img)
        hog_feat = (hog_feat - self.mean) / self.std

        # é¢„æµ‹
        pred_cat = self.svm.predict(np.array([hog_feat]))[0]
        pred_proba = self.svm.predict_proba(np.array([hog_feat]))[0]
        conf = pred_proba[self.svm.classes.tolist().index(pred_cat)]

        # è¾“å‡ºç»“æœ
        print("\nğŸ¯ å•å¼ å›¾ç‰‡è¯†åˆ«ç»“æœï¼š")
        print(f"  é¢„æµ‹ç±»åˆ«ï¼š{pred_cat}")
        print(f"  ç½®ä¿¡åº¦ï¼š{conf:.4f}")
        print(f"  æ˜¯å¦é«˜ç½®ä¿¡åº¦ï¼š{'æ˜¯' if conf >= 0.8 else 'å¦'}")
        print("  å„ç±»åˆ«æ¦‚ç‡ï¼š")
        for i, cat in enumerate(self.categories):
            print(f"    {cat}ï¼š{pred_proba[i]:.4f}")


# ===================== 6. ä¸»è¿è¡Œå‡½æ•°ï¼ˆPyCharmä¸€é”®è¿è¡Œï¼‰ =====================
def main():
    """PyCharmä¸»è¿è¡Œå…¥å£"""
    # æ­¥éª¤1ï¼šç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†
    create_simulated_dataset()

    # æ­¥éª¤2ï¼šåˆå§‹åŒ–æ£€æµ‹å™¨
    detector = TrafficSignDetector()

    # æ­¥éª¤3ï¼šåŠ è½½æ•°æ®
    X_train, X_test, y_train, y_test = detector.load_data()

    # æ­¥éª¤4ï¼šè®­ç»ƒæ¨¡å‹
    detector.svm.fit(X_train, y_train)

    # æ­¥éª¤5ï¼šè¯„ä¼°æ¨¡å‹ï¼ˆç”Ÿæˆæ··æ·†çŸ©é˜µå›¾ç‰‡ï¼‰
    detector.evaluate(X_test, y_test)

    # æ­¥éª¤6ï¼šå•å¼ å›¾ç‰‡é¢„æµ‹ï¼ˆç”Ÿæˆæµ‹è¯•å›¾ç‰‡ï¼‰
    detector.predict_single()

    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
    print(f"  1. æ··æ·†çŸ©é˜µï¼š{CONFUSION_MATRIX_PATH}")
    print(f"  2. æµ‹è¯•å›¾ç‰‡ï¼š{TEST_IMG_PATH}")
    print(f"  3. æ•°æ®é›†ï¼š{DATA_PATH}")


# ===================== è¿è¡Œå…¥å£ =====================
if __name__ == "__main__":
    # PyCharmä¸­ç›´æ¥è¿è¡Œæ­¤è„šæœ¬
    main()