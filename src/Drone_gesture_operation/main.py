#!/usr/bin/env python
# -*- coding: utf-8 -*-
import cv2 as cv
import numpy as np
import time
import threading


class StableFPSHandRecognizer:
    def __init__(self, target_fps=30):
        # 1. å¸§ç‡é”å®šå‚æ•°
        self.target_fps = target_fps
        self.frame_interval = 1.0 / target_fps
        self.last_frame_time = time.time()

        # 2. ä¼˜åŒ–åçš„è‚¤è‰²æ£€æµ‹é˜ˆå€¼ï¼ˆé€‚é…æ›´å¤šè‚¤è‰²/å…‰çº¿ï¼‰
        self.skin_lower = np.array([0, 20, 70], np.uint8)  # æ”¾å®½ä¸‹ç•Œ
        self.skin_upper = np.array([20, 255, 255], np.uint8)  # è°ƒæ•´ä¸Šç•Œ
        self.kernel = np.ones((5, 5), np.uint8)  # æ›´å¤§çš„æ ¸å»å™ª

        # 3. ä¼˜åŒ–åçš„æ‰‹æŒ‡æ£€æµ‹å‚æ•°ï¼ˆé™ä½é˜ˆå€¼ï¼Œæé«˜è¯†åˆ«ç‡ï¼‰
        self.defect_depth_threshold = 10  # é™ä½æ·±åº¦é˜ˆå€¼
        self.min_defect_distance = 5  # é™ä½è·ç¦»é˜ˆå€¼
        self.min_contour_area = 500  # é™ä½æœ€å°è½®å»“é¢ç§¯

        # 4. æ‰‹åŠ¿ç¼“å­˜&å¸§ç¼“å­˜
        self.gesture_buffer = []
        self.stable_gesture = "None"
        self.frame_queue = []
        self.queue_lock = threading.Lock()

        # 5. è¯†åˆ«åŒºåŸŸå‚æ•°ï¼ˆä»…æ˜¾ç¤ºè¾¹æ¡†ï¼‰
        self.recognition_area = None
        self.area_color = (0, 255, 0)  # è¾¹æ¡†é¢œè‰²ï¼ˆç»¿è‰²ï¼‰

    def _init_recognition_area(self, frame_shape):
        """åˆå§‹åŒ–è¯†åˆ«åŒºåŸŸï¼ˆè°ƒå¤§å°ºå¯¸ï¼Œå³ä¾§æ›´å¤§èŒƒå›´ï¼‰"""
        h, w = frame_shape[:2]
        x1 = int(w * 1.5 / 3)  # å·¦è¾¹ç•Œå·¦ç§»ï¼ˆä»2/3æ”¹ä¸º1.5/3ï¼‰ï¼Œæ‰©å¤§å®½åº¦
        y1 = int(h * 0.05)  # ä¸Šè¾¹ç•Œä¸Šç§»ï¼ˆä»0.1æ”¹ä¸º0.05ï¼‰ï¼Œæ‰©å¤§é«˜åº¦
        x2 = w - 10  # å³è¾¹ç•Œå³ç§»ï¼ˆä»-20æ”¹ä¸º-10ï¼‰ï¼Œå‡å°‘å³ä¾§è¾¹è·
        y2 = int(h * 0.95)  # ä¸‹è¾¹ç•Œä¸‹ç§»ï¼ˆä»0.9æ”¹ä¸º0.95ï¼‰ï¼Œå‡å°‘åº•éƒ¨è¾¹è·
        self.recognition_area = (x1, y1, x2, y2)

    def _draw_recognition_area(self, frame):
        """ç»˜åˆ¶è¯†åˆ«åŒºåŸŸï¼ˆä»…æ˜¾ç¤ºè¾¹æ¡†ï¼Œæ— èƒŒæ™¯è‰²ï¼‰"""
        if self.recognition_area is None:
            self._init_recognition_area(frame.shape)
        x1, y1, x2, y2 = self.recognition_area

        # ä»…ç»˜åˆ¶è¾¹æ¡†ï¼ˆç§»é™¤åŠé€æ˜èƒŒæ™¯ï¼‰
        cv.rectangle(frame, (x1, y1), (x2, y2), self.area_color, 2)

        # æ·»åŠ åŒºåŸŸæç¤ºæ–‡å­—ï¼ˆåœ¨è¾¹æ¡†ä¸Šæ–¹ï¼‰
        cv.putText(frame, "Recognition Area", (x1 + 10, y1 - 10),
                   cv.FONT_HERSHEY_SIMPLEX, 0.6, self.area_color, 2)
        return frame

    def _get_roi(self, frame):
        """è·å–è¯†åˆ«åŒºåŸŸçš„ROIï¼ˆç¡®ä¿åæ ‡æœ‰æ•ˆï¼‰"""
        if self.recognition_area is None:
            self._init_recognition_area(frame.shape)
        x1, y1, x2, y2 = self.recognition_area

        # è¾¹ç•Œä¿æŠ¤
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(frame.shape[1], x2)
        y2 = min(frame.shape[0], y2)

        return frame[y1:y2, x1:x2], (x1, y1)

    def count_fingers(self, cnt):
        """ä¼˜åŒ–åçš„æ‰‹æŒ‡è®¡æ•°é€»è¾‘ï¼ˆæ›´é²æ£’ï¼‰"""
        try:
            # è®¡ç®—å‡¸åŒ…ï¼ˆå¸¦åæ ‡ï¼‰å’Œå‡¸åŒ…ç¼ºé™·
            hull = cv.convexHull(cnt)
            hull_indices = cv.convexHull(cnt, returnPoints=False)
            defects = cv.convexityDefects(cnt, hull_indices)

            if defects is None or len(defects) == 0:
                return 0

            finger_count = 0
            # éå†ç¼ºé™·ç‚¹
            for i in range(defects.shape[0]):
                s, e, f, d = defects[i, 0]
                start = tuple(cnt[s][0])
                end = tuple(cnt[e][0])
                far = tuple(cnt[f][0])

                # è®¡ç®—ç¼ºé™·æ·±åº¦ï¼ˆå®é™…åƒç´ å€¼ï¼‰
                depth = d / 256.0

                # è®¡ç®—è§’åº¦ï¼ˆè¿‡æ»¤è¯¯åˆ¤çš„ç¼ºé™·ï¼‰
                a = np.linalg.norm(np.array(end) - np.array(start))
                b = np.linalg.norm(np.array(far) - np.array(start))
                c = np.linalg.norm(np.array(end) - np.array(far))
                angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c)) * 180 / np.pi

                # æœ‰æ•ˆç¼ºé™·ï¼šæ·±åº¦è¶³å¤Ÿ + è§’åº¦å°äº90åº¦ï¼ˆæ‰‹æŒ‡é—´çš„å‡¹é™·ï¼‰
                if depth > self.defect_depth_threshold and angle < 90:
                    finger_count += 1

            # ç¼ºé™·æ•°+1=æ‰‹æŒ‡æ•°é‡ï¼ˆæœ€å¤š5æ ¹ï¼‰
            return min(finger_count + 1, 5)
        except Exception as e:
            print(f"æ‰‹æŒ‡è®¡æ•°é”™è¯¯: {e}")
            return 0

    def capture_frames(self, cap):
        """å¸§é‡‡é›†çº¿ç¨‹ï¼ˆç¨³å®šï¼‰"""
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            with self.queue_lock:
                self.frame_queue = [frame]  # åªä¿ç•™æœ€æ–°å¸§
            time.sleep(self.frame_interval * 0.5)

    def process_frame(self, frame):
        """ä¼˜åŒ–åçš„å¸§å¤„ç†é€»è¾‘"""
        # é•œåƒç¿»è½¬
        frame = cv.flip(frame, 1)
        # ç»˜åˆ¶è¯†åˆ«åŒºåŸŸï¼ˆä»…è¾¹æ¡†ï¼‰
        frame = self._draw_recognition_area(frame)
        # è·å–ROI
        roi, (roi_x, roi_y) = self._get_roi(frame)
        current_gesture = "None"

        if roi.size > 0:  # ç¡®ä¿ROIæœ‰æ•ˆ
            # é¢„å¤„ç†ï¼šç¼©å°+è½¬HSV+è‚¤è‰²æ©ç 
            roi_small = cv.resize(roi, (320, 240))  # é€‚åº¦æ”¾å¤§ROIï¼Œæé«˜æ£€æµ‹ç²¾åº¦
            hsv = cv.cvtColor(roi_small, cv.COLOR_BGR2HSV)
            mask = cv.inRange(hsv, self.skin_lower, self.skin_upper)

            # å½¢æ€å­¦æ“ä½œï¼ˆå»å™ª+å¡«å……ï¼‰
            mask = cv.morphologyEx(mask, cv.MORPH_OPEN, self.kernel)
            mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, self.kernel)
            mask = cv.dilate(mask, self.kernel, iterations=2)

            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
            if contours:
                # å–æœ€å¤§è½®å»“ï¼ˆæ‰‹éƒ¨ï¼‰
                cnt = max(contours, key=cv.contourArea)
                area = cv.contourArea(cnt)

                if area > self.min_contour_area:
                    # è®¡ç®—å¯†å®åº¦ï¼ˆåˆ¤æ–­æ˜¯å¦æ¡æ‹³ï¼‰
                    hull = cv.convexHull(cnt)
                    hull_area = cv.contourArea(hull)
                    solidity = area / hull_area if hull_area > 0 else 0

                    # æ‰‹æŒ‡è®¡æ•°
                    finger_count = self.count_fingers(cnt)

                    # å¯è§†åŒ–è°ƒè¯•ï¼ˆå¯é€‰ï¼šåœ¨ROIå†…ç»˜åˆ¶è½®å»“ï¼‰
                    cnt_scaled = cnt * (roi.shape[1] / roi_small.shape[1], roi.shape[0] / roi_small.shape[0])
                    cnt_scaled = cnt_scaled.astype(np.int32)
                    cnt_scaled[:, :, 0] += roi_x
                    cnt_scaled[:, :, 1] += roi_y
                    cv.drawContours(frame, [cnt_scaled], -1, (255, 0, 0), 2)

                    # æ‰‹åŠ¿åˆ¤æ–­é€»è¾‘ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
                    if solidity > 0.8:  # æ¡æ‹³ï¼ˆå¯†å®åº¦é«˜ï¼‰
                        current_gesture = "stop"
                    elif finger_count == 2:  # é£ŸæŒ‡+ä¸­æŒ‡
                        current_gesture = "front"
                    elif finger_count >= 4:  # æ‰‹æŒå¼ å¼€ï¼ˆ4-5æŒ‡ï¼‰
                        current_gesture = "back"
                    # å…¶ä»–æƒ…å†µï¼ˆ1/3æŒ‡ï¼‰å½’ä¸ºNone

        # æ‰‹åŠ¿ç¼“å­˜ç¨³å®š
        self.gesture_buffer.append(current_gesture)
        if len(self.gesture_buffer) > 2:
            self.gesture_buffer.pop(0)
        if len(set(self.gesture_buffer)) == 1:
            self.stable_gesture = self.gesture_buffer[0]

        # ç»˜åˆ¶UI
        cv.putText(frame, f"Gesture: {self.stable_gesture}", (10, 40),
                   cv.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
        cv.putText(frame, f"FPS: {self.target_fps}", (10, 80),
                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)

        # æ‹‰ä¼¸æ˜¾ç¤º
        frame_show = cv.resize(frame, (640, 480))
        return frame_show

    def run(self):
        """ä¸»è¿è¡Œé€»è¾‘"""
        # æ‘„åƒå¤´åˆå§‹åŒ–ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
        cap = cv.VideoCapture(0)
        cap.set(cv.CAP_PROP_FRAME_WIDTH, 640)  # æé«˜æ‘„åƒå¤´åˆ†è¾¨ç‡
        cap.set(cv.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv.CAP_PROP_FOURCC, cv.VideoWriter_fourcc(*'MJPG'))
        cap.set(cv.CAP_PROP_BUFFERSIZE, 1)
        cap.set(cv.CAP_PROP_FPS, self.target_fps)

        # å¯åŠ¨é‡‡é›†çº¿ç¨‹
        capture_thread = threading.Thread(target=self.capture_frames, args=(cap,), daemon=True)
        capture_thread.start()

        # æç¤ºä¿¡æ¯
        print("=" * 50)
        print(f"âœ… å¸§ç‡é”å®š {self.target_fps} å¸§ | ESCé€€å‡º")
        print("ğŸ’¡ è°ƒè¯•æç¤ºï¼š")
        print("   1. æŠŠæ‰‹æ”¾åœ¨å³ä¾§ç»¿è‰²è¾¹æ¡†çš„è¯†åˆ«åŒºåŸŸå†…ï¼ˆå·²æ‰©å¤§èŒƒå›´ï¼‰")
        print("   2. æ¡æ‹³ â†’ stop | é£ŸæŒ‡+ä¸­æŒ‡ â†’ front | æ‰‹æŒå¼ å¼€ â†’ back")
        print("   3. è“è‰²è½®å»“è¡¨ç¤ºæ£€æµ‹åˆ°çš„æ‰‹éƒ¨åŒºåŸŸ")
        print("=" * 50)

        # ä¸»å¾ªç¯
        while cap.isOpened():
            # å¸§ç‡æ§åˆ¶
            current_time = time.time()
            elapsed = current_time - self.last_frame_time
            if elapsed < self.frame_interval:
                time.sleep(self.frame_interval - elapsed)

            # è¯»å–å¸§
            with self.queue_lock:
                if not self.frame_queue:
                    continue
                frame = self.frame_queue.pop(0)

            # å¤„ç†å¹¶æ˜¾ç¤º
            frame_show = self.process_frame(frame)
            cv.imshow("Hand Gesture Recognition", frame_show)

            # æ›´æ–°æ—¶é—´æˆ³
            self.last_frame_time = time.time()

            # ESCé€€å‡º
            if cv.waitKey(1) & 0xFF == 27:
                break

        # é‡Šæ”¾èµ„æº
        cap.release()
        cv.destroyAllWindows()


if __name__ == '__main__':
    # å¯é™ä½å¸§ç‡ï¼ˆå¦‚15ï¼‰æé«˜ç¨³å®šæ€§
    recognizer = StableFPSHandRecognizer(target_fps=20)
    recognizer.run()