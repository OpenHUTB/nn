"""
AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢æ— äººæœº - é›†æˆå‰è§†çª—å£ç‰ˆ
æ ¸å¿ƒï¼šè§†è§‰æ„ŸçŸ¥ â†’ è¯­ä¹‰ç†è§£ â†’ æ™ºèƒ½å†³ç­– â†’ å®‰å…¨æ‰§è¡Œ
"""

import airsim
import time
import numpy as np
import cv2
import math
from collections import deque
from dataclasses import dataclass
from enum import Enum
import threading
import queue
import signal
import sys
from typing import Tuple, List, Optional, Dict

# ==================== å‰è§†æ˜¾ç¤ºçª—å£ç±» ====================

class FrontViewDisplay:
    """
    å‰è§†ç”»é¢æ˜¾ç¤ºç®¡ç†å™¨
    ä¿®å¤äº†çª—å£æ¨¡ç³Šå’Œæ˜¾ç¤ºé—®é¢˜
    """

    def __init__(self, window_name="æ— äººæœºå‰è§†ç”»é¢", width=640, height=480):
        """
        åˆå§‹åŒ–æ˜¾ç¤ºçª—å£

        æ³¨æ„ï¼šè¦è·å¾—æ¸…æ™°ç”»é¢ï¼Œæœ‰ä¸¤ç§æ–¹æ³•ï¼š
        1. ä¿®æ”¹AirSimé…ç½®æ–‡ä»¶settings.jsonï¼Œæé«˜ç›¸æœºåˆ†è¾¨ç‡ï¼ˆæ¨èï¼‰
        2. åœ¨ä»£ç ä¸­å¯ç”¨å›¾åƒé”åŒ–å¤„ç†ï¼ˆä¸‹æ–¹å·²å®ç°ï¼‰
        """
        self.window_name = window_name
        self.window_width = width
        self.window_height = height

        # å›¾åƒé˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.image_queue = queue.Queue(maxsize=2)
        self.display_active = True
        self.display_thread = None

        # æ˜¾ç¤ºæ§åˆ¶
        self.paused = False
        self.show_info = True

        # å›¾åƒå¢å¼ºé€‰é¡¹
        self.enable_sharpening = True  # å¯ç”¨å›¾åƒé”åŒ–ï¼ˆæ”¹å–„æ¨¡ç³Šï¼‰
        self.enable_upscaling = False  # å¯ç”¨å›¾åƒæ”¾å¤§ï¼ˆè°¨æ…ä½¿ç”¨ï¼Œå¯èƒ½æ›´æ¨¡ç³Šï¼‰

        # å¯åŠ¨æ˜¾ç¤ºçº¿ç¨‹
        self.start()

    def start(self):
        """å¯åŠ¨æ˜¾ç¤ºçº¿ç¨‹"""
        if self.display_thread and self.display_thread.is_alive():
            return

        self.display_active = True
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="FrontViewDisplay"
        )
        self.display_thread.start()
        print(f"âœ… å‰è§†ç”»é¢çª—å£å·²å¯åŠ¨: {self.window_name}")
        print("ğŸ’¡ æ˜¾ç¤ºçª—å£æ§åˆ¶:")
        print("   - æŒ‰ 'Q': å…³é—­æ˜¾ç¤ºçª—å£")
        print("   - æŒ‰ 'S': ä¿å­˜å½“å‰ç”»é¢")
        print("   - æŒ‰ 'P': æš‚åœ/ç»§ç»­è§†é¢‘æµ")
        print("   - æŒ‰ 'I': åˆ‡æ¢ä¿¡æ¯å åŠ å±‚")
        print("ğŸ’¡ ç”»é¢æ¸…æ™°åº¦æç¤º:")
        print("   å½“å‰åˆ†è¾¨ç‡: 256x144 (é»˜è®¤è¾ƒä½)")
        print("   å¦‚éœ€æ›´é«˜æ¸…ï¼Œè¯·ä¿®æ”¹settings.jsonç›¸æœºé…ç½®")

    def stop(self):
        """åœæ­¢æ˜¾ç¤ºçº¿ç¨‹"""
        self.display_active = False
        if self.display_thread:
            self.display_thread.join(timeout=2.0)
            print("ğŸ›‘ å‰è§†ç”»é¢æ˜¾ç¤ºçª—å£å·²åœæ­¢")

    def update_image(self, image_data: np.ndarray, info: Optional[Dict] = None):
        """
        æ›´æ–°è¦æ˜¾ç¤ºçš„å›¾åƒ

        Args:
            image_data: OpenCVæ ¼å¼çš„å›¾åƒ (BGR)
            info: å åŠ ä¿¡æ¯ï¼Œå¦‚çŠ¶æ€ã€ä½ç½®ç­‰
        """
        if not self.display_active or self.paused or image_data is None:
            return

        try:
            # å›¾åƒå¢å¼ºå¤„ç†
            processed_image = self._enhance_image(image_data)

            # å¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæœ€æ—§çš„ä¸€å¸§
            if self.image_queue.full():
                try:
                    self.image_queue.get_nowait()
                except queue.Empty:
                    pass

            display_packet = {
                'image': processed_image,
                'info': info.copy() if info else {},
                'timestamp': time.time()
            }

            self.image_queue.put_nowait(display_packet)

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°å›¾åƒæ—¶å‡ºé”™: {e}")

    def _enhance_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒå¢å¼ºå¤„ç†"""
        if image is None or image.size == 0:
            return image

        enhanced = image.copy()

        try:
            # 1. é”åŒ–å¤„ç†ï¼ˆæ”¹å–„æ¨¡ç³Šï¼‰
            if self.enable_sharpening:
                # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è¿›è¡Œé”åŒ–
                kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
                enhanced = cv2.filter2D(enhanced, -1, kernel)

            # 2. å¯¹æ¯”åº¦å¢å¼º
            # enhanced = cv2.convertScaleAbs(enhanced, alpha=1.2, beta=10)

            # 3. å¯é€‰ï¼šæ”¾å¤§å›¾åƒï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
            if self.enable_upscaling and enhanced.shape[0] < 400:
                # ä½¿ç”¨åŒä¸‰æ¬¡æ’å€¼æ”¾å¤§
                new_width = self.window_width
                new_height = self.window_height
                enhanced = cv2.resize(enhanced, (new_width, new_height),
                                     interpolation=cv2.INTER_CUBIC)

            return enhanced

        except Exception as e:
            print(f"âš ï¸ å›¾åƒå¢å¼ºå‡ºé”™: {e}")
            return image

    def _display_loop(self):
        """æ˜¾ç¤ºçº¿ç¨‹ä¸»å¾ªç¯"""
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        # åˆå§‹æ˜¾ç¤ºç­‰å¾…ç”»é¢
        wait_img = np.zeros((300, 400, 3), dtype=np.uint8)
        cv2.putText(wait_img, "ç­‰å¾…æ— äººæœºå›¾åƒ...", (50, 150),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        cv2.imshow(self.window_name, wait_img)
        cv2.waitKey(100)  # å…³é”®ï¼šç»™çª—å£æ—¶é—´åˆå§‹åŒ–

        print("ğŸ¬ æ˜¾ç¤ºçº¿ç¨‹å¼€å§‹è¿è¡Œ...")

        while self.display_active:
            display_image = None
            info = {}

            try:
                # è·å–æœ€æ–°å›¾åƒ
                if not self.image_queue.empty():
                    packet = self.image_queue.get_nowait()
                    display_image = packet['image']
                    info = packet['info']

                    # æ¸…ç©ºé˜Ÿåˆ—ä¸­çš„æ—§å¸§
                    while not self.image_queue.empty():
                        self.image_queue.get_nowait()
            except queue.Empty:
                pass

            # æ˜¾ç¤ºå›¾åƒ
            if display_image is not None:
                # æ·»åŠ ä¿¡æ¯å åŠ 
                if self.show_info:
                    display_image = self._add_info_overlay(display_image, info)

                cv2.imshow(self.window_name, display_image)
            elif self.paused:
                # æš‚åœæ—¶æ˜¾ç¤ºæç¤º
                blank = np.zeros((300, 400, 3), dtype=np.uint8)
                cv2.putText(blank, "PAUSED", (120, 150),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
                cv2.imshow(self.window_name, blank)
            else:
                # æ— å›¾åƒæ—¶ä¿æŒçª—å£æ´»åŠ¨
                pass

            # å…³é”®ï¼šå¿…é¡»å®šæœŸè°ƒç”¨waitKeyä¿æŒçª—å£å“åº”
            key = cv2.waitKey(30) & 0xFF

            if key == ord('q') or key == ord('Q'):
                print("ğŸ”„ ç”¨æˆ·å…³é—­æ˜¾ç¤ºçª—å£")
                self.display_active = False
                break
            elif key == ord('s') or key == ord('S'):
                self._save_screenshot(display_image)
            elif key == ord('p') or key == ord('P'):
                self.paused = not self.paused
                status = "å·²æš‚åœ" if self.paused else "å·²æ¢å¤"
                print(f"â¸ï¸ è§†é¢‘æµ{status}")
            elif key == ord('i') or key == ord('I'):
                self.show_info = not self.show_info
                status = "å¼€å¯" if self.show_info else "å…³é—­"
                print(f"ğŸ“Š ä¿¡æ¯å åŠ å±‚{status}")
            elif key == ord('h') or key == ord('H'):
                # åˆ‡æ¢é”åŒ–æ•ˆæœ
                self.enable_sharpening = not self.enable_sharpening
                status = "å¼€å¯" if self.enable_sharpening else "å…³é—­"
                print(f"ğŸ” å›¾åƒé”åŒ–{status}")

        cv2.destroyWindow(self.window_name)
        cv2.waitKey(1)

    def _add_info_overlay(self, image: np.ndarray, info: Dict) -> np.ndarray:
        """åœ¨å›¾åƒä¸Šå åŠ çŠ¶æ€ä¿¡æ¯"""
        try:
            overlay = image.copy()
            height, width = image.shape[:2]

            # åˆ›å»ºåŠé€æ˜ä¿¡æ¯æ 
            info_height = 80
            cv2.rectangle(overlay, (0, 0), (width, info_height), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)

            # é£è¡ŒçŠ¶æ€
            state = info.get('state', 'UNKNOWN')
            state_color = (0, 255, 0) if 'EXPLORING' in state else (0, 255, 255) if 'HOVERING' in state else (0, 0, 255)
            cv2.putText(image, f"çŠ¶æ€: {state}", (10, 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, state_color, 2)

            # ä½ç½®ä¿¡æ¯
            pos = info.get('position', (0, 0, 0))
            cv2.putText(image, f"ä½ç½®: ({pos[0]:.1f}, {pos[1]:.1f}, {-pos[2]:.1f}m)", (10, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # éšœç¢ç‰©ä¿¡æ¯
            obs_dist = info.get('obstacle_distance', 0.0)
            if obs_dist < 100:
                obs_color = (0, 0, 255) if obs_dist < 5.0 else (0, 165, 255) if obs_dist < 10.0 else (0, 255, 0)
                cv2.putText(image, f"éšœç¢: {obs_dist:.1f}m", (width - 120, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, obs_color, 1)

            # åˆ†è¾¨ç‡æç¤ºï¼ˆåªåœ¨ä½åˆ†è¾¨ç‡æ—¶æ˜¾ç¤ºï¼‰
            if height < 200:
                cv2.putText(image, f"åˆ†è¾¨ç‡: {width}x{height}", (width - 120, 55),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)

            return image
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ ä¿¡æ¯å åŠ å±‚å‡ºé”™: {e}")
            return image

    def _save_screenshot(self, image: Optional[np.ndarray]):
        """ä¿å­˜å½“å‰ç”»é¢ä¸ºæˆªå›¾"""
        if image is not None and image.size > 0:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"drone_snapshot_{timestamp}.png"
            cv2.imwrite(filename, image)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        else:
            print("âš ï¸ æ— æ³•ä¿å­˜æˆªå›¾ï¼šæ— æœ‰æ•ˆå›¾åƒæ•°æ®")


# ==================== åŸæœ‰ç±»å®šä¹‰ ====================

class FlightState(Enum):
    """æ— äººæœºçŠ¶æ€æšä¸¾"""
    TAKEOFF = "èµ·é£"
    HOVERING = "æ‚¬åœè§‚æµ‹"
    EXPLORING = "ä¸»åŠ¨æ¢ç´¢"
    AVOIDING = "é¿éšœæœºåŠ¨"
    LANDING = "é™è½"
    EMERGENCY = "ç´§æ€¥çŠ¶æ€"


@dataclass
class PerceptionResult:
    """æ„ŸçŸ¥ç»“æœæ•°æ®ç»“æ„"""
    has_obstacle: bool = False
    obstacle_distance: float = 100.0
    obstacle_direction: float = 0.0  # éšœç¢ç‰©ç›¸å¯¹æ–¹å‘ï¼ˆå¼§åº¦ï¼‰
    terrain_slope: float = 0.0  # åœ°å½¢å¡åº¦
    open_space_score: float = 0.0  # å¼€é˜”åº¦è¯„åˆ† (0-1)
    recommended_height: float = -15.0  # æ¨èé£è¡Œé«˜åº¦
    safe_directions: List[float] = None  # å®‰å…¨æ–¹å‘åˆ—è¡¨
    front_image: Optional[np.ndarray] = None  # æ–°å¢ï¼šå‰è§†å›¾åƒ

    def __post_init__(self):
        if self.safe_directions is None:
            self.safe_directions = []


class PerceptiveExplorer:
    """åŸºäºæ„ŸçŸ¥çš„è‡ªä¸»æ¢ç´¢æ— äººæœº - é›†æˆå‰è§†çª—å£ç‰ˆ"""

    def __init__(self, drone_name=""):
        print("=" * 60)
        print("AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢ç³»ç»Ÿ - é›†æˆå‰è§†çª—å£ç‰ˆ")
        print("=" * 60)

        # åˆå§‹åŒ–AirSimè¿æ¥
        self.client = airsim.MultirotorClient()
        self.client.confirmConnection()
        self.drone_name = drone_name

        # å¯ç”¨APIæ§åˆ¶
        self.client.enableApiControl(True, vehicle_name=drone_name)
        self.client.armDisarm(True, vehicle_name=drone_name)

        # çŠ¶æ€ç®¡ç†
        self.state = FlightState.TAKEOFF
        self.state_history = deque(maxlen=20)
        self.emergency_flag = False

        # æ„ŸçŸ¥å‚æ•°
        self.depth_threshold_near = 5.0  # è¿‘è·ç¦»è­¦æŠ¥é˜ˆå€¼(ç±³)
        self.depth_threshold_safe = 10.0  # å®‰å…¨è·ç¦»é˜ˆå€¼(ç±³)
        self.min_ground_clearance = 2.0  # æœ€å°ç¦»åœ°é—´éš™(ç±³)
        self.max_pitch_angle = math.radians(15)  # æœ€å¤§å…è®¸ä¿¯ä»°è§’

        # æ¢ç´¢å‚æ•°
        self.exploration_time = 180  # æ€»æ¢ç´¢æ—¶é—´(ç§’)
        self.preferred_speed = 3.0  # ä¼˜é€‰é€Ÿåº¦(m/s)
        self.max_altitude = -30  # æœ€å¤§æµ·æ‹”(ç±³)
        self.min_altitude = -8  # æœ€å°æµ·æ‹”(ç±³)

        # è®°å¿†ç³»ç»Ÿ
        self.visited_positions = deque(maxlen=100)

        # æ€§èƒ½ç›‘æ§
        self.perception_fps = 0
        self.decision_fps = 0
        self.start_time = time.time()

        # ========== æ–°å¢ï¼šå‰è§†æ˜¾ç¤ºçª—å£ ==========
        self.front_display = FrontViewDisplay(
            window_name=f"æ— äººæœºå‰è§† - {drone_name or 'AirSimNH'}",
            width=640,
            height=480
        )

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
        print(f"   é¢„è®¡æ¢ç´¢æ—¶é•¿: {self.exploration_time}ç§’")
        print("ğŸ¥ å‰è§†çª—å£å·²é›†æˆï¼Œæ”¯æŒäº¤äº’æ§åˆ¶")

    def get_depth_perception(self) -> PerceptionResult:
        """è·å–å¹¶åˆ†ææ·±åº¦å›¾åƒï¼Œç†è§£ç¯å¢ƒ - é›†æˆå‰è§†å›¾åƒ"""
        result = PerceptionResult()

        try:
            # ========== æ–°å¢ï¼šåŒæ—¶è·å–æ·±åº¦å›¾åƒå’Œå‰è§†å›¾åƒ ==========
            responses = self.client.simGetImages([
                airsim.ImageRequest(
                    "0",  # ç›¸æœºåç§°ï¼Œå¦‚"front_center"
                    airsim.ImageType.DepthPlanar,
                    pixels_as_float=True,
                    compress=False
                ),
                airsim.ImageRequest(
                    "0",  # åŒä¸€ç›¸æœºè·å–å‰è§†å›¾åƒ
                    airsim.ImageType.Scene,
                    False,
                    False
                )
            ])

            if not responses or len(responses) < 2:
                print("âš ï¸ å›¾åƒè·å–å¤±è´¥")
                return result

            # 1. å¤„ç†æ·±åº¦å›¾åƒï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            depth_img = responses[0]
            if depth_img:
                depth_array = np.array(depth_img.image_data_float, dtype=np.float32)
                depth_array = depth_array.reshape(depth_img.height, depth_img.width)

                # åˆ†ææ·±åº¦å›¾åƒçš„ä¸åŒåŒºåŸŸ
                h, w = depth_array.shape

                # å‰æ–¹è¿‘è·ç¦»åŒºåŸŸï¼ˆç´§æ€¥é¿éšœï¼‰
                front_near = depth_array[h // 2:, w // 3:2 * w // 3]
                min_front_distance = np.min(front_near) if front_near.size > 0 else 100

                # å¤šæ–¹å‘æ‰‡å½¢æ‰«æ
                directions = []
                scan_angles = [-45, -30, -15, 0, 15, 30, 45]  # åº¦

                for angle_deg in scan_angles:
                    angle_rad = math.radians(angle_deg)
                    col = int(w / 2 + (w / 2) * math.tan(angle_rad) * 0.5)
                    col = max(0, min(w - 1, col))

                    col_data = depth_array[h // 2:, col]
                    if col_data.size > 0:
                        dir_distance = np.percentile(col_data, 25)
                        directions.append((angle_rad, dir_distance))

                        if dir_distance > self.depth_threshold_safe:
                            result.safe_directions.append(angle_rad)

                # åœ°å½¢åˆ†æ
                ground_region = depth_array[3 * h // 4:, :]
                if ground_region.size > 10:
                    row_variances = np.var(ground_region, axis=1)
                    result.terrain_slope = np.mean(row_variances) * 100

                # å¼€é˜”åº¦è¯„åˆ†
                open_pixels = np.sum(depth_array[h // 2:, :] > self.depth_threshold_safe)
                total_pixels = depth_array[h // 2:, :].size
                result.open_space_score = open_pixels / total_pixels if total_pixels > 0 else 0

                # æ•´åˆæ„ŸçŸ¥ç»“æœ
                result.has_obstacle = min_front_distance < self.depth_threshold_near
                result.obstacle_distance = min_front_distance

                if directions:
                    closest_dir = min(directions, key=lambda x: x[1])
                    result.obstacle_direction = closest_dir[0]

                # æ ¹æ®æ„ŸçŸ¥åŠ¨æ€è°ƒæ•´æ¨èé«˜åº¦
                if result.terrain_slope > 5:
                    result.recommended_height = -20
                elif result.open_space_score > 0.7:
                    result.recommended_height = -12
                else:
                    result.recommended_height = -15

            # ========== æ–°å¢ï¼šå¤„ç†å‰è§†å›¾åƒ ==========
            front_img = responses[1]
            if front_img and hasattr(front_img, 'image_data_uint8'):
                try:
                    # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                    img_array = np.frombuffer(front_img.image_data_uint8, dtype=np.uint8)

                    if len(img_array) > 0:
                        img_rgb = img_array.reshape(front_img.height, front_img.width, 3)
                        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
                        result.front_image = img_bgr

                        # è·å–å½“å‰ä½ç½®ç”¨äºæ˜¾ç¤º
                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                        pos = state.kinematics_estimated.position

                        # å‡†å¤‡æ˜¾ç¤ºä¿¡æ¯
                        display_info = {
                            'state': self.state.name,
                            'obstacle_distance': result.obstacle_distance,
                            'position': (pos.x_val, pos.y_val, pos.z_val),
                        }

                        # æ›´æ–°å‰è§†çª—å£
                        self.front_display.update_image(img_bgr, display_info)

                        # è°ƒè¯•ï¼šæ‰“å°å›¾åƒä¿¡æ¯
                        if hasattr(self, 'loop_count') and self.loop_count % 50 == 0:
                            print(f"ğŸ“· å‰è§†å›¾åƒ: {front_img.width}x{front_img.height}")
                    else:
                        print("âš ï¸ å‰è§†å›¾åƒæ•°æ®ä¸ºç©º")

                except Exception as e:
                    print(f"âš ï¸ å‰è§†å›¾åƒå¤„ç†å‡ºé”™: {e}")

        except Exception as e:
            print(f"âŒ æ·±åº¦æ„ŸçŸ¥å¼‚å¸¸: {e}")

        return result

    def get_visual_perception(self):
        """è·å–è§†è§‰å›¾åƒç”¨äºé«˜çº§æ„ŸçŸ¥ï¼ˆå¯é€‰ï¼‰"""
        try:
            responses = self.client.simGetImages([
                airsim.ImageRequest("0", airsim.ImageType.Scene, False, False)
            ])

            if responses and responses[0]:
                # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                img_data = responses[0].image_data_uint8
                img_array = np.frombuffer(img_data, dtype=np.uint8)
                img = img_array.reshape(responses[0].height, responses[0].width, 3)

                # ç®€å•é¢œè‰²åˆ†æï¼ˆç¤ºä¾‹ï¼šå¯»æ‰¾ç»¿è‰²æ¤è¢«åŒºåŸŸï¼‰
                hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
                green_mask = cv2.inRange(hsv, (40, 40, 40), (80, 255, 255))
                green_ratio = np.sum(green_mask > 0) / green_mask.size

                return img, green_ratio
        except:
            pass

        return None, 0

    def make_intelligent_decision(self, perception: PerceptionResult) -> Tuple[float, float, float, float]:
        """åŸºäºæ„ŸçŸ¥ç»“æœåšå‡ºæ™ºèƒ½å†³ç­–"""

        # è·å–å½“å‰ä½ç½®å’ŒçŠ¶æ€
        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
        pos = state.kinematics_estimated.position
        vel = state.kinematics_estimated.linear_velocity

        # åŸºç¡€å†³ç­–ï¼šé€Ÿåº¦ã€åèˆªã€é«˜åº¦
        target_vx, target_vy, target_z, target_yaw = 0.0, 0.0, perception.recommended_height, 0.0

        # çŠ¶æ€æœºå†³ç­–é€»è¾‘
        if self.state == FlightState.TAKEOFF:
            target_z = -10  # èµ·é£åˆ°10ç±³
            if pos.z_val < -9.5:
                self.change_state(FlightState.HOVERING)

        elif self.state == FlightState.HOVERING:
            # æ‚¬åœè§‚å¯Ÿï¼Œç¼“æ…¢æ—‹è½¬æ‰«æ
            target_yaw = (time.time() % 10) * 0.2  # ç¼“æ…¢æ—‹è½¬

            if len(perception.safe_directions) > 0:
                self.change_state(FlightState.EXPLORING)

        elif self.state == FlightState.EXPLORING:
            # ä¸»åŠ¨æ¢ç´¢æ¨¡å¼
            if perception.has_obstacle:
                self.change_state(FlightState.AVOIDING)
                # ç´§æ€¥åˆ¶åŠ¨
                target_vx, target_vy = -vel.x_val, -vel.y_val
            else:
                # é€‰æ‹©æœ€ä½³æ¢ç´¢æ–¹å‘
                if perception.safe_directions:
                    # ä¼˜å…ˆé€‰æ‹©ä¸å½“å‰èˆªå‘ç›¸å·®45-90åº¦çš„æ–°æ–¹å‘ï¼ˆé¿å…æ¥å›æ‘†åŠ¨ï¼‰
                    current_yaw = airsim.to_eularian_angles(
                        state.kinematics_estimated.orientation
                    )[2]

                    # è¿‡æ»¤å‡ºä¸å½“å‰æ–¹å‘ä¸åŒçš„å®‰å…¨æ–¹å‘
                    diverse_dirs = [
                        d for d in perception.safe_directions
                        if abs(d - current_yaw) > math.radians(45)
                    ]

                    if diverse_dirs:
                        best_dir = diverse_dirs[0]
                    else:
                        best_dir = perception.safe_directions[0]

                    # è®¾ç½®å‰è¿›é€Ÿåº¦
                    speed_factor = min(1.0, perception.open_space_score * 1.5)
                    target_vx = self.preferred_speed * speed_factor * math.cos(best_dir)
                    target_vy = self.preferred_speed * speed_factor * math.sin(best_dir)
                else:
                    # æ²¡æœ‰å®‰å…¨æ–¹å‘ï¼Œçˆ¬å‡
                    target_z = pos.z_val - 5
                    self.change_state(FlightState.AVOIDING)

        elif self.state == FlightState.AVOIDING:
            # é¿éšœæœºåŠ¨
            if perception.has_obstacle:
                # æ ¹æ®éšœç¢ç‰©æ–¹å‘å†³å®šé¿éšœç­–ç•¥
                if abs(perception.obstacle_direction) < math.radians(30):
                    # å‰æ–¹éšœç¢ç‰©ï¼šçˆ¬å‡
                    target_z = pos.z_val - 3
                    target_vx, target_vy = 0, 0
                else:
                    # ä¾§æ–¹éšœç¢ç‰©ï¼šå‘åæ–¹å‘å¹³ç§»
                    avoid_dir = perception.obstacle_direction + math.pi
                    target_vx = 1.5 * math.cos(avoid_dir)
                    target_vy = 1.5 * math.sin(avoid_dir)
            else:
                # éšœç¢ç‰©æ¸…é™¤ï¼Œè¿”å›æ¢ç´¢
                self.change_state(FlightState.HOVERING)
                time.sleep(1)  # é¿éšœåæš‚åœè§‚å¯Ÿ

        elif self.state == FlightState.EMERGENCY:
            # ç´§æ€¥çŠ¶æ€ï¼šæ‚¬åœå¹¶å‡†å¤‡é™è½
            target_vx, target_vy, target_yaw = 0, 0, 0
            target_z = max(pos.z_val, -20)  # é™åˆ¶çˆ¬å‡

        # ç¡®ä¿é«˜åº¦åœ¨å®‰å…¨èŒƒå›´å†…
        target_z = max(self.max_altitude, min(self.min_altitude, target_z))

        return target_vx, target_vy, target_z, target_yaw

    def change_state(self, new_state: FlightState):
        """çŠ¶æ€è½¬æ¢"""
        if self.state != new_state:
            print(f"ğŸ”„ çŠ¶æ€è½¬æ¢: {self.state.value} â†’ {new_state.value}")
            self.state = new_state
            self.state_history.append((time.time(), new_state))

    def run_perception_loop(self):
        """ä¸»æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶å¾ªç¯"""
        print("\n" + "=" * 60)
        print("å¯åŠ¨æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶å¾ªç¯")
        print("=" * 60)

        # èµ·é£
        print("ğŸš€ èµ·é£ä¸­...")
        self.client.takeoffAsync(vehicle_name=self.drone_name).join()
        time.sleep(3)
        self.change_state(FlightState.HOVERING)

        # ä¸»å¾ªç¯
        self.loop_count = 0
        exploration_start = time.time()

        while time.time() - exploration_start < self.exploration_time and not self.emergency_flag:
            loop_start = time.time()
            self.loop_count += 1

            # 1. æ„ŸçŸ¥é˜¶æ®µ
            self.perception_start = time.time()
            perception = self.get_depth_perception()

            # 2. å†³ç­–é˜¶æ®µ
            decision = self.make_intelligent_decision(perception)

            # 3. æ§åˆ¶æ‰§è¡Œé˜¶æ®µ
            target_vx, target_vy, target_z, target_yaw = decision

            # ä½¿ç”¨é€Ÿåº¦æ§åˆ¶ï¼ˆæ›´çµæ´»ï¼‰æˆ–ä½ç½®æ§åˆ¶ï¼ˆæ›´ç²¾ç¡®ï¼‰
            use_velocity_control = self.state in [FlightState.EXPLORING, FlightState.AVOIDING]

            if use_velocity_control:
                self.client.moveByVelocityZAsync(
                    target_vx, target_vy, target_z, 0.5,  # æŒç»­æ—¶é—´0.5ç§’
                    vehicle_name=self.drone_name
                )
            else:
                self.client.moveToPositionAsync(
                    0, 0, target_z, 2,  # ç›¸å¯¹å½“å‰ä½ç½®ç§»åŠ¨
                    vehicle_name=self.drone_name
                )

            # è®°å½•å½“å‰ä½ç½®
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            self.visited_positions.append((pos.x_val, pos.y_val, pos.z_val))

            # æ€§èƒ½ç›‘æ§è¾“å‡º
            if self.loop_count % 20 == 0:
                elapsed = time.time() - exploration_start
                print(f"\nğŸ“Š å¾ªç¯{self.loop_count} | å·²è¿è¡Œ{elapsed:.1f}s | çŠ¶æ€:{self.state.value}")
                print(f"   æ„ŸçŸ¥FPS:{self.perception_fps:.1f} | éšœç¢:{perception.has_obstacle}")
                print(f"   æœ€è¿‘éšœç¢:{perception.obstacle_distance:.1f}m | å¼€é˜”åº¦:{perception.open_space_score:.2f}")
                print(f"   ä½ç½®:({pos.x_val:.1f}, {pos.y_val:.1f}, {-pos.z_val:.1f}m)")
                print(f"   å®‰å…¨æ–¹å‘æ•°:{len(perception.safe_directions)}")

                # æ˜¾ç¤ºå‰è§†çª—å£çŠ¶æ€
                if hasattr(self, 'front_display'):
                    print(f"   å‰è§†çª—å£: {'æ´»è·ƒ' if self.front_display.display_active else 'å…³é—­'}")

            # å¾ªç¯é¢‘ç‡æ§åˆ¶ï¼ˆ10Hzï¼‰
            loop_time = time.time() - loop_start
            if loop_time < 0.1:
                time.sleep(0.1 - loop_time)

        # æ¢ç´¢ç»“æŸï¼Œå‡†å¤‡é™è½
        print("\n" + "=" * 60)
        print("æ¢ç´¢å®Œæˆï¼Œå¼€å§‹è¿”èˆªé™è½")
        print("=" * 60)

        self.change_state(FlightState.LANDING)
        self.return_to_start()

    def return_to_start(self):
        """è¿”å›èµ·å§‹ç‚¹é™„è¿‘å¹¶é™è½"""
        try:
            # å›åˆ°èµ·ç‚¹é™„è¿‘ï¼ˆç®€å•å®ç°ï¼šå›åˆ°åŸç‚¹ï¼‰
            print("â†©ï¸ è¿”å›èµ·å§‹åŒºåŸŸ...")
            self.client.moveToPositionAsync(0, 0, -10, 5, vehicle_name=self.drone_name).join()
            time.sleep(2)

            # é™è½
            print("ğŸ›¬ é™è½ä¸­...")
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(3)

            # æ–­å¼€æ§åˆ¶
            self.client.armDisarm(False, vehicle_name=self.drone_name)
            self.client.enableApiControl(False, vehicle_name=self.drone_name)

            # å…³é—­å‰è§†çª—å£
            if hasattr(self, 'front_display'):
                self.front_display.stop()

            print("âœ… ä»»åŠ¡å®Œæˆï¼Œç³»ç»Ÿå®‰å…¨å…³é—­")

        except Exception as e:
            print(f"âŒ é™è½å¼‚å¸¸: {e}")
            print("âš  å°è¯•ç´§æ€¥é™è½...")
            try:
                self.client.landAsync(vehicle_name=self.drone_name).join()
            except:
                pass

    def emergency_stop(self):
        """ç´§æ€¥åœæ­¢"""
        print("ğŸ†˜ ç´§æ€¥åœæ­¢è§¦å‘ï¼")
        self.emergency_flag = True
        self.change_state(FlightState.EMERGENCY)
        self.client.hoverAsync(vehicle_name=self.drone_name).join()

        # å…³é—­å‰è§†çª—å£
        if hasattr(self, 'front_display'):
            self.front_display.stop()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    try:
        # åˆ›å»ºæ„ŸçŸ¥æ¢ç´¢å™¨
        explorer = PerceptiveExplorer(drone_name="")

        # è®¾ç½®é”®ç›˜ä¸­æ–­å¤„ç†
        def signal_handler(sig, frame):
            print("\nâš  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
            explorer.emergency_stop()
            sys.exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        # è¿è¡Œä¸»å¾ªç¯
        explorer.run_perception_loop()

    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

        # å°è¯•å®‰å…¨é™è½
        try:
            client = airsim.MultirotorClient()
            client.landAsync().join()
            client.armDisarm(False)
            client.enableApiControl(False)
        except:
            pass


if __name__ == "__main__":
    print("=" * 70)
    print("é‡è¦æç¤ºï¼š")
    print("1. è¦è·å¾—é«˜æ¸…ç”»é¢ï¼Œè¯·ä¿®æ”¹AirSimçš„settings.jsoné…ç½®æ–‡ä»¶")
    print("   æé«˜ç›¸æœºåˆ†è¾¨ç‡ï¼ˆå¦‚1280x720ï¼‰")
    print("2. å½“å‰ä»£ç å·²é›†æˆå›¾åƒé”åŒ–å¤„ç†æ”¹å–„æ¨¡ç³Š")
    print("3. å‰è§†çª—å£æ”¯æŒäº¤äº’æ§åˆ¶ï¼ˆæŒ‰Hé”®åˆ‡æ¢é”åŒ–ï¼‰")
    print("=" * 70)
    main()