import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# å¯¼å…¥å…¶ä»–æ¨¡å—çš„åŠŸèƒ½
from Data_classfication import split_dataset
from image_classification import ImageDataset, ImageClassifier, train_pytorch_model
from visual_navigation import run_visual_navigation
from é¢„æµ‹ import predict_image, predict_directory

# è·¯å¾„è®¾ç½®
base_dir = os.path.abspath("./data")  # ä¿®æ”¹ä¸ºå½“å‰ç›®å½•ä¸‹çš„data
train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "test")
dataset_dir = os.path.join(base_dir, "dataset")

def setup_directories():
    """è®¾ç½®æ•°æ®ç›®å½•"""
    print("=" * 50)
    
    # æ£€æŸ¥å¹¶åˆ›å»ºç›®å½•
    os.makedirs(base_dir, exist_ok=True)
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å‰²æ•°æ®é›†
    if not os.path.exists(train_dir) or not os.listdir(train_dir):
        print("è®­ç»ƒé›†ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå¼€å§‹è‡ªåŠ¨åˆ†å‰²æ•°æ®é›†...")
        if os.path.exists(dataset_dir):
            success = split_dataset(dataset_dir, train_dir, test_dir, split_ratio=0.8)
            if not success:
                print("âŒ æ•°æ®é›†åˆ†å‰²å¤±è´¥ï¼Œè¯·æ£€æŸ¥åŸå§‹æ•°æ®é›†è·¯å¾„")
                return False
        else:
            print(f"âŒ åŸå§‹æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_dir}")
            print("è¯·å°†æ•°æ®é›†æ”¾å…¥ ./data/dataset/ ç›®å½•")
            return False
    else:
        print("âœ… è®­ç»ƒé›†å·²å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®é›†åˆ†å‰²æ­¥éª¤")
    
    return True

def train_tensorflow_model():
    """ä½¿ç”¨TensorFlowè®­ç»ƒæ¨¡å‹"""
    print("\n" + "=" * 50)
    print("å¼€å§‹TensorFlowæ¨¡å‹è®­ç»ƒ...")
    
    # æ¨¡å‹å‚æ•°è®¾ç½®
    img_size = (128, 128)
    batch_size = 32
    epochs = 70

    # å›¾åƒæ•°æ®é¢„å¤„ç†ä¸å¢å¼º
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=30,
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True
    )

    # æµ‹è¯•é›†æ•°æ®é¢„å¤„ç†
    test_datagen = ImageDataGenerator(rescale=1./255)

    # åˆ›å»ºè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
    train_gen = train_datagen.flow_from_directory(
        train_dir,
        target_size=img_size,
        batch_size=batch_size,
        class_mode="categorical"
    )

    # åˆ›å»ºæµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
    test_gen = test_datagen.flow_from_directory(
        test_dir,
        target_size=img_size,
        batch_size=batch_size,
        class_mode="categorical"
    )

    # å¯¼å…¥è¿ç§»å­¦ä¹ ç›¸å…³æ¨¡å—
    from tensorflow.keras.applications import MobileNetV2
    from tensorflow.keras.layers import GlobalAveragePooling2D

    # åŠ è½½é¢„è®­ç»ƒçš„MobileNetV2åŸºç¡€æ¨¡å‹
    base_model = MobileNetV2(
        input_shape=(128, 128, 3),
        include_top=False,
        weights='imagenet'
    )
    base_model.trainable = False

    # æ„å»ºè¿ç§»å­¦ä¹ æ¨¡å‹
    model = tf.keras.Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(128, activation="relu"),
        Dropout(0.5),
        Dense(train_gen.num_classes, activation="softmax")
    ])

    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer="adam",
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )

    # æ‰“å°æ¨¡å‹ç»“æ„æ‘˜è¦
    model.summary()

    # è®¾ç½®è®­ç»ƒå›è°ƒå‡½æ•°
    early_stop = EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    )

    checkpoint = ModelCheckpoint(
        filepath=os.path.join(base_dir, "best_tensorflow_model.h5"),
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )

    # å¼€å§‹è®­ç»ƒæ¨¡å‹
    history = model.fit(
        train_gen,
        epochs=epochs,
        validation_data=test_gen,
        callbacks=[early_stop, checkpoint]
    )

    # ä¿å­˜æœ€ç»ˆè®­ç»ƒå®Œæˆçš„æ¨¡å‹
    model.save(os.path.join(base_dir, "cnn_model.h5"))
    print("âœ… TensorFlowæ¨¡å‹è®­ç»ƒå®Œæˆå¹¶å·²ä¿å­˜ã€‚")
    
    return model, train_gen, test_gen

def train_pytorch_model_wrapper():
    """ä½¿ç”¨PyTorchè®­ç»ƒæ¨¡å‹"""
    print("\n" + "=" * 50)
    print("å¼€å§‹PyTorchæ¨¡å‹è®­ç»ƒ...")
    
    # è°ƒç”¨tuxianfenlei.pyä¸­çš„è®­ç»ƒå‡½æ•°
    model, train_losses, val_accuracies = train_pytorch_model(
        base_dir=base_dir,
        train_dir=train_dir,
        test_dir=test_dir,
        img_size=(128, 128),
        batch_size=32,
        epochs=70
    )
    
    print("âœ… PyTorchæ¨¡å‹è®­ç»ƒå®Œæˆã€‚")
    return model, train_losses, val_accuracies

def analyze_errors(model, test_gen, class_labels, num_samples=16):
    """
    åˆ†ææ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„é”™è¯¯åˆ†ç±»æƒ…å†µ
    """
    # é‡ç½®æµ‹è¯•ç”Ÿæˆå™¨
    test_gen.reset()

    # è·å–æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
    predictions = model.predict(test_gen, verbose=1)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = test_gen.classes

    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = np.mean(predicted_classes == true_classes)
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")

    # åˆ†ç±»æŠ¥å‘Š
    print("\nåˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(true_classes, predicted_classes, target_names=class_labels))

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(true_classes, predicted_classes)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_labels, yticklabels=class_labels)
    plt.title('æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.savefig(os.path.join(base_dir, 'confusion_matrix.png'))
    plt.show()

    # æ‰¾å‡ºé”™è¯¯åˆ†ç±»çš„æ ·æœ¬
    misclassified_indices = np.where(predicted_classes != true_classes)[0]

    print(f"\næ€»é”™è¯¯åˆ†ç±»æ ·æœ¬æ•°: {len(misclassified_indices)}")
    print(f"æ€»æ ·æœ¬æ•°: {len(true_classes)}")
    print(f"é”™è¯¯ç‡: {len(misclassified_indices) / len(true_classes):.4f}")

    return misclassified_indices

def run_error_analysis():
    """è¿è¡Œé”™è¯¯åˆ†æ"""
    print("\n" + "=" * 50)
    print("å¼€å§‹é”™è¯¯åˆ†æ...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œé”™è¯¯åˆ†æ
    best_model_path = os.path.join(base_dir, "best_tensorflow_model.h5")
    if os.path.exists(best_model_path):
        print("åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œé”™è¯¯åˆ†æ...")
        best_model = tf.keras.models.load_model(best_model_path)
        
        # é‡æ–°åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨ä»¥è·å–ç±»åˆ«ä¿¡æ¯
        test_datagen = ImageDataGenerator(rescale=1./255)
        test_gen = test_datagen.flow_from_directory(
            test_dir,
            target_size=(128, 128),
            batch_size=32,
            class_mode="categorical",
            shuffle=False
        )
        
        class_labels = list(test_gen.class_indices.keys())
        misclassified_indices = analyze_errors(best_model, test_gen, class_labels)
    else:
        print("âŒ æœ€ä½³æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œé”™è¯¯åˆ†æ")
    
    print("\né”™è¯¯åˆ†æå®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å›¾åƒåˆ†ç±»ç³»ç»Ÿ...")
    
    # 1. è®¾ç½®æ•°æ®ç›®å½•
    if not setup_directories():
        return
    
    # 2. è®­ç»ƒTensorFlowæ¨¡å‹
    tf_model, train_gen, test_gen = train_tensorflow_model()
    
    # 3. è®­ç»ƒPyTorchæ¨¡å‹
    pytorch_model, train_losses, val_accuracies = train_pytorch_model_wrapper()
    
    # 4. é”™è¯¯åˆ†æ
    run_error_analysis()
    
    # 5. å¯åŠ¨è§†è§‰å¯¼èˆªï¼ˆå¯é€‰ï¼‰
    print("\n" + "=" * 50)
    choice = input("æ˜¯å¦å¯åŠ¨è§†è§‰å¯¼èˆªç³»ç»Ÿï¼Ÿ(y/n): ")
    if choice.lower() == 'y':
        run_visual_navigation()
    
    # 6. æä¾›é¢„æµ‹åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
    print("\n" + "=" * 50)
    choice = input("æ˜¯å¦è¿›è¡Œå›¾åƒé¢„æµ‹ï¼Ÿ(y/n): ")
    if choice.lower() == 'y':
        test_image_path = input("è¯·è¾“å…¥æµ‹è¯•å›¾åƒè·¯å¾„ï¼ˆæˆ–ç›®å½•ï¼‰: ")
        if os.path.exists(test_image_path):
            if os.path.isdir(test_image_path):
                results = predict_directory(
                    os.path.join(base_dir, "best_model.pth"),
                    test_image_path,
                    train_dir
                )
            else:
                result = predict_image(
                    os.path.join(base_dir, "best_model.pth"),
                    test_image_path,
                    train_dir
                )
        else:
            print("âŒ æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨")
    
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
