"""
AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢æ— äººæœº
æ ¸å¿ƒï¼šè§†è§‰æ„ŸçŸ¥ â†’ è¯­ä¹‰ç†è§£ â†’ æ™ºèƒ½å†³ç­– â†’ å®‰å…¨æ‰§è¡Œ
é›†æˆå‰è§†çª—å£ç‰ˆæœ¬ - æ”¯æŒå®æ—¶è§†è§‰ç›‘æ§
"""

import airsim
import time
import numpy as np
import cv2
import math
from collections import deque
from dataclasses import dataclass
from enum import Enum
import threading
from typing import Tuple, List, Optional

# ============== æ–°å¢ï¼šå¯¼å…¥é˜Ÿåˆ—æ¨¡å— ==============
import queue


class FlightState(Enum):
    """æ— äººæœºçŠ¶æ€æšä¸¾"""
    TAKEOFF = "èµ·é£"
    HOVERING = "æ‚¬åœè§‚æµ‹"
    EXPLORING = "ä¸»åŠ¨æ¢ç´¢"
    AVOIDING = "é¿éšœæœºåŠ¨"
    LANDING = "é™è½"
    EMERGENCY = "ç´§æ€¥çŠ¶æ€"


@dataclass
class PerceptionResult:
    """æ„ŸçŸ¥ç»“æœæ•°æ®ç»“æ„"""
    has_obstacle: bool = False
    obstacle_distance: float = 100.0
    obstacle_direction: float = 0.0  # éšœç¢ç‰©ç›¸å¯¹æ–¹å‘ï¼ˆå¼§åº¦ï¼‰
    terrain_slope: float = 0.0  # åœ°å½¢å¡åº¦
    open_space_score: float = 0.0  # å¼€é˜”åº¦è¯„åˆ† (0-1)
    recommended_height: float = -15.0  # æ¨èé£è¡Œé«˜åº¦
    safe_directions: List[float] = None  # å®‰å…¨æ–¹å‘åˆ—è¡¨
    # ========== æ–°å¢ï¼šå‰è§†å›¾åƒå­—æ®µ ==========
    front_image: Optional[np.ndarray] = None  # å‰è§†å›¾åƒ

    def __post_init__(self):
        if self.safe_directions is None:
            self.safe_directions = []


class PerceptiveExplorer:
    """åŸºäºæ„ŸçŸ¥çš„è‡ªä¸»æ¢ç´¢æ— äººæœº"""

    def __init__(self, drone_name=""):
        print("=" * 60)
        print("AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢ç³»ç»Ÿ")
        print("=" * 60)

        # åˆå§‹åŒ–AirSimè¿æ¥
        self.client = airsim.MultirotorClient()
        self.client.confirmConnection()
        self.drone_name = drone_name

        # å¯ç”¨APIæ§åˆ¶
        self.client.enableApiControl(True, vehicle_name=drone_name)
        self.client.armDisarm(True, vehicle_name=drone_name)

        # çŠ¶æ€ç®¡ç†
        self.state = FlightState.TAKEOFF
        self.state_history = deque(maxlen=20)
        self.emergency_flag = False

        # æ„ŸçŸ¥å‚æ•°
        self.depth_threshold_near = 5.0  # è¿‘è·ç¦»è­¦æŠ¥é˜ˆå€¼(ç±³)
        self.depth_threshold_safe = 10.0  # å®‰å…¨è·ç¦»é˜ˆå€¼(ç±³)
        self.min_ground_clearance = 2.0  # æœ€å°ç¦»åœ°é—´éš™(ç±³)
        self.max_pitch_angle = math.radians(15)  # æœ€å¤§å…è®¸ä¿¯ä»°è§’

        # æ¢ç´¢å‚æ•°
        self.exploration_time = 180  # æ€»æ¢ç´¢æ—¶é—´(ç§’)
        self.preferred_speed = 3.0  # ä¼˜é€‰é€Ÿåº¦(m/s)
        self.max_altitude = -30  # æœ€å¤§æµ·æ‹”(ç±³)
        self.min_altitude = -8  # æœ€å°æµ·æ‹”(ç±³)

        # è®°å¿†ç³»ç»Ÿ
        self.visited_positions = deque(maxlen=100)
        self.obstacle_map = {}  # éšœç¢ç‰©ä½ç½®è®°å¿†
        self.traversability_map = {}  # åœ°å½¢å¯é€šè¡Œæ€§è®°å¿†

        # æ€§èƒ½ç›‘æ§
        self.perception_fps = 0
        self.decision_fps = 0
        self.start_time = time.time()

        # ========== æ–°å¢ï¼šå‰è§†çª—å£åˆå§‹åŒ– ==========
        self.front_display = FrontViewDisplay(
            window_name=f"æ— äººæœºå‰è§† - {drone_name or 'AirSimNH'}"
        )
        print("ğŸ¥ å‰è§†çª—å£å·²åˆå§‹åŒ–")

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
        print(f"   é¢„è®¡æ¢ç´¢æ—¶é•¿: {self.exploration_time}ç§’")

    def get_depth_perception(self) -> PerceptionResult:
        """è·å–å¹¶åˆ†ææ·±åº¦å›¾åƒï¼Œç†è§£ç¯å¢ƒ"""
        result = PerceptionResult()

        try:
            # ========== ä¿®æ”¹ï¼šåŒæ—¶è·å–æ·±åº¦å›¾åƒå’Œå‰è§†å›¾åƒ ==========
            responses = self.client.simGetImages([
                airsim.ImageRequest(
                    "0",
                    airsim.ImageType.DepthPlanar,
                    pixels_as_float=True,
                    compress=False
                ),
                # æ–°å¢ï¼šè·å–å‰è§†RGBå›¾åƒ
                airsim.ImageRequest(
                    "0",
                    airsim.ImageType.Scene,
                    False,
                    False
                )
            ])

            if not responses or len(responses) < 2:
                print("âš  å›¾åƒè·å–å¤±è´¥")
                return result

            # å¤„ç†æ·±åº¦å›¾åƒï¼ˆåŸé€»è¾‘ï¼‰
            depth_img = responses[0]
            depth_array = np.array(depth_img.image_data_float, dtype=np.float32)
            depth_array = depth_array.reshape(depth_img.height, depth_img.width)

            # åˆ†ææ·±åº¦å›¾åƒçš„ä¸åŒåŒºåŸŸ
            h, w = depth_array.shape

            # 1. å‰æ–¹è¿‘è·ç¦»åŒºåŸŸï¼ˆç´§æ€¥é¿éšœï¼‰
            front_near = depth_array[h // 2:, w // 3:2 * w // 3]
            min_front_distance = np.min(front_near) if front_near.size > 0 else 100

            # 2. å¤šæ–¹å‘æ‰‡å½¢æ‰«æ
            directions = []
            scan_angles = [-45, -30, -15, 0, 15, 30, 45]  # åº¦

            for angle_deg in scan_angles:
                angle_rad = math.radians(angle_deg)
                # è®¡ç®—å¯¹åº”å›¾åƒåˆ—
                col = int(w / 2 + (w / 2) * math.tan(angle_rad) * 0.5)
                col = max(0, min(w - 1, col))

                # åˆ†æè¯¥åˆ—çš„æ·±åº¦
                col_data = depth_array[h // 2:, col]
                if col_data.size > 0:
                    dir_distance = np.percentile(col_data, 25)  # ä½¿ç”¨25%åˆ†ä½æ•°ï¼ˆè¾ƒä¿å®ˆï¼‰
                    directions.append((angle_rad, dir_distance))

                    if dir_distance > self.depth_threshold_safe:
                        result.safe_directions.append(angle_rad)

            # 3. åœ°å½¢åˆ†æï¼ˆé€šè¿‡æ·±åº¦æ¢¯åº¦ä¼°è®¡å¡åº¦ï¼‰
            ground_region = depth_array[3 * h // 4:, :]
            if ground_region.size > 10:
                row_variances = np.var(ground_region, axis=1)
                result.terrain_slope = np.mean(row_variances) * 100

            # 4. å¼€é˜”åº¦è¯„åˆ†ï¼ˆåŸºäºæœ‰æ•ˆè·ç¦»åƒç´ æ¯”ä¾‹ï¼‰
            open_pixels = np.sum(depth_array[h // 2:, :] > self.depth_threshold_safe)
            total_pixels = depth_array[h // 2:, :].size
            result.open_space_score = open_pixels / total_pixels if total_pixels > 0 else 0

            # æ•´åˆæ„ŸçŸ¥ç»“æœ
            result.has_obstacle = min_front_distance < self.depth_threshold_near
            result.obstacle_distance = min_front_distance

            if directions:
                # æ‰¾å‡ºæœ€è¿‘éšœç¢ç‰©çš„æ–¹å‘
                closest_dir = min(directions, key=lambda x: x[1])
                result.obstacle_direction = closest_dir[0]

            # æ ¹æ®æ„ŸçŸ¥åŠ¨æ€è°ƒæ•´æ¨èé«˜åº¦
            if result.terrain_slope > 5:
                result.recommended_height = -20  # é™¡å³­åœ°å½¢é£é«˜äº›
            elif result.open_space_score > 0.7:
                result.recommended_height = -12  # å¼€é˜”åœ°å¸¦å¯ä»¥é£ä½äº›
            else:
                result.recommended_height = -15  # é»˜è®¤é«˜åº¦

            # ========== æ–°å¢ï¼šå¤„ç†å‰è§†å›¾åƒ ==========
            front_response = responses[1]
            if front_response and front_response.image_data_uint8:
                # è½¬æ¢å›¾åƒæ ¼å¼
                img_array = np.frombuffer(front_response.image_data_uint8, dtype=np.uint8)
                img_rgb = img_array.reshape(front_response.height, front_response.width, 3)
                img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
                result.front_image = img_bgr

                # å‡†å¤‡æ˜¾ç¤ºä¿¡æ¯
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                pos = state.kinematics_estimated.position
                display_info = {
                    'state': self.state.value,
                    'obstacle_distance': result.obstacle_distance,
                    'position': (pos.x_val, pos.y_val, pos.z_val)
                }

                # æ›´æ–°å‰è§†çª—å£
                self.front_display.update_image(img_bgr, display_info)

            # æ›´æ–°æ„ŸçŸ¥FPS
            self.perception_fps = 1 / (time.time() - self.perception_start)

        except Exception as e:
            print(f"âŒ æ·±åº¦æ„ŸçŸ¥å¼‚å¸¸: {e}")

        return result

    # æ³¨æ„ï¼šget_visual_perception æ–¹æ³•ç°åœ¨å¯èƒ½å¤šä½™ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§ä¿ç•™
    def get_visual_perception(self):
        """è·å–è§†è§‰å›¾åƒç”¨äºé«˜çº§æ„ŸçŸ¥ï¼ˆå¯é€‰ï¼‰"""
        try:
            responses = self.client.simGetImages([
                airsim.ImageRequest("0", airsim.ImageType.Scene, False, False)
            ])

            if responses and responses[0]:
                # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                img_data = responses[0].image_data_uint8
                img_array = np.frombuffer(img_data, dtype=np.uint8)
                img = img_array.reshape(responses[0].height, responses[0].width, 3)

                # ç®€å•é¢œè‰²åˆ†æï¼ˆç¤ºä¾‹ï¼šå¯»æ‰¾ç»¿è‰²æ¤è¢«åŒºåŸŸï¼‰
                hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
                green_mask = cv2.inRange(hsv, (40, 40, 40), (80, 255, 255))
                green_ratio = np.sum(green_mask > 0) / green_mask.size

                return img, green_ratio
        except:
            pass

        return None, 0

    def make_intelligent_decision(self, perception: PerceptionResult) -> Tuple[float, float, float, float]:
        """åŸºäºæ„ŸçŸ¥ç»“æœåšå‡ºæ™ºèƒ½å†³ç­–"""

        # è·å–å½“å‰ä½ç½®å’ŒçŠ¶æ€
        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
        pos = state.kinematics_estimated.position
        vel = state.kinematics_estimated.linear_velocity

        # åŸºç¡€å†³ç­–ï¼šé€Ÿåº¦ã€åèˆªã€é«˜åº¦
        target_vx, target_vy, target_z, target_yaw = 0.0, 0.0, perception.recommended_height, 0.0

        # çŠ¶æ€æœºå†³ç­–é€»è¾‘
        if self.state == FlightState.TAKEOFF:
            target_z = -10  # èµ·é£åˆ°10ç±³
            if pos.z_val < -9.5:
                self.change_state(FlightState.HOVERING)

        elif self.state == FlightState.HOVERING:
            # æ‚¬åœè§‚å¯Ÿï¼Œç¼“æ…¢æ—‹è½¬æ‰«æ
            target_yaw = (time.time() % 10) * 0.2  # ç¼“æ…¢æ—‹è½¬

            if len(perception.safe_directions) > 0:
                self.change_state(FlightState.EXPLORING)

        elif self.state == FlightState.EXPLORING:
            # ä¸»åŠ¨æ¢ç´¢æ¨¡å¼
            if perception.has_obstacle:
                self.change_state(FlightState.AVOIDING)
                # ç´§æ€¥åˆ¶åŠ¨
                target_vx, target_vy = -vel.x_val, -vel.y_val
            else:
                # é€‰æ‹©æœ€ä½³æ¢ç´¢æ–¹å‘
                if perception.safe_directions:
                    # ä¼˜å…ˆé€‰æ‹©ä¸å½“å‰èˆªå‘ç›¸å·®45-90åº¦çš„æ–°æ–¹å‘ï¼ˆé¿å…æ¥å›æ‘†åŠ¨ï¼‰
                    current_yaw = airsim.to_eularian_angles(
                        state.kinematics_estimated.orientation
                    )[2]

                    # è¿‡æ»¤å‡ºä¸å½“å‰æ–¹å‘ä¸åŒçš„å®‰å…¨æ–¹å‘
                    diverse_dirs = [
                        d for d in perception.safe_directions
                        if abs(d - current_yaw) > math.radians(45)
                    ]

                    if diverse_dirs:
                        best_dir = diverse_dirs[0]
                    else:
                        best_dir = perception.safe_directions[0]

                    # è®¾ç½®å‰è¿›é€Ÿåº¦
                    speed_factor = min(1.0, perception.open_space_score * 1.5)
                    target_vx = self.preferred_speed * speed_factor * math.cos(best_dir)
                    target_vy = self.preferred_speed * speed_factor * math.sin(best_dir)
                else:
                    # æ²¡æœ‰å®‰å…¨æ–¹å‘ï¼Œçˆ¬å‡
                    target_z = pos.z_val - 5
                    self.change_state(FlightState.AVOIDING)

        elif self.state == FlightState.AVOIDING:
            # é¿éšœæœºåŠ¨
            if perception.has_obstacle:
                # æ ¹æ®éšœç¢ç‰©æ–¹å‘å†³å®šé¿éšœç­–ç•¥
                if abs(perception.obstacle_direction) < math.radians(30):
                    # å‰æ–¹éšœç¢ç‰©ï¼šçˆ¬å‡
                    target_z = pos.z_val - 3
                    target_vx, target_vy = 0, 0
                else:
                    # ä¾§æ–¹éšœç¢ç‰©ï¼šå‘åæ–¹å‘å¹³ç§»
                    avoid_dir = perception.obstacle_direction + math.pi
                    target_vx = 1.5 * math.cos(avoid_dir)
                    target_vy = 1.5 * math.sin(avoid_dir)
            else:
                # éšœç¢ç‰©æ¸…é™¤ï¼Œè¿”å›æ¢ç´¢
                self.change_state(FlightState.HOVERING)
                time.sleep(1)  # é¿éšœåæš‚åœè§‚å¯Ÿ

        elif self.state == FlightState.EMERGENCY:
            # ç´§æ€¥çŠ¶æ€ï¼šæ‚¬åœå¹¶å‡†å¤‡é™è½
            target_vx, target_vy, target_yaw = 0, 0, 0
            target_z = max(pos.z_val, -20)  # é™åˆ¶çˆ¬å‡

        # ç¡®ä¿é«˜åº¦åœ¨å®‰å…¨èŒƒå›´å†…
        target_z = max(self.max_altitude, min(self.min_altitude, target_z))

        return target_vx, target_vy, target_z, target_yaw

    def change_state(self, new_state: FlightState):
        """çŠ¶æ€è½¬æ¢"""
        if self.state != new_state:
            print(f"ğŸ”„ çŠ¶æ€è½¬æ¢: {self.state.value} â†’ {new_state.value}")
            self.state = new_state
            self.state_history.append((time.time(), new_state))

    def run_perception_loop(self):
        """ä¸»æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶å¾ªç¯"""
        print("\n" + "=" * 60)
        print("å¯åŠ¨æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶å¾ªç¯")
        print("=" * 60)

        # èµ·é£
        print("ğŸš€ èµ·é£ä¸­...")
        self.client.takeoffAsync(vehicle_name=self.drone_name).join()
        time.sleep(3)
        self.change_state(FlightState.HOVERING)

        # ä¸»å¾ªç¯
        loop_count = 0
        exploration_start = time.time()

        while time.time() - exploration_start < self.exploration_time and not self.emergency_flag:
            loop_start = time.time()
            loop_count += 1

            # 1. æ„ŸçŸ¥é˜¶æ®µ
            self.perception_start = time.time()
            perception = self.get_depth_perception()
            # visual_img, green_ratio = self.get_visual_perception()  # å¯é€‰

            # 2. å†³ç­–é˜¶æ®µ
            decision = self.make_intelligent_decision(perception)

            # 3. æ§åˆ¶æ‰§è¡Œé˜¶æ®µ
            target_vx, target_vy, target_z, target_yaw = decision

            # ä½¿ç”¨é€Ÿåº¦æ§åˆ¶ï¼ˆæ›´çµæ´»ï¼‰æˆ–ä½ç½®æ§åˆ¶ï¼ˆæ›´ç²¾ç¡®ï¼‰
            use_velocity_control = self.state in [FlightState.EXPLORING, FlightState.AVOIDING]

            if use_velocity_control:
                self.client.moveByVelocityZAsync(
                    target_vx, target_vy, target_z, 0.5,  # æŒç»­æ—¶é—´0.5ç§’
                    vehicle_name=self.drone_name
                )
            else:
                self.client.moveToPositionAsync(
                    0, 0, target_z, 2,  # ç›¸å¯¹å½“å‰ä½ç½®ç§»åŠ¨
                    vehicle_name=self.drone_name
                )

            # è®°å½•å½“å‰ä½ç½®
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            self.visited_positions.append((pos.x_val, pos.y_val, pos.z_val))

            # æ€§èƒ½ç›‘æ§è¾“å‡º
            if loop_count % 20 == 0:
                elapsed = time.time() - exploration_start
                print(f"\nğŸ“Š å¾ªç¯{loop_count} | å·²è¿è¡Œ{elapsed:.1f}s | çŠ¶æ€:{self.state.value}")
                print(f"   æ„ŸçŸ¥FPS:{self.perception_fps:.1f} | éšœç¢:{perception.has_obstacle}")
                print(f"   æœ€è¿‘éšœç¢:{perception.obstacle_distance:.1f}m | å¼€é˜”åº¦:{perception.open_space_score:.2f}")
                print(f"   ä½ç½®:({pos.x_val:.1f}, {pos.y_val:.1f}, {-pos.z_val:.1f}m)")
                print(f"   å®‰å…¨æ–¹å‘æ•°:{len(perception.safe_directions)}")

            # å¾ªç¯é¢‘ç‡æ§åˆ¶ï¼ˆ10Hzï¼‰
            loop_time = time.time() - loop_start
            if loop_time < 0.1:
                time.sleep(0.1 - loop_time)

        # æ¢ç´¢ç»“æŸï¼Œå‡†å¤‡é™è½
        print("\n" + "=" * 60)
        print("æ¢ç´¢å®Œæˆï¼Œå¼€å§‹è¿”èˆªé™è½")
        print("=" * 60)

        self.change_state(FlightState.LANDING)
        self.return_to_start()

    def return_to_start(self):
        """è¿”å›èµ·å§‹ç‚¹é™„è¿‘å¹¶é™è½"""
        try:
            # å›åˆ°èµ·ç‚¹é™„è¿‘ï¼ˆç®€å•å®ç°ï¼šå›åˆ°åŸç‚¹ï¼‰
            print("â†©ï¸ è¿”å›èµ·å§‹åŒºåŸŸ...")
            self.client.moveToPositionAsync(0, 0, -10, 5, vehicle_name=self.drone_name).join()
            time.sleep(2)

            # é™è½
            print("ğŸ›¬ é™è½ä¸­...")
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(3)

            # æ–­å¼€æ§åˆ¶
            self.client.armDisarm(False, vehicle_name=self.drone_name)
            self.client.enableApiControl(False, vehicle_name=self.drone_name)

            # ========== æ–°å¢ï¼šå…³é—­å‰è§†çª—å£ ==========
            self.front_display.stop()

            print("âœ… ä»»åŠ¡å®Œæˆï¼Œç³»ç»Ÿå®‰å…¨å…³é—­")

        except Exception as e:
            print(f"âŒ é™è½å¼‚å¸¸: {e}")
            print("âš  å°è¯•ç´§æ€¥é™è½...")
            try:
                self.client.landAsync(vehicle_name=self.drone_name).join()
            except:
                pass

    def emergency_stop(self):
        """ç´§æ€¥åœæ­¢"""
        print("ğŸ†˜ ç´§æ€¥åœæ­¢è§¦å‘ï¼")
        self.emergency_flag = True
        self.change_state(FlightState.EMERGENCY)
        self.client.hoverAsync(vehicle_name=self.drone_name).join()

        # ========== æ–°å¢ï¼šå…³é—­å‰è§†çª—å£ ==========
        self.front_display.stop()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    try:
        # åˆ›å»ºæ„ŸçŸ¥æ¢ç´¢å™¨
        explorer = PerceptiveExplorer(drone_name="")

        # è®¾ç½®é”®ç›˜ä¸­æ–­å¤„ç†
        import signal
        def signal_handler(sig, frame):
            print("\nâš  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
            explorer.emergency_stop()
            exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        # è¿è¡Œä¸»å¾ªç¯
        explorer.run_perception_loop()

    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

        # å°è¯•å®‰å…¨é™è½
        try:
            client = airsim.MultirotorClient()
            client.landAsync().join()
            client.armDisarm(False)
            client.enableApiControl(False)
        except:
            pass


# ============== æ–°å¢ï¼šå‰è§†çª—å£æ˜¾ç¤ºç±» ==============
class FrontViewDisplay:
    """å‰è§†ç”»é¢æ˜¾ç¤ºç®¡ç†å™¨"""

    def __init__(self, window_name="æ— äººæœºå‰è§†ç”»é¢", width=640, height=480):
        self.window_name = window_name
        self.window_width = width
        self.window_height = height

        # å›¾åƒé˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self.image_queue = queue.Queue(maxsize=2)
        self.display_active = True
        self.display_thread = None

        # æ˜¾ç¤ºçŠ¶æ€
        self.paused = False
        self.show_info = True
        self.enable_sharpening = True  # å¯ç”¨é”åŒ–æ”¹å–„æ¨¡ç³Š

        # å¯åŠ¨æ˜¾ç¤ºçº¿ç¨‹
        self.start()

    def start(self):
        """å¯åŠ¨æ˜¾ç¤ºçº¿ç¨‹"""
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="FrontViewDisplay"
        )
        self.display_thread.start()

    def stop(self):
        """åœæ­¢æ˜¾ç¤ºçº¿ç¨‹"""
        self.display_active = False
        if self.display_thread:
            self.display_thread.join(timeout=2.0)

    def update_image(self, image_data: np.ndarray, info: dict):
        """æ›´æ–°è¦æ˜¾ç¤ºçš„å›¾åƒ"""
        if not self.display_active or self.paused or image_data is None:
            return

        try:
            # å›¾åƒå¢å¼ºï¼ˆé”åŒ–å¤„ç†ï¼‰
            if self.enable_sharpening and image_data is not None:
                kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
                image_data = cv2.filter2D(image_data, -1, kernel)

            # å¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæœ€æ—§çš„ä¸€å¸§
            if self.image_queue.full():
                try:
                    self.image_queue.get_nowait()
                except queue.Empty:
                    pass

            display_packet = {
                'image': image_data.copy(),
                'info': info.copy() if info else {},
                'timestamp': time.time()
            }

            self.image_queue.put_nowait(display_packet)

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°å›¾åƒæ—¶å‡ºé”™: {e}")

    def _display_loop(self):
        """æ˜¾ç¤ºçº¿ç¨‹ä¸»å¾ªç¯"""
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        print("ğŸ’¡ å‰è§†çª—å£æ§åˆ¶:")
        print("   - æŒ‰ 'Q': å…³é—­çª—å£ | 'S': ä¿å­˜æˆªå›¾")
        print("   - æŒ‰ 'P': æš‚åœ/ç»§ç»­ | 'I': åˆ‡æ¢ä¿¡æ¯æ˜¾ç¤º")
        print("   - æŒ‰ 'H': åˆ‡æ¢é”åŒ–æ•ˆæœ")

        while self.display_active:
            display_image = None
            info = {}

            try:
                # è·å–æœ€æ–°å›¾åƒ
                if not self.image_queue.empty():
                    packet = self.image_queue.get_nowait()
                    display_image = packet['image']
                    info = packet['info']

                    # æ¸…ç©ºé˜Ÿåˆ—ä¸­çš„æ—§å¸§
                    while not self.image_queue.empty():
                        self.image_queue.get_nowait()
            except queue.Empty:
                pass

            # æ˜¾ç¤ºå›¾åƒ
            if display_image is not None:
                # æ·»åŠ ä¿¡æ¯å åŠ 
                if self.show_info:
                    display_image = self._add_info_overlay(display_image, info)

                cv2.imshow(self.window_name, display_image)

            # é”®ç›˜äº‹ä»¶å¤„ç†
            key = cv2.waitKey(30) & 0xFF

            if key == ord('q') or key == ord('Q'):
                print("ğŸ”„ ç”¨æˆ·å…³é—­æ˜¾ç¤ºçª—å£")
                self.display_active = False
                break
            elif key == ord('s') or key == ord('S'):
                self._save_screenshot(display_image)
            elif key == ord('p') or key == ord('P'):
                self.paused = not self.paused
                status = "å·²æš‚åœ" if self.paused else "å·²æ¢å¤"
                print(f"â¸ï¸ è§†é¢‘æµ{status}")
            elif key == ord('i') or key == ord('I'):
                self.show_info = not self.show_info
                status = "å¼€å¯" if self.show_info else "å…³é—­"
                print(f"ğŸ“Š ä¿¡æ¯å åŠ å±‚{status}")
            elif key == ord('h') or key == ord('H'):
                self.enable_sharpening = not self.enable_sharpening
                status = "å¼€å¯" if self.enable_sharpening else "å…³é—­"
                print(f"ğŸ” å›¾åƒé”åŒ–{status}")

        cv2.destroyWindow(self.window_name)

    def _add_info_overlay(self, image: np.ndarray, info: dict) -> np.ndarray:
        """åœ¨å›¾åƒä¸Šå åŠ çŠ¶æ€ä¿¡æ¯"""
        try:
            height, width = image.shape[:2]

            # åˆ›å»ºåŠé€æ˜ä¿¡æ¯æ 
            info_height = 80
            overlay = image.copy()
            cv2.rectangle(overlay, (0, 0), (width, info_height), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)

            # é£è¡ŒçŠ¶æ€
            state = info.get('state', 'UNKNOWN')
            state_color = (0, 255, 0) if 'æ¢ç´¢' in state else (0, 255, 255) if 'æ‚¬åœ' in state else (0, 0, 255)
            cv2.putText(image, f"çŠ¶æ€: {state}", (10, 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, state_color, 2)

            # ä½ç½®ä¿¡æ¯
            pos = info.get('position', (0, 0, 0))
            cv2.putText(image, f"ä½ç½®: ({pos[0]:.1f}, {pos[1]:.1f}, {-pos[2]:.1f}m)", (10, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            # éšœç¢ç‰©ä¿¡æ¯
            obs_dist = info.get('obstacle_distance', 0.0)
            if obs_dist < 100:
                obs_color = (0, 0, 255) if obs_dist < 5.0 else (0, 165, 255) if obs_dist < 10.0 else (0, 255, 0)
                cv2.putText(image, f"éšœç¢: {obs_dist:.1f}m", (width - 120, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, obs_color, 1)

            # æ¸…æ™°åº¦æç¤º
            if height < 200:
                cv2.putText(image, "æç¤º: ä¿®æ”¹settings.jsonå¯æé«˜åˆ†è¾¨ç‡", (10, height-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)

            return image
        except Exception:
            return image

    def _save_screenshot(self, image: Optional[np.ndarray]):
        """ä¿å­˜å½“å‰ç”»é¢ä¸ºæˆªå›¾"""
        if image is not None and image.size > 0:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"drone_snapshot_{timestamp}.png"
            cv2.imwrite(filename, image)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")


if __name__ == "__main__":
    print("=" * 70)
    print("AirSimNH æ— äººæœºæ„ŸçŸ¥æ¢ç´¢ç³»ç»Ÿ - é›†æˆå‰è§†çª—å£ç‰ˆ")
    print("æ³¨æ„: é»˜è®¤åˆ†è¾¨ç‡è¾ƒä½(256x144)ï¼Œå¦‚éœ€é«˜æ¸…ç”»é¢è¯·ä¿®æ”¹settings.json")
    print("=" * 70)
    main()