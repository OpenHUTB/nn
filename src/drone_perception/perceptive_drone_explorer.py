"""
AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢æ— äººæœº - æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆï¼ˆçº¢è‰²ç‰©ä½“æ£€æµ‹ç‰ˆï¼‰
æ ¸å¿ƒï¼šè§†è§‰æ„ŸçŸ¥ â†’ è¯­ä¹‰ç†è§£ â†’ æ™ºèƒ½å†³ç­– â†’ å®‰å…¨æ‰§è¡Œ
é›†æˆï¼šé…ç½®ç®¡ç†ã€æ—¥å¿—ç³»ç»Ÿã€å¼‚å¸¸æ¢å¤ã€å‰è§†çª—å£æ˜¾ç¤º
æ–°å¢ï¼šå‘é‡åœºé¿éšœç®—æ³•ã€åŸºäºç½‘æ ¼çš„ä¿¡æ¯å¢ç›Šæ¢ç´¢ã€å¹³æ»‘é£è¡Œæ§åˆ¶
æ–°å¢ï¼šæ€§èƒ½ç›‘æ§ä¸æ•°æ®é—­ç¯ç³»ç»Ÿã€çº¢è‰²ç‰©ä½“æ£€æµ‹ä¸è®°å½•
ç‰ˆæœ¬: 3.3 (çº¢è‰²ç‰©ä½“æ£€æµ‹ç‰ˆ)
"""

import airsim
import time
import numpy as np
import cv2
import math
import json
import csv
from collections import deque
from dataclasses import dataclass
from enum import Enum
import threading
import queue
import signal
import sys
from typing import Tuple, List, Optional, Dict, Set, Any
import traceback
import logging
from datetime import datetime
import random
import psutil
import os

# ============ å¯¼å…¥é…ç½®æ–‡ä»¶ ============
try:
    import config
    CONFIG_LOADED = True
except ImportError as e:
    print(f"âŒ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ config.py: {e}")
    print("æ­£åœ¨ä½¿ç”¨é»˜è®¤é…ç½®...")
    CONFIG_LOADED = False
    class DefaultConfig:
        EXPLORATION = {'TOTAL_TIME': 120, 'PREFERRED_SPEED': 2.5, 'BASE_HEIGHT': -15.0,
                      'MAX_ALTITUDE': -30.0, 'MIN_ALTITUDE': -5.0, 'TAKEOFF_HEIGHT': -10.0}
        PERCEPTION = {'DEPTH_NEAR_THRESHOLD': 5.0, 'DEPTH_SAFE_THRESHOLD': 10.0,
                     'MIN_GROUND_CLEARANCE': 2.0, 'MAX_PITCH_ANGLE_DEG': 15,
                     'SCAN_ANGLES': [-60, -45, -30, -15, 0, 15, 30, 45, 60],
                     'HEIGHT_STRATEGY': {'STEEP_SLOPE': -20.0, 'OPEN_SPACE': -12.0,
                                         'DEFAULT': -15.0, 'SLOPE_THRESHOLD': 5.0,
                                         'OPENNESS_THRESHOLD': 0.7},
                     'RED_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                            'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                            'MEMORY_TIME': 5.0}}
        DISPLAY = {'WINDOW_WIDTH': 640, 'WINDOW_HEIGHT': 480, 'ENABLE_SHARPENING': True,
                  'SHOW_INFO_OVERLAY': True, 'REFRESH_RATE_MS': 30, 'SHOW_RED_OBJECTS': True}
        SYSTEM = {'LOG_LEVEL': 'INFO', 'LOG_TO_FILE': True, 'LOG_FILENAME': 'drone_log.txt',
                 'MAX_RECONNECT_ATTEMPTS': 3, 'RECONNECT_DELAY': 2.0,
                 'ENABLE_HEALTH_CHECK': True, 'HEALTH_CHECK_INTERVAL': 20}
        CAMERA = {'DEFAULT_NAME': "0",
                 'RED_COLOR_RANGE': {'LOWER1': [0, 120, 70], 'UPPER1': [10, 255, 255],
                                    'LOWER2': [170, 120, 70], 'UPPER2': [180, 255, 255]}}
        MANUAL = {
            'CONTROL_SPEED': 3.0,
            'ALTITUDE_SPEED': 2.0,
            'YAW_SPEED': 30.0,
            'ENABLE_AUTO_HOVER': True,
            'DISPLAY_CONTROLS': True,
            'SAFETY_ENABLED': True,
            'MAX_MANUAL_SPEED': 5.0,
            'MIN_ALTITUDE_LIMIT': -5.0,
            'MAX_ALTITUDE_LIMIT': -30.0
        }
        INTELLIGENT_DECISION = {
            'VECTOR_FIELD_RADIUS': 8.0,
            'OBSTACLE_REPULSION_GAIN': 3.0,
            'GOAL_ATTRACTION_GAIN': 2.0,
            'SMOOTHING_FACTOR': 0.3,
            'MIN_TURN_ANGLE_DEG': 10,
            'MAX_TURN_ANGLE_DEG': 60,
            'GRID_RESOLUTION': 2.0,
            'GRID_SIZE': 50,
            'INFORMATION_GAIN_DECAY': 0.95,
            'EXPLORATION_FRONTIER_THRESHOLD': 0.3,
            'PID_KP': 1.5,
            'PID_KI': 0.05,
            'PID_KD': 0.2,
            'SMOOTHING_WINDOW_SIZE': 5,
            'ADAPTIVE_SPEED_ENABLED': True,
            'MIN_SPEED_FACTOR': 0.3,
            'MAX_SPEED_FACTOR': 1.5,
            'MEMORY_WEIGHT': 0.7,
            'CURIOUSITY_WEIGHT': 0.3,
            'TARGET_LIFETIME': 15.0,
            'TARGET_REACHED_DISTANCE': 3.0,
            'RED_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.5, 'DETECTION_RADIUS': 10.0,
                                      'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.5}
        }
        DEBUG = {
            'SAVE_PERCEPTION_IMAGES': False,
            'IMAGE_SAVE_INTERVAL': 50,
            'LOG_DECISION_DETAILS': False,
            'SAVE_RED_OBJECT_IMAGES': False
        }
        DATA_RECORDING = {
            'ENABLED': True,
            'RECORD_INTERVAL': 0.2,
            'SAVE_TO_CSV': True,
            'SAVE_TO_JSON': True,
            'CSV_FILENAME': 'flight_data.csv',
            'JSON_FILENAME': 'flight_data.json',
            'PERFORMANCE_MONITORING': True,
            'SYSTEM_METRICS_INTERVAL': 5.0,
            'RECORD_RED_OBJECTS': True
        }
        PERFORMANCE = {
            'ENABLE_REALTIME_METRICS': True,
            'CPU_WARNING_THRESHOLD': 80.0,
            'MEMORY_WARNING_THRESHOLD': 80.0,
            'LOOP_TIME_WARNING_THRESHOLD': 0.2,
            'SAVE_PERFORMANCE_REPORT': True,
            'REPORT_INTERVAL': 30.0,
        }
    config = DefaultConfig()


class FlightState(Enum):
    """æ— äººæœºé£è¡ŒçŠ¶æ€æšä¸¾"""
    TAKEOFF = "èµ·é£"
    HOVERING = "æ‚¬åœè§‚æµ‹"
    EXPLORING = "ä¸»åŠ¨æ¢ç´¢"
    AVOIDING = "é¿éšœæœºåŠ¨"
    RETURNING = "è¿”èˆªä¸­"
    LANDING = "é™è½"
    EMERGENCY = "ç´§æ€¥çŠ¶æ€"
    MANUAL = "æ‰‹åŠ¨æ§åˆ¶"
    PLANNING = "è·¯å¾„è§„åˆ’"
    RED_OBJECT_INSPECTION = "çº¢è‰²ç‰©ä½“æ£€æŸ¥"


@dataclass
class RedObject:
    """çº¢è‰²ç‰©ä½“æ•°æ®ç»“æ„"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


class Vector2D:
    """äºŒç»´å‘é‡ç±»"""
    def __init__(self, x=0.0, y=0.0):
        self.x = x
        self.y = y

    def __add__(self, other):
        return Vector2D(self.x + other.x, self.y + other.y)

    def __sub__(self, other):
        return Vector2D(self.x - other.x, self.y - other.y)

    def __mul__(self, scalar):
        return Vector2D(self.x * scalar, self.y * scalar)

    def __truediv__(self, scalar):
        return Vector2D(self.x / scalar, self.y / scalar)

    def magnitude(self):
        return math.sqrt(self.x**2 + self.y**2)

    def normalize(self):
        mag = self.magnitude()
        if mag > 0:
            return Vector2D(self.x / mag, self.y / mag)
        return Vector2D()

    def rotate(self, angle):
        cos_a = math.cos(angle)
        sin_a = math.sin(angle)
        return Vector2D(
            self.x * cos_a - self.y * sin_a,
            self.x * sin_a + self.y * cos_a
        )

    def to_tuple(self):
        return (self.x, self.y)

    @staticmethod
    def from_angle(angle, magnitude=1.0):
        return Vector2D(magnitude * math.cos(angle), magnitude * math.sin(angle))


class PIDController:
    """PIDæ§åˆ¶å™¨ç±»"""
    def __init__(self, kp, ki, kd, integral_limit=5.0, output_limit=10.0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.integral_limit = integral_limit
        self.output_limit = output_limit

        self.previous_error = 0.0
        self.integral = 0.0
        self.previous_time = time.time()

    def update(self, error, dt=None):
        if dt is None:
            current_time = time.time()
            dt = current_time - self.previous_time
            self.previous_time = current_time

        self.integral += error * dt
        self.integral = max(-self.integral_limit, min(self.integral_limit, self.integral))

        derivative = (error - self.previous_error) / dt if dt > 0 else 0.0
        self.previous_error = error

        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        return max(-self.output_limit, min(self.output_limit, output))


class ExplorationGrid:
    """æ¢ç´¢ç½‘æ ¼åœ°å›¾ç±»"""
    def __init__(self, resolution=2.0, grid_size=50):
        self.resolution = resolution
        self.grid_size = grid_size
        self.half_size = grid_size // 2

        self.grid = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.information_gain = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.obstacle_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.visit_time = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.red_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.current_idx = (self.half_size, self.half_size)
        self.frontier_cells = set()

        print(f"ğŸ—ºï¸ åˆå§‹åŒ–æ¢ç´¢ç½‘æ ¼: {grid_size}x{grid_size}, åˆ†è¾¨ç‡: {resolution}m")

    def world_to_grid(self, world_x, world_y):
        grid_x = int(world_x / self.resolution) + self.half_size
        grid_y = int(world_y / self.resolution) + self.half_size

        grid_x = max(0, min(self.grid_size - 1, grid_x))
        grid_y = max(0, min(self.grid_size - 1, grid_y))

        return (grid_x, grid_y)

    def grid_to_world(self, grid_x, grid_y):
        world_x = (grid_x - self.half_size) * self.resolution
        world_y = (grid_y - self.half_size) * self.resolution
        return (world_x, world_y)

    def update_position(self, world_x, world_y):
        self.current_idx = self.world_to_grid(world_x, world_y)

        x, y = self.current_idx
        radius = 3

        for dx in range(-radius, radius + 1):
            for dy in range(-radius, radius + 1):
                nx, ny = x + dx, y + dy
                if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                    distance = math.sqrt(dx**2 + dy**2)
                    exploration_value = max(0, 1.0 - distance / radius)
                    self.grid[nx, ny] = max(self.grid[nx, ny], exploration_value)
                    self.visit_time[nx, ny] = time.time()

        self._update_frontiers()

    def _update_frontiers(self):
        self.frontier_cells.clear()

        for x in range(1, self.grid_size - 1):
            for y in range(1, self.grid_size - 1):
                if self.grid[x, y] > 0.7:
                    neighbors = [
                        (x-1, y), (x+1, y), (x, y-1), (x, y+1),
                        (x-1, y-1), (x-1, y+1), (x+1, y-1), (x+1, y+1)
                    ]

                    for nx, ny in neighbors:
                        if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                            if self.grid[nx, ny] < 0.3 and not self.obstacle_grid[nx, ny]:
                                unexplored_neighbors = 0
                                for nnx in range(nx-1, nx+2):
                                    for nny in range(ny-1, ny+2):
                                        if 0 <= nnx < self.grid_size and 0 <= nny < self.grid_size:
                                            if self.grid[nnx, nny] < 0.3:
                                                unexplored_neighbors += 1

                                self.information_gain[nx, ny] = unexplored_neighbors / 9.0
                                self.frontier_cells.add((nx, ny))

    def update_obstacles(self, obstacles_world):
        for obs_x, obs_y in obstacles_world:
            grid_x, grid_y = self.world_to_grid(obs_x, obs_y)

            radius = 2
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.obstacle_grid[nx, ny] = True
                        self.grid[nx, ny] = 0.0

    def update_red_objects(self, red_objects):
        self.red_object_grid.fill(False)

        for obj in red_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.red_object_grid[nx, ny] = True

    def get_best_exploration_target(self, current_pos, red_objects=None):
        if red_objects and len(red_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in red_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 15.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        if not self.frontier_cells:
            angle = random.uniform(0, 2 * math.pi)
            distance = 10.0
            return (
                current_pos[0] + distance * math.cos(angle),
                current_pos[1] + distance * math.sin(angle)
            )

        best_score = -1
        best_target = None
        current_x, current_y = current_pos

        for fx, fy in self.frontier_cells:
            info_gain = self.information_gain[fx, fy]

            world_x, world_y = self.grid_to_world(fx, fy)
            distance = math.sqrt((world_x - current_x)**2 + (world_y - current_y)**2)
            distance_cost = min(1.0, distance / 30.0)

            time_since_visit = time.time() - self.visit_time[fx, fy]
            time_factor = min(1.0, time_since_visit / 60.0)

            red_bonus = 0.0
            if self.red_object_grid[fx, fy]:
                red_bonus = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            score = (
                config.INTELLIGENT_DECISION['CURIOUSITY_WEIGHT'] * info_gain +
                (1 - config.INTELLIGENT_DECISION['MEMORY_WEIGHT'] * time_factor) -
                distance_cost * 0.3 +
                red_bonus
            )

            if score > best_score:
                best_score = score
                best_target = (world_x, world_y)

        return best_target

    def visualize_grid(self, size=300):
        if self.grid.size == 0:
            return None

        img_size = min(size, self.grid_size * 5)
        img = np.zeros((img_size, img_size, 3), dtype=np.uint8)

        cell_size = img_size // self.grid_size

        for x in range(self.grid_size):
            for y in range(self.grid_size):
                color = (0, 0, 0)

                if (x, y) == self.current_idx:
                    color = (0, 255, 0)
                elif self.obstacle_grid[x, y]:
                    color = (0, 0, 255)
                elif self.red_object_grid[x, y]:
                    color = (0, 100, 255)
                elif self.grid[x, y] > 0.7:
                    color = (200, 200, 200)
                elif self.grid[x, y] > 0.3:
                    color = (100, 100, 100)
                elif (x, y) in self.frontier_cells:
                    gain = self.information_gain[x, y]
                    color = (0, int(255 * gain), int(255 * (1 - gain)))

                x1 = x * cell_size
                y1 = y * cell_size
                x2 = (x + 1) * cell_size
                y2 = (y + 1) * cell_size

                cv2.rectangle(img, (y1, x1), (y2, x2), color, -1)

        return img


class DataLogger:
    """æ•°æ®è®°å½•å™¨ç±»"""

    def __init__(self, enable_csv=True, enable_json=True, csv_filename=None, json_filename=None):
        self.enable_csv = enable_csv
        self.enable_json = enable_json

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if csv_filename:
            self.csv_filename = csv_filename
        else:
            self.csv_filename = f"flight_data_{timestamp}.csv"

        if json_filename:
            self.json_filename = json_filename
        else:
            self.json_filename = f"flight_data_{timestamp}.json"

        self.data_buffer = []
        self.json_data = {
            "flight_info": {
                "start_time": datetime.now().isoformat(),
                "config_loaded": CONFIG_LOADED,
                "system": config.SYSTEM,
                "exploration": config.EXPLORATION,
                "perception": config.PERCEPTION,
                "intelligent_decision": config.INTELLIGENT_DECISION,
                "performance": config.PERFORMANCE
            },
            "flight_data": []
        }

        self.performance_metrics = {
            "start_time": time.time(),
            "cpu_usage": [],
            "memory_usage": [],
            "loop_times": [],
            "data_points": 0
        }

        self.red_objects_detected = []

        self.csv_columns = [
            'timestamp', 'loop_count', 'state', 'pos_x', 'pos_y', 'pos_z',
            'vel_x', 'vel_y', 'vel_z', 'yaw', 'pitch', 'roll',
            'obstacle_distance', 'open_space_score', 'terrain_slope',
            'has_obstacle', 'obstacle_direction', 'recommended_height',
            'target_x', 'target_y', 'target_z', 'velocity_command_x',
            'velocity_command_y', 'velocity_command_z', 'yaw_command',
            'battery_level', 'cpu_usage', 'memory_usage', 'loop_time',
            'grid_frontiers', 'grid_explored', 'vector_field_magnitude',
            'adaptive_speed_factor', 'decision_making_time', 'perception_time',
            'red_objects_count', 'red_objects_detected', 'red_objects_visited'
        ]

        if self.enable_csv:
            self._init_csv_file()

        print(f"ğŸ“Š æ•°æ®è®°å½•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  CSVæ–‡ä»¶: {self.csv_filename}")
        print(f"  JSONæ–‡ä»¶: {self.json_filename}")

    def _init_csv_file(self):
        try:
            with open(self.csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=self.csv_columns)
                writer.writeheader()
        except Exception as e:
            print(f"âŒ æ— æ³•åˆå§‹åŒ–CSVæ–‡ä»¶: {e}")
            self.enable_csv = False

    def record_flight_data(self, data_dict):
        if not config.DATA_RECORDING['ENABLED']:
            return

        try:
            data_dict['timestamp'] = datetime.now().isoformat()

            if self.enable_csv:
                with open(self.csv_filename, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=self.csv_columns)
                    row = {col: data_dict.get(col, '') for col in self.csv_columns}
                    writer.writerow(row)

            if self.enable_json:
                self.json_data['flight_data'].append(data_dict)

            self.performance_metrics['data_points'] += 1

            if self.performance_metrics['data_points'] % 10 == 0:
                self._collect_system_metrics()

        except Exception as e:
            print(f"âš ï¸ è®°å½•é£è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")

    def record_red_object(self, red_object):
        try:
            red_object_data = {
                'id': red_object.id,
                'position': red_object.position,
                'pixel_position': red_object.pixel_position,
                'size': red_object.size,
                'confidence': red_object.confidence,
                'timestamp': red_object.timestamp,
                'visited': red_object.visited
            }

            self.red_objects_detected.append(red_object_data)

            if 'red_objects' not in self.json_data:
                self.json_data['red_objects'] = []

            self.json_data['red_objects'].append(red_object_data)

        except Exception as e:
            print(f"âš ï¸ è®°å½•çº¢è‰²ç‰©ä½“æ—¶å‡ºé”™: {e}")

    def _collect_system_metrics(self):
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            self.performance_metrics['cpu_usage'].append(cpu_percent)

            memory_info = psutil.virtual_memory()
            memory_percent = memory_info.percent
            self.performance_metrics['memory_usage'].append(memory_percent)

            max_length = 1000
            if len(self.performance_metrics['cpu_usage']) > max_length:
                self.performance_metrics['cpu_usage'] = self.performance_metrics['cpu_usage'][-max_length:]
            if len(self.performance_metrics['memory_usage']) > max_length:
                self.performance_metrics['memory_usage'] = self.performance_metrics['memory_usage'][-max_length:]

        except Exception as e:
            print(f"âš ï¸ æ”¶é›†ç³»ç»ŸæŒ‡æ ‡æ—¶å‡ºé”™: {e}")

    def record_loop_time(self, loop_time):
        self.performance_metrics['loop_times'].append(loop_time)

        max_length = 1000
        if len(self.performance_metrics['loop_times']) > max_length:
            self.performance_metrics['loop_times'] = self.performance_metrics['loop_times'][-max_length:]

    def record_event(self, event_type, event_data):
        try:
            event_record = {
                'timestamp': datetime.now().isoformat(),
                'event_type': event_type,
                'event_data': event_data
            }

            if 'events' not in self.json_data:
                self.json_data['events'] = []

            self.json_data['events'].append(event_record)

        except Exception as e:
            print(f"âš ï¸ è®°å½•äº‹ä»¶æ—¶å‡ºé”™: {e}")

    def save_json_data(self):
        if not self.enable_json:
            return

        try:
            self._calculate_performance_stats()

            if 'red_objects' in self.json_data:
                red_count = len(self.json_data['red_objects'])
                visited_count = sum(1 for obj in self.json_data['red_objects'] if obj.get('visited', False))
                self.json_data['red_objects_summary'] = {
                    'total_detected': red_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / red_count if red_count > 0 else 0
                }

            with open(self.json_filename, 'w', encoding='utf-8') as f:
                json.dump(self.json_data, f, indent=2, ensure_ascii=False)

            print(f"âœ… JSONæ•°æ®å·²ä¿å­˜: {self.json_filename}")

        except Exception as e:
            print(f"âŒ ä¿å­˜JSONæ•°æ®æ—¶å‡ºé”™: {e}")

    def _calculate_performance_stats(self):
        if not self.performance_metrics['cpu_usage']:
            return

        cpu_avg = np.mean(self.performance_metrics['cpu_usage'])
        cpu_max = np.max(self.performance_metrics['cpu_usage'])
        cpu_min = np.min(self.performance_metrics['cpu_usage'])

        mem_avg = np.mean(self.performance_metrics['memory_usage'])
        mem_max = np.max(self.performance_metrics['memory_usage'])
        mem_min = np.min(self.performance_metrics['memory_usage'])

        if self.performance_metrics['loop_times']:
            loop_avg = np.mean(self.performance_metrics['loop_times'])
            loop_max = np.max(self.performance_metrics['loop_times'])
            loop_min = np.min(self.performance_metrics['loop_times'])
        else:
            loop_avg = loop_max = loop_min = 0

        self.json_data['performance_summary'] = {
            'total_data_points': self.performance_metrics['data_points'],
            'total_time_seconds': time.time() - self.performance_metrics['start_time'],
            'cpu_usage': {
                'average': float(cpu_avg),
                'maximum': float(cpu_max),
                'minimum': float(cpu_min)
            },
            'memory_usage': {
                'average': float(mem_avg),
                'maximum': float(mem_max),
                'minimum': float(mem_min)
            },
            'loop_times': {
                'average_seconds': float(loop_avg),
                'maximum_seconds': float(loop_max),
                'minimum_seconds': float(loop_min)
            }
        }

    def generate_performance_report(self):
        try:
            if not self.performance_metrics['cpu_usage']:
                return "æ— æ€§èƒ½æ•°æ®å¯ç”¨"

            self._calculate_performance_stats()

            report = "\n" + "="*60 + "\n"
            report += "ğŸ“Š ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š\n"
            report += "="*60 + "\n"

            report += f"æ€»æ•°æ®ç‚¹æ•°: {self.performance_metrics['data_points']}\n"
            report += f"è¿è¡Œæ—¶é—´: {time.time() - self.performance_metrics['start_time']:.1f}ç§’\n"

            if self.performance_metrics['cpu_usage']:
                cpu_avg = np.mean(self.performance_metrics['cpu_usage'])
                cpu_max = np.max(self.performance_metrics['cpu_usage'])
                report += f"CPUä½¿ç”¨ç‡: å¹³å‡{cpu_avg:.1f}%, æœ€å¤§{cpu_max:.1f}%\n"

            if self.performance_metrics['memory_usage']:
                mem_avg = np.mean(self.performance_metrics['memory_usage'])
                mem_max = np.max(self.performance_metrics['memory_usage'])
                report += f"å†…å­˜ä½¿ç”¨ç‡: å¹³å‡{mem_avg:.1f}%, æœ€å¤§{mem_max:.1f}%\n"

            if self.performance_metrics['loop_times']:
                loop_avg = np.mean(self.performance_metrics['loop_times'])
                loop_max = np.max(self.performance_metrics['loop_times'])
                report += f"å¾ªç¯æ—¶é—´: å¹³å‡{loop_avg*1000:.1f}ms, æœ€å¤§{loop_max*1000:.1f}ms\n"

            if 'red_objects' in self.json_data:
                red_count = len(self.json_data['red_objects'])
                visited_count = sum(1 for obj in self.json_data['red_objects'] if obj.get('visited', False))
                report += f"çº¢è‰²ç‰©ä½“æ£€æµ‹: æ€»æ•°{red_count}ä¸ª, å·²è®¿é—®{visited_count}ä¸ª\n"

            report += "="*60 + "\n"

            warnings = []
            if cpu_avg > config.PERFORMANCE['CPU_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_avg:.1f}%")

            if mem_avg > config.PERFORMANCE['MEMORY_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {mem_avg:.1f}%")

            if loop_avg > config.PERFORMANCE['LOOP_TIME_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å¾ªç¯æ—¶é—´è¿‡é•¿: {loop_avg*1000:.1f}ms")

            if warnings:
                report += "\nâš ï¸ æ€§èƒ½è­¦å‘Š:\n"
                for warning in warnings:
                    report += f"  {warning}\n"

            return report

        except Exception as e:
            return f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ—¶å‡ºé”™: {e}"


@dataclass
class PerceptionResult:
    """æ„ŸçŸ¥ç»“æœæ•°æ®ç»“æ„"""
    has_obstacle: bool = False
    obstacle_distance: float = 100.0
    obstacle_direction: float = 0.0
    terrain_slope: float = 0.0
    open_space_score: float = 0.0
    recommended_height: float = config.PERCEPTION['HEIGHT_STRATEGY']['DEFAULT']
    safe_directions: List[float] = None
    front_image: Optional[np.ndarray] = None
    obstacle_positions: List[Tuple[float, float]] = None
    red_objects: List[RedObject] = None
    red_objects_count: int = 0
    red_objects_image: Optional[np.ndarray] = None

    def __post_init__(self):
        if self.safe_directions is None:
            self.safe_directions = []
        if self.obstacle_positions is None:
            self.obstacle_positions = []
        if self.red_objects is None:
            self.red_objects = []


class VectorFieldPlanner:
    """å‘é‡åœºè§„åˆ’å™¨"""
    def __init__(self):
        self.repulsion_gain = config.INTELLIGENT_DECISION['OBSTACLE_REPULSION_GAIN']
        self.attraction_gain = config.INTELLIGENT_DECISION['GOAL_ATTRACTION_GAIN']
        self.field_radius = config.INTELLIGENT_DECISION['VECTOR_FIELD_RADIUS']
        self.smoothing_factor = config.INTELLIGENT_DECISION['SMOOTHING_FACTOR']
        self.red_attraction_gain = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['ATTRACTION_GAIN']

        self.min_turn_angle = math.radians(config.INTELLIGENT_DECISION['MIN_TURN_ANGLE_DEG'])
        self.max_turn_angle = math.radians(config.INTELLIGENT_DECISION['MAX_TURN_ANGLE_DEG'])

        self.vector_history = deque(maxlen=config.INTELLIGENT_DECISION['SMOOTHING_WINDOW_SIZE'])
        self.current_vector = Vector2D()

    def compute_vector(self, current_pos, goal_pos, obstacles, red_objects=None):
        attraction_vector = self._compute_attraction(current_pos, goal_pos)
        repulsion_vector = self._compute_repulsion(current_pos, obstacles)
        red_attraction_vector = Vector2D()
        if red_objects:
            red_attraction_vector = self._compute_red_attraction(current_pos, red_objects)

        combined_vector = attraction_vector + repulsion_vector + red_attraction_vector
        smoothed_vector = self._smooth_vector(combined_vector)
        limited_vector = self._limit_turn_angle(smoothed_vector)

        self.current_vector = limited_vector
        return limited_vector

    def _compute_attraction(self, current_pos, goal_pos):
        if goal_pos is None:
            return Vector2D()

        dx = goal_pos[0] - current_pos[0]
        dy = goal_pos[1] - current_pos[1]
        distance = math.sqrt(dx**2 + dy**2)

        if distance < 0.1:
            return Vector2D()

        strength = min(self.attraction_gain, self.attraction_gain / max(1.0, distance))
        return Vector2D(dx, dy).normalize() * strength

    def _compute_repulsion(self, current_pos, obstacles):
        repulsion = Vector2D()

        for obs_x, obs_y in obstacles:
            dx = current_pos[0] - obs_x
            dy = current_pos[1] - obs_y
            distance = math.sqrt(dx**2 + dy**2)

            if distance < self.field_radius and distance > 0.1:
                strength = self.repulsion_gain * (1.0 / distance**2)
                direction = Vector2D(dx, dy).normalize()
                repulsion += direction * strength

        return repulsion

    def _compute_red_attraction(self, current_pos, red_objects):
        attraction = Vector2D()

        for obj in red_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.red_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _smooth_vector(self, new_vector):
        self.vector_history.append(new_vector)

        if len(self.vector_history) < 2:
            return new_vector

        smoothed = Vector2D()
        total_weight = 0.0

        for i, vec in enumerate(reversed(self.vector_history)):
            weight = math.exp(-i * self.smoothing_factor)
            smoothed += vec * weight
            total_weight += weight

        if total_weight > 0:
            smoothed = smoothed / total_weight

        return smoothed

    def _limit_turn_angle(self, vector):
        if self.current_vector.magnitude() < 0.1:
            return vector

        current_angle = math.atan2(self.current_vector.y, self.current_vector.x)
        new_angle = math.atan2(vector.y, vector.x)

        angle_diff = new_angle - current_angle
        angle_diff = (angle_diff + math.pi) % (2 * math.pi) - math.pi

        if abs(angle_diff) > self.max_turn_angle:
            angle_diff = math.copysign(self.max_turn_angle, angle_diff)
        elif abs(angle_diff) < self.min_turn_angle and vector.magnitude() > 0.1:
            angle_diff = math.copysign(self.min_turn_angle, angle_diff)

        magnitude = vector.magnitude()
        limited_angle = current_angle + angle_diff

        return Vector2D.from_angle(limited_angle, magnitude)


class FrontViewDisplay:
    """å‰è§†ç”»é¢æ˜¾ç¤ºç®¡ç†å™¨"""

    def __init__(self, window_name="æ— äººæœºå‰è§†ç”»é¢", width=None, height=None,
                 enable_sharpening=None, show_info=None):
        self.window_name = window_name
        self.window_width = width if width is not None else config.DISPLAY['WINDOW_WIDTH']
        self.window_height = height if height is not None else config.DISPLAY['WINDOW_HEIGHT']
        self.enable_sharpening = (enable_sharpening if enable_sharpening is not None
                                 else config.DISPLAY['ENABLE_SHARPENING'])
        self.show_info = (show_info if show_info is not None
                         else config.DISPLAY['SHOW_INFO_OVERLAY'])

        self.image_queue = queue.Queue(maxsize=3)
        self.display_active = True
        self.display_thread = None
        self.paused = False

        self.manual_mode = False
        self.key_states = {}
        self.last_keys = {}

        self.exit_manual_flag = False
        self.exit_display_flag = False

        self.display_stats = {
            'fps': 0.0,
            'last_update': time.time(),
            'frame_count': 0
        }

        self.performance_info = {
            'cpu_usage': 0.0,
            'memory_usage': 0.0,
            'update_time': time.time()
        }

        self.start()

    def start(self):
        if self.display_thread and self.display_thread.is_alive():
            return

        self.display_active = True
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="FrontViewDisplay"
        )
        self.display_thread.start()

    def stop(self):
        self.display_active = False
        self.exit_display_flag = True
        if self.display_thread:
            self.display_thread.join(timeout=2.0)

    def update_image(self, image_data: np.ndarray, info: Optional[Dict] = None,
                     manual_info: Optional[List[str]] = None,
                     additional_images: Optional[Dict] = None):
        if not self.display_active or self.paused or image_data is None:
            return

        try:
            if self.enable_sharpening and image_data is not None and image_data.size > 0:
                kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
                image_data = cv2.filter2D(image_data, -1, kernel)

            if self.image_queue.full():
                try:
                    self.image_queue.get_nowait()
                except queue.Empty:
                    pass

            display_packet = {
                'image': image_data.copy(),
                'info': info.copy() if info else {},
                'manual_info': manual_info.copy() if manual_info else [],
                'additional_images': additional_images.copy() if additional_images else {},
                'timestamp': time.time()
            }

            self.image_queue.put_nowait(display_packet)

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°å›¾åƒæ—¶å‡ºé”™: {e}")

    def update_performance_info(self, cpu_usage, memory_usage):
        self.performance_info['cpu_usage'] = cpu_usage
        self.performance_info['memory_usage'] = memory_usage
        self.performance_info['update_time'] = time.time()

    def set_manual_mode(self, manual_mode):
        self.manual_mode = manual_mode
        self.exit_manual_flag = False
        self.key_states = {}
        self.last_keys = {}
        print(f"ğŸ”„ {'è¿›å…¥' if manual_mode else 'é€€å‡º'}æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")

    def get_control_inputs(self):
        return self.key_states.copy()

    def should_exit_manual(self):
        return self.exit_manual_flag

    def _display_loop(self):
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        wait_img = np.zeros((300, 400, 3), dtype=np.uint8)
        cv2.putText(wait_img, "ç­‰å¾…æ— äººæœºå›¾åƒ...", (50, 150),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        cv2.imshow(self.window_name, wait_img)
        cv2.waitKey(100)

        print("ğŸ’¡ å‰è§†çª—å£æ§åˆ¶:")
        print("   - é€šç”¨æ§åˆ¶: P=æš‚åœ/ç»§ç»­, I=ä¿¡æ¯æ˜¾ç¤º, H=é”åŒ–æ•ˆæœ")
        print("   - éæ‰‹åŠ¨æ¨¡å¼: Q=å…³é—­çª—å£, S=ä¿å­˜æˆªå›¾")
        print("   - æ‰‹åŠ¨æ¨¡å¼: ESC=é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")
        print("\nğŸ® æ‰‹åŠ¨æ§åˆ¶é”®ä½:")
        print("   - W/S: å‰è¿›/åé€€, A/D: å·¦ç§»/å³ç§»")
        print("   - Q/E: ä¸Šå‡/ä¸‹é™, Z/X: å·¦è½¬/å³è½¬")
        print("   - ç©ºæ ¼: æ‚¬åœ, ESC: é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")

        while self.display_active and not self.exit_display_flag:
            display_image = None
            info = {}
            manual_info = []
            additional_images = {}

            try:
                if not self.image_queue.empty():
                    packet = self.image_queue.get_nowait()
                    display_image = packet['image']
                    info = packet['info']
                    manual_info = packet['manual_info']
                    additional_images = packet.get('additional_images', {})

                    self._update_stats()

                    while not self.image_queue.empty():
                        try:
                            self.image_queue.get_nowait()
                        except queue.Empty:
                            break
            except queue.Empty:
                pass

            if display_image is not None:
                if self.show_info:
                    display_image = self._add_info_overlay(display_image, info, manual_info, additional_images)

                cv2.imshow(self.window_name, display_image)
            elif self.paused:
                blank = np.zeros((300, 400, 3), dtype=np.uint8)
                cv2.putText(blank, "PAUSED", (120, 150),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
                cv2.imshow(self.window_name, blank)

            key = cv2.waitKey(config.DISPLAY.get('REFRESH_RATE_MS', 30)) & 0xFF

            current_keys = {}
            if key != 255:
                current_keys[key] = True

                if self.manual_mode:
                    self._handle_manual_mode_key(key)
                else:
                    self._handle_window_control_key(key, display_image)

            self._update_key_states(current_keys)

            try:
                if cv2.getWindowProperty(self.window_name, cv2.WND_PROP_VISIBLE) < 1:
                    print("ğŸ”„ ç”¨æˆ·å…³é—­äº†å‰è§†çª—å£")
                    self.display_active = False
                    break
            except:
                self.display_active = False
                break

        try:
            cv2.destroyWindow(self.window_name)
        except:
            pass
        cv2.waitKey(1)

    def _handle_manual_mode_key(self, key):
        if key == 27:
            print("æ”¶åˆ°é€€å‡ºæ‰‹åŠ¨æ¨¡å¼æŒ‡ä»¤")
            self.exit_manual_flag = True
            return

        self.key_states[key] = True

        if key == 32:
            print("â¸ï¸ æ‚¬åœæŒ‡ä»¤")

    def _handle_window_control_key(self, key, display_image):
        key_char = chr(key).lower() if 0 <= key <= 255 else ''

        if key_char == 'q':
            print("ğŸ”„ ç”¨æˆ·å…³é—­æ˜¾ç¤ºçª—å£")
            self.display_active = False
        elif key_char == 's' and display_image is not None:
            self._save_screenshot(display_image)
        elif key_char == 'p':
            self.paused = not self.paused
            status = "å·²æš‚åœ" if self.paused else "å·²æ¢å¤"
            print(f"â¸ï¸ è§†é¢‘æµ{status}")
        elif key_char == 'i':
            self.show_info = not self.show_info
            status = "å¼€å¯" if self.show_info else "å…³é—­"
            print(f"ğŸ“Š ä¿¡æ¯å åŠ å±‚{status}")
        elif key_char == 'h':
            self.enable_sharpening = not self.enable_sharpening
            status = "å¼€å¯" if self.enable_sharpening else "å…³é—­"
            print(f"ğŸ” å›¾åƒé”åŒ–{status}")

    def _update_key_states(self, current_keys):
        released_keys = []
        for key in list(self.key_states.keys()):
            if key not in current_keys:
                released_keys.append(key)

        for key in released_keys:
            del self.key_states[key]

        self.last_keys = current_keys.copy()

    def _update_stats(self):
        now = time.time()
        self.display_stats['frame_count'] += 1

        if now - self.display_stats['last_update'] >= 1.0:
            self.display_stats['fps'] = self.display_stats['frame_count'] / (now - self.display_stats['last_update'])
            self.display_stats['frame_count'] = 0
            self.display_stats['last_update'] = now

    def _add_info_overlay(self, image: np.ndarray, info: Dict, manual_info: List[str] = None,
                         additional_images: Dict = None) -> np.ndarray:
        if image is None or image.size == 0:
            return image

        try:
            overlay = image.copy()
            height, width = image.shape[:2]

            is_manual = info.get('state', '') == "æ‰‹åŠ¨æ§åˆ¶"

            grid_img = additional_images.get('grid') if additional_images else None
            info_height = 180 if (is_manual and manual_info) or grid_img is not None else 100

            cv2.rectangle(overlay, (0, 0), (width, info_height), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)

            state = info.get('state', 'UNKNOWN')
            state_color = (0, 255, 0) if 'æ¢ç´¢' in state else (0, 255, 255) if 'æ‚¬åœ' in state else (255, 255, 0) if 'æ‰‹åŠ¨' in state else (0, 0, 255)
            cv2.putText(image, f"çŠ¶æ€: {state}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, state_color, 2)

            pos = info.get('position', (0, 0, 0))
            cv2.putText(image, f"ä½ç½®: ({pos[0]:.1f}, {pos[1]:.1f}, {-pos[2]:.1f}m)", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

            red_objects_count = info.get('red_objects_count', 0)
            red_objects_visited = info.get('red_objects_visited', 0)
            if red_objects_count > 0:
                red_text = f"çº¢è‰²ç‰©ä½“: {red_objects_visited}/{red_objects_count}"
                cv2.putText(image, red_text, (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 100, 255), 2)

            decision_info = info.get('decision_info', {})
            if decision_info:
                y_pos = 120 if red_objects_count > 0 else 90
                for key, value in decision_info.items():
                    if key == 'vector_angle':
                        cv2.putText(image, f"æ–¹å‘: {math.degrees(value):.0f}Â°", (10, y_pos),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 255, 200), 1)
                        y_pos += 20
                    elif key == 'grid_score':
                        cv2.putText(image, f"æ¢ç´¢å¾—åˆ†: {value:.2f}", (10, y_pos),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 255), 1)
                        y_pos += 20

            if is_manual and manual_info:
                y_start = 130 if red_objects_count > 0 else 100
                for i, line in enumerate(manual_info):
                    y_pos = y_start + i * 20
                    cv2.putText(image, line, (10, y_pos),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 255, 200), 1)

                cv2.putText(image, "æ‰‹åŠ¨æ§åˆ¶ä¸­...", (width - 150, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)
            elif not is_manual and red_objects_count == 0:
                obs_dist = info.get('obstacle_distance', 0.0)
                obs_color = (0, 0, 255) if obs_dist < 5.0 else (0, 165, 255) if obs_dist < 10.0 else (0, 255, 0)
                cv2.putText(image, f"éšœç¢: {obs_dist:.1f}m", (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, obs_color, 2)

            fps_text = f"FPS: {self.display_stats['fps']:.1f}"
            cv2.putText(image, fps_text, (width - 120, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)

            if self.performance_info['cpu_usage'] > 0:
                cpu_text = f"CPU: {self.performance_info['cpu_usage']:.1f}%"
                mem_text = f"MEM: {self.performance_info['memory_usage']:.1f}%"

                cpu_color = (0, 200, 255) if self.performance_info['cpu_usage'] > 80 else (0, 255, 0)
                mem_color = (0, 200, 255) if self.performance_info['memory_usage'] > 80 else (0, 255, 0)

                cv2.putText(image, cpu_text, (width - 120, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, cpu_color, 1)
                cv2.putText(image, mem_text, (width - 120, 80),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, mem_color, 1)

            if grid_img is not None and grid_img.size > 0:
                grid_size = 150
                grid_resized = cv2.resize(grid_img, (grid_size, grid_size))

                x_offset = width - grid_size - 10
                y_offset = info_height + 10

                if y_offset + grid_size < height:
                    cv2.rectangle(image, (x_offset-2, y_offset-2),
                                 (x_offset+grid_size+2, y_offset+grid_size+2),
                                 (255, 255, 255), 1)

                    image[y_offset:y_offset+grid_size, x_offset:x_offset+grid_size] = grid_resized

                    cv2.putText(image, "æ¢ç´¢ç½‘æ ¼", (x_offset, y_offset-5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            return image
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ ä¿¡æ¯å åŠ å±‚å‡ºé”™: {e}")
            return image

    def _save_screenshot(self, image: Optional[np.ndarray]):
        if image is not None and image.size > 0:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"drone_snapshot_{timestamp}.png"
            cv2.imwrite(filename, image)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        else:
            print("âš ï¸ æ— æ³•ä¿å­˜æˆªå›¾ï¼šæ— æœ‰æ•ˆå›¾åƒæ•°æ®")


class PerceptiveExplorer:
    """åŸºäºæ„ŸçŸ¥çš„è‡ªä¸»æ¢ç´¢æ— äººæœº - æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆï¼ˆçº¢è‰²ç‰©ä½“æ£€æµ‹ç‰ˆï¼‰"""

    def __init__(self, drone_name=""):
        self._setup_logging()
        self.logger.info("=" * 60)
        self.logger.info("AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢ç³»ç»Ÿ - çº¢è‰²ç‰©ä½“æ£€æµ‹ç‰ˆ")
        self.logger.info("=" * 60)

        self.client = None
        self.drone_name = drone_name
        self._connect_to_airsim()

        try:
            self.client.enableApiControl(True, vehicle_name=drone_name)
            self.client.armDisarm(True, vehicle_name=drone_name)
            self.logger.info("âœ… APIæ§åˆ¶å·²å¯ç”¨")
        except Exception as e:
            self.logger.error(f"âŒ å¯ç”¨APIæ§åˆ¶å¤±è´¥: {e}")
            raise

        self.state = FlightState.TAKEOFF
        self.state_history = deque(maxlen=20)
        self.emergency_flag = False

        self.depth_threshold_near = config.PERCEPTION['DEPTH_NEAR_THRESHOLD']
        self.depth_threshold_safe = config.PERCEPTION['DEPTH_SAFE_THRESHOLD']
        self.min_ground_clearance = config.PERCEPTION['MIN_GROUND_CLEARANCE']
        self.max_pitch_angle = math.radians(config.PERCEPTION['MAX_PITCH_ANGLE_DEG'])
        self.scan_angles = config.PERCEPTION['SCAN_ANGLES']

        self.exploration_time = config.EXPLORATION['TOTAL_TIME']
        self.preferred_speed = config.EXPLORATION['PREFERRED_SPEED']
        self.max_altitude = config.EXPLORATION['MAX_ALTITUDE']
        self.min_altitude = config.EXPLORATION['MIN_ALTITUDE']
        self.base_height = config.EXPLORATION['BASE_HEIGHT']
        self.takeoff_height = config.EXPLORATION['TAKEOFF_HEIGHT']

        self.vector_planner = VectorFieldPlanner()
        self.exploration_grid = ExplorationGrid(
            resolution=config.INTELLIGENT_DECISION['GRID_RESOLUTION'],
            grid_size=config.INTELLIGENT_DECISION['GRID_SIZE']
        )

        self.velocity_pid = PIDController(
            config.INTELLIGENT_DECISION['PID_KP'],
            config.INTELLIGENT_DECISION['PID_KI'],
            config.INTELLIGENT_DECISION['PID_KD']
        )
        self.height_pid = PIDController(1.0, 0.1, 0.3)

        self.exploration_target = None
        self.target_update_time = 0
        self.target_lifetime = config.INTELLIGENT_DECISION.get('TARGET_LIFETIME', 15.0)
        self.target_reached_distance = config.INTELLIGENT_DECISION.get('TARGET_REACHED_DISTANCE', 3.0)

        self.red_objects = []
        self.red_object_id_counter = 0
        self.last_red_detection_time = 0
        self.red_detection_interval = config.PERCEPTION['RED_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.red_object_memory_time = config.PERCEPTION['RED_OBJECT_DETECTION']['MEMORY_TIME']

        self.visited_positions = deque(maxlen=100)

        self.loop_count = 0
        self.start_time = time.time()
        self.last_health_check = 0
        self.reconnect_attempts = 0
        self.last_successful_loop = time.time()

        self.data_logger = None
        self.last_data_record_time = 0
        self.data_record_interval = config.DATA_RECORDING.get('RECORD_INTERVAL', 0.2)
        if config.DATA_RECORDING['ENABLED']:
            self._setup_data_logger()

        self.last_performance_report = time.time()
        self.performance_report_interval = config.PERFORMANCE.get('REPORT_INTERVAL', 30.0)

        self.stats = {
            'perception_cycles': 0,
            'decision_cycles': 0,
            'exceptions_caught': 0,
            'obstacles_detected': 0,
            'state_changes': 0,
            'front_image_updates': 0,
            'manual_control_time': 0.0,
            'vector_field_updates': 0,
            'grid_updates': 0,
            'data_points_recorded': 0,
            'average_loop_time': 0.0,
            'max_loop_time': 0.0,
            'min_loop_time': 100.0,
            'red_objects_detected': 0,
            'red_objects_visited': 0,
        }

        self.front_display = None
        self._setup_front_display()

        self.manual_control_start = 0
        self.control_keys = {}

        self.logger.info("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        self.logger.info(f"   é¢„è®¡æ¢ç´¢æ—¶é•¿: {self.exploration_time}ç§’")
        self.logger.info(f"   æ™ºèƒ½å†³ç­–: å‘é‡åœºé¿éšœ + ç½‘æ ¼æ¢ç´¢ + çº¢è‰²ç‰©ä½“æ£€æµ‹")
        if config.DATA_RECORDING['ENABLED']:
            self.logger.info(f"   æ•°æ®è®°å½•: CSV + JSON æ ¼å¼")
        if config.PERCEPTION['RED_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   çº¢è‰²ç‰©ä½“æ£€æµ‹: å·²å¯ç”¨")

    def _setup_logging(self):
        self.logger = logging.getLogger('DroneExplorer')
        self.logger.setLevel(getattr(logging, config.SYSTEM['LOG_LEVEL']))

        if self.logger.hasHandlers():
            self.logger.handlers.clear()

        console_handler = logging.StreamHandler(sys.stdout)
        console_format = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s', datefmt='%H:%M:%S')
        console_handler.setFormatter(console_format)
        self.logger.addHandler(console_handler)

        if config.SYSTEM['LOG_TO_FILE']:
            try:
                file_handler = logging.FileHandler(config.SYSTEM['LOG_FILENAME'], encoding='utf-8')
                file_format = logging.Formatter('%(asctime)s | %(name)s | %(levelname)-8s | %(message)s')
                file_handler.setFormatter(file_format)
                self.logger.addHandler(file_handler)
                self.logger.info(f"ğŸ“ æ—¥å¿—å°†ä¿å­˜è‡³: {config.SYSTEM['LOG_FILENAME']}")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶: {e}")

    def _setup_data_logger(self):
        try:
            self.data_logger = DataLogger(
                enable_csv=config.DATA_RECORDING['SAVE_TO_CSV'],
                enable_json=config.DATA_RECORDING['SAVE_TO_JSON'],
                csv_filename=config.DATA_RECORDING.get('CSV_FILENAME'),
                json_filename=config.DATA_RECORDING.get('JSON_FILENAME')
            )
            self.logger.info("ğŸ“Š æ•°æ®è®°å½•å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®è®°å½•å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.data_logger = None

    def _connect_to_airsim(self):
        max_attempts = config.SYSTEM['MAX_RECONNECT_ATTEMPTS']
        for attempt in range(1, max_attempts + 1):
            try:
                self.logger.info(f"ğŸ”„ å°è¯•è¿æ¥åˆ°AirSim (ç¬¬{attempt}æ¬¡)...")
                self.client = airsim.MultirotorClient()
                self.client.confirmConnection()
                self.logger.info("âœ… æˆåŠŸè¿æ¥åˆ°AirSim")
                self.reconnect_attempts = 0
                return
            except ConnectionRefusedError:
                self.logger.warning(f"âŒ è¿æ¥è¢«æ‹’ç»ï¼Œè¯·ç¡®ä¿AirSimæ­£åœ¨è¿è¡Œ")
            except Exception as e:
                self.logger.warning(f"âŒ è¿æ¥å¤±è´¥: {e}")

            if attempt < max_attempts:
                self.logger.info(f"â³ {config.SYSTEM['RECONNECT_DELAY']}ç§’åé‡è¯•...")
                time.sleep(config.SYSTEM['RECONNECT_DELAY'])

        self.logger.error(f"âŒ ç»è¿‡{max_attempts}æ¬¡å°è¯•åä»æ— æ³•è¿æ¥åˆ°AirSim")
        self.logger.error("è¯·æ£€æŸ¥ï¼š1. AirSimæ˜¯å¦å¯åŠ¨ 2. ç½‘ç»œè®¾ç½® 3. é˜²ç«å¢™")
        sys.exit(1)

    def _check_connection_health(self):
        try:
            self.client.ping()
            self.logger.debug("âœ… è¿æ¥å¥åº·æ£€æŸ¥é€šè¿‡")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿æ¥å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            try:
                self._connect_to_airsim()
                return True
            except:
                return False

    def _setup_front_display(self):
        try:
            self.front_display = FrontViewDisplay(
                window_name=f"æ— äººæœºå‰è§† - {self.drone_name or 'AirSimNH'}",
                width=config.DISPLAY['WINDOW_WIDTH'],
                height=config.DISPLAY['WINDOW_HEIGHT'],
                enable_sharpening=config.DISPLAY['ENABLE_SHARPENING'],
                show_info=config.DISPLAY['SHOW_INFO_OVERLAY']
            )
            self.logger.info("ğŸ¥ å‰è§†çª—å£å·²åˆå§‹åŒ–")
        except Exception as e:
            self.logger.error(f"âŒ å‰è§†çª—å£åˆå§‹åŒ–å¤±è´¥: {e}")
            self.front_display = None

    def _detect_red_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[RedObject], np.ndarray]:
        red_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['RED_OBJECT_DETECTION']['ENABLED'] or image is None:
            return red_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_red1 = np.array(config.CAMERA['RED_COLOR_RANGE']['LOWER1'])
            upper_red1 = np.array(config.CAMERA['RED_COLOR_RANGE']['UPPER1'])
            lower_red2 = np.array(config.CAMERA['RED_COLOR_RANGE']['LOWER2'])
            upper_red2 = np.array(config.CAMERA['RED_COLOR_RANGE']['UPPER2'])

            mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            red_mask = cv2.bitwise_or(mask1, mask2)

            kernel = np.ones((5, 5), np.uint8)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['RED_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['RED_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    red_object = RedObject(
                        id=self.red_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.red_objects:
                        if self._is_same_object(red_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = red_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            red_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.red_object_id_counter += 1
                        red_objects.append(red_object)
                        self.stats['red_objects_detected'] += 1
                        self.logger.info(f"ğŸ”´ æ£€æµ‹åˆ°çº¢è‰²ç‰©ä½“ #{red_object.id} (ç½®ä¿¡åº¦: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_RED_OBJECTS']:
                            self.data_logger.record_red_object(red_object)
                    else:
                        red_objects.append(red_object)

                    if marked_image is not None:
                        color = (0, 100, 255)
                        if red_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"ID:{red_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.red_objects = [obj for obj in self.red_objects
                              if current_time - obj.last_seen < self.red_object_memory_time]

            visited_count = sum(1 for obj in self.red_objects if obj.visited)
            if len(red_objects) > 0:
                self.logger.debug(f"ğŸ”´ å½“å‰çº¢è‰²ç‰©ä½“: {len(self.red_objects)}ä¸ª, å·²è®¿é—®: {visited_count}ä¸ª")

        except Exception as e:
            self.logger.warning(f"âš ï¸ çº¢è‰²ç‰©ä½“æ£€æµ‹å¤±è´¥: {e}")

        return red_objects, marked_image

    def _is_same_object(self, obj1: RedObject, obj2: RedObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _check_red_object_proximity(self, current_pos):
        for obj in self.red_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['red_objects_visited'] += 1

                    self.logger.info(f"âœ… å·²è®¿é—®çº¢è‰²ç‰©ä½“ #{obj.id} (è·ç¦»: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('red_object_visited', event_data)

                    self.change_state(FlightState.RED_OBJECT_INSPECTION)
                    return True

        return False

    def get_depth_perception(self) -> PerceptionResult:
        result = PerceptionResult()
        self.stats['perception_cycles'] += 1

        try:
            if config.SYSTEM['ENABLE_HEALTH_CHECK']:
                current_time = time.time()
                if current_time - self.last_successful_loop > 10.0:
                    self.logger.warning("âš ï¸ æ„ŸçŸ¥å¾ªç¯é•¿æ—¶é—´æ— å“åº”ï¼Œå°è¯•æ¢å¤...")
                    self._check_connection_health()

            camera_name = config.CAMERA['DEFAULT_NAME']
            responses = self.client.simGetImages([
                airsim.ImageRequest(
                    camera_name,
                    airsim.ImageType.DepthPlanar,
                    pixels_as_float=True,
                    compress=False
                ),
                airsim.ImageRequest(
                    camera_name,
                    airsim.ImageType.Scene,
                    False,
                    False
                )
            ])

            if not responses or len(responses) < 2:
                self.logger.warning("âš ï¸ å›¾åƒè·å–å¤±è´¥ï¼šå“åº”ä¸ºç©ºæˆ–æ•°é‡ä¸è¶³")
                return result

            depth_img = responses[0]
            depth_array = None
            if depth_img and hasattr(depth_img, 'image_data_float'):
                try:
                    depth_array = np.array(depth_img.image_data_float, dtype=np.float32)
                    depth_array = depth_array.reshape(depth_img.height, depth_img.width)

                    h, w = depth_array.shape

                    front_near = depth_array[h // 2:, w // 3:2 * w // 3]
                    min_front_distance = np.min(front_near) if front_near.size > 0 else 100

                    directions = []
                    for angle_deg in self.scan_angles:
                        angle_rad = math.radians(angle_deg)
                        col = int(w / 2 + (w / 2) * math.tan(angle_rad) * 0.5)
                        col = max(0, min(w - 1, col))

                        col_data = depth_array[h // 2:, col]
                        if col_data.size > 0:
                            dir_distance = np.percentile(col_data, 25)
                            directions.append((angle_rad, dir_distance))

                            if dir_distance > self.depth_threshold_safe:
                                result.safe_directions.append(angle_rad)

                    result.obstacle_positions = self._extract_obstacle_positions(depth_array, h, w)

                    ground_region = depth_array[3 * h // 4:, :]
                    if ground_region.size > 10:
                        row_variances = np.var(ground_region, axis=1)
                        result.terrain_slope = np.mean(row_variances) * 100

                    open_pixels = np.sum(depth_array[h // 2:, :] > self.depth_threshold_safe)
                    total_pixels = depth_array[h // 2:, :].size
                    result.open_space_score = open_pixels / total_pixels if total_pixels > 0 else 0

                    result.has_obstacle = min_front_distance < self.depth_threshold_near
                    result.obstacle_distance = min_front_distance
                    if result.has_obstacle:
                        self.stats['obstacles_detected'] += 1

                    if directions:
                        closest_dir = min(directions, key=lambda x: x[1])
                        result.obstacle_direction = closest_dir[0]

                    if result.terrain_slope > config.PERCEPTION['HEIGHT_STRATEGY']['SLOPE_THRESHOLD']:
                        result.recommended_height = config.PERCEPTION['HEIGHT_STRATEGY']['STEEP_SLOPE']
                    elif result.open_space_score > config.PERCEPTION['HEIGHT_STRATEGY']['OPENNESS_THRESHOLD']:
                        result.recommended_height = config.PERCEPTION['HEIGHT_STRATEGY']['OPEN_SPACE']

                except ValueError as e:
                    self.logger.error(f"âŒ æ·±åº¦å›¾åƒæ•°æ®è½¬æ¢é”™è¯¯: {e}")
                except Exception as e:
                    self.logger.error(f"âŒ æ·±åº¦å›¾åƒå¤„ç†å¼‚å¸¸: {e}")

            front_response = responses[1]
            if front_response and hasattr(front_response, 'image_data_uint8'):
                try:
                    img_array = np.frombuffer(front_response.image_data_uint8, dtype=np.uint8)

                    if len(img_array) > 0:
                        img_rgb = img_array.reshape(front_response.height, front_response.width, 3)
                        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                        current_time = time.time()
                        if current_time - self.last_red_detection_time >= self.red_detection_interval:
                            red_objects, red_marked_image = self._detect_red_objects(img_bgr, depth_array)
                            result.red_objects = red_objects
                            result.red_objects_count = len(red_objects)
                            result.red_objects_image = red_marked_image
                            self.last_red_detection_time = current_time

                        result.front_image = img_bgr

                        display_info = self._prepare_display_info(result)

                        self._update_exploration_grid(result)

                        self._record_flight_data(result)

                        if self.front_display:
                            manual_info = None
                            if self.state == FlightState.MANUAL:
                                manual_info = self._get_manual_control_info()

                            grid_img = self.exploration_grid.visualize_grid(size=150)
                            additional_images = {'grid': grid_img} if grid_img is not None else {}

                            display_image = result.red_objects_image if result.red_objects_image is not None else img_bgr

                            if config.PERFORMANCE['ENABLE_REALTIME_METRICS']:
                                cpu_usage = psutil.cpu_percent(interval=0)
                                memory_usage = psutil.virtual_memory().percent
                                self.front_display.update_performance_info(cpu_usage, memory_usage)

                            self.front_display.update_image(display_image, display_info, manual_info, additional_images)
                            self.stats['front_image_updates'] += 1

                except Exception as e:
                    self.logger.warning(f"âš ï¸ å‰è§†å›¾åƒå¤„ç†å¼‚å¸¸: {e}")

            self.last_successful_loop = time.time()

            if self.loop_count % 50 == 0 and config.DEBUG.get('LOG_DECISION_DETAILS', False):
                self.logger.debug(f"æ„ŸçŸ¥ç»“æœ: éšœç¢={result.has_obstacle}, è·ç¦»={result.obstacle_distance:.1f}m, "
                                f"å¼€é˜”åº¦={result.open_space_score:.2f}, çº¢è‰²ç‰©ä½“={result.red_objects_count}ä¸ª")

        except Exception as e:
            if "ClientException" in str(type(e)) or "Connection" in str(e):
                self.logger.error(f"âŒ AirSimå®¢æˆ·ç«¯å¼‚å¸¸: {e}")
                self.stats['exceptions_caught'] += 1
                if self.data_logger:
                    self.data_logger.record_event('airsim_exception', {'error': str(e)})
                self._check_connection_health()
            else:
                self.logger.error(f"âŒ æ„ŸçŸ¥è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}")
                self.logger.debug(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                self.stats['exceptions_caught'] += 1
                if self.data_logger:
                    self.data_logger.record_event('perception_exception', {'error': str(e)})

        return result

    def _record_flight_data(self, perception: PerceptionResult):
        if not config.DATA_RECORDING['ENABLED'] or not self.data_logger:
            return

        current_time = time.time()
        if current_time - self.last_data_record_time < self.data_record_interval:
            return

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            vel = state.kinematics_estimated.linear_velocity
            orientation = state.kinematics_estimated.orientation

            roll, pitch, yaw = airsim.to_eularian_angles(orientation)

            cpu_usage = psutil.cpu_percent(interval=0) if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0
            memory_usage = psutil.virtual_memory().percent if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0

            red_objects_count = perception.red_objects_count
            red_objects_visited = sum(1 for obj in self.red_objects if obj.visited)

            data_dict = {
                'timestamp': datetime.now().isoformat(),
                'loop_count': self.loop_count,
                'state': self.state.value,
                'pos_x': pos.x_val,
                'pos_y': pos.y_val,
                'pos_z': pos.z_val,
                'vel_x': vel.x_val,
                'vel_y': vel.y_val,
                'vel_z': vel.z_val,
                'yaw': yaw,
                'pitch': pitch,
                'roll': roll,
                'obstacle_distance': perception.obstacle_distance,
                'open_space_score': perception.open_space_score,
                'terrain_slope': perception.terrain_slope,
                'has_obstacle': perception.has_obstacle,
                'obstacle_direction': perception.obstacle_direction,
                'recommended_height': perception.recommended_height,
                'target_x': self.exploration_target[0] if self.exploration_target else 0.0,
                'target_y': self.exploration_target[1] if self.exploration_target else 0.0,
                'target_z': perception.recommended_height,
                'cpu_usage': cpu_usage,
                'memory_usage': memory_usage,
                'grid_frontiers': len(self.exploration_grid.frontier_cells),
                'grid_explored': np.sum(self.exploration_grid.grid > 0.7),
                'adaptive_speed_factor': self._calculate_adaptive_speed(perception, 0) if hasattr(self, '_calculate_adaptive_speed') else 1.0,
                'red_objects_count': red_objects_count,
                'red_objects_detected': self.stats['red_objects_detected'],
                'red_objects_visited': red_objects_visited,
            }

            self.data_logger.record_flight_data(data_dict)
            self.stats['data_points_recorded'] += 1
            self.last_data_record_time = current_time

        except Exception as e:
            self.logger.warning(f"âš ï¸ è®°å½•é£è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")

    def _extract_obstacle_positions(self, depth_array, height, width):
        obstacles = []

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            orientation = state.kinematics_estimated.orientation
            roll, pitch, yaw = airsim.to_eularian_angles(orientation)

            near_mask = depth_array < self.depth_threshold_near * 1.5

            step = 4
            for i in range(0, height, step):
                for j in range(0, width, step):
                    if near_mask[i, j]:
                        distance = depth_array[i, j]

                        fov_h = math.radians(90)
                        pixel_angle_x = (j - width/2) / (width/2) * (fov_h/2)
                        pixel_angle_y = (i - height/2) / (height/2) * (fov_h/2)

                        z = distance
                        x = z * math.tan(pixel_angle_x)
                        y = z * math.tan(pixel_angle_y)

                        world_x = x * math.cos(yaw) - y * math.sin(yaw) + pos.x_val
                        world_y = x * math.sin(yaw) + y * math.cos(yaw) + pos.y_val

                        obstacles.append((world_x, world_y))

            max_obstacles = 20
            if len(obstacles) > max_obstacles:
                obstacles = random.sample(obstacles, max_obstacles)

        except Exception as e:
            self.logger.warning(f"âš ï¸ æå–éšœç¢ç‰©ä½ç½®å¤±è´¥: {e}")

        return obstacles

    def _update_exploration_grid(self, perception: PerceptionResult):
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            self.exploration_grid.update_position(pos.x_val, pos.y_val)

            if perception.obstacle_positions:
                self.exploration_grid.update_obstacles(perception.obstacle_positions)

            if perception.red_objects:
                self.exploration_grid.update_red_objects(perception.red_objects)

            self.stats['grid_updates'] += 1

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ›´æ–°æ¢ç´¢ç½‘æ ¼å¤±è´¥: {e}")

    def _prepare_display_info(self, perception: PerceptionResult) -> Dict:
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            info = {
                'state': self.state.value,
                'obstacle_distance': perception.obstacle_distance,
                'position': (pos.x_val, pos.y_val, pos.z_val),
                'loop_count': self.loop_count,
                'red_objects_count': perception.red_objects_count,
                'red_objects_visited': sum(1 for obj in self.red_objects if obj.visited),
            }

            if hasattr(self, 'last_decision_info'):
                info['decision_info'] = self.last_decision_info

            if config.DATA_RECORDING['ENABLED']:
                info['data_points'] = self.stats['data_points_recorded']

            return info
        except:
            return {}

    def _get_manual_control_info(self):
        info_lines = []

        if self.control_keys:
            key_names = []
            for key in self.control_keys:
                if key == ord('w'):
                    key_names.append("å‰è¿›")
                elif key == ord('s'):
                    key_names.append("åé€€")
                elif key == ord('a'):
                    key_names.append("å·¦ç§»")
                elif key == ord('d'):
                    key_names.append("å³ç§»")
                elif key == ord('q'):
                    key_names.append("ä¸Šå‡")
                elif key == ord('e'):
                    key_names.append("ä¸‹é™")
                elif key == ord('z'):
                    key_names.append("å·¦è½¬")
                elif key == ord('x'):
                    key_names.append("å³è½¬")
                elif key == 32:
                    key_names.append("æ‚¬åœ")

            if key_names:
                info_lines.append(f"æ§åˆ¶: {', '.join(key_names)}")
        else:
            info_lines.append("æ§åˆ¶: æ‚¬åœ")

        if self.red_objects:
            visited_count = sum(1 for obj in self.red_objects if obj.visited)
            info_lines.append(f"çº¢è‰²ç‰©ä½“: {visited_count}/{len(self.red_objects)}")

        if self.manual_control_start > 0:
            elapsed = time.time() - self.manual_control_start
            info_lines.append(f"æ‰‹åŠ¨æ¨¡å¼: {elapsed:.1f}ç§’")

        info_lines.append("ESC: é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")

        return info_lines

    def apply_manual_control(self):
        if self.state != FlightState.MANUAL:
            return

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            orientation = state.kinematics_estimated.orientation

            _, _, yaw = airsim.to_eularian_angles(orientation)

            vx, vy, vz, yaw_rate = 0.0, 0.0, 0.0, 0.0

            for key in list(self.control_keys.keys()):
                key_char = chr(key).lower() if 0 <= key <= 255 else ''

                if key_char == 'w':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw)
                elif key_char == 's':
                    vx -= config.MANUAL['CONTROL_SPEED'] * math.cos(yaw)
                    vy -= config.MANUAL['CONTROL_SPEED'] * math.sin(yaw)

                if key_char == 'a':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw + math.pi/2)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw + math.pi/2)
                elif key_char == 'd':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw - math.pi/2)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw - math.pi/2)

                if key_char == 'q':
                    vz = -config.MANUAL['ALTITUDE_SPEED']
                elif key_char == 'e':
                    vz = config.MANUAL['ALTITUDE_SPEED']

                if key_char == 'z':
                    yaw_rate = -math.radians(config.MANUAL['YAW_SPEED'])
                elif key_char == 'x':
                    yaw_rate = math.radians(config.MANUAL['YAW_SPEED'])

                if key == 32:
                    self.client.hoverAsync(vehicle_name=self.drone_name)
                    self.control_keys = {}
                    return

            if config.MANUAL['SAFETY_ENABLED']:
                speed = math.sqrt(vx**2 + vy**2)
                if speed > config.MANUAL['MAX_MANUAL_SPEED']:
                    scale = config.MANUAL['MAX_MANUAL_SPEED'] / speed
                    vx *= scale
                    vy *= scale

                target_z = pos.z_val + vz * 0.1
                if target_z > config.MANUAL['MIN_ALTITUDE_LIMIT']:
                    vz = max(vz, (config.MANUAL['MIN_ALTITUDE_LIMIT'] - pos.z_val) * 10)
                if target_z < config.MANUAL['MAX_ALTITUDE_LIMIT']:
                    vz = min(vz, (config.MANUAL['MAX_ALTITUDE_LIMIT'] - pos.z_val) * 10)

            if vx != 0.0 or vy != 0.0 or vz != 0.0:
                self.client.moveByVelocityAsync(vx, vy, vz, 0.1, vehicle_name=self.drone_name)
            elif yaw_rate != 0.0:
                self.client.rotateByYawRateAsync(yaw_rate, 0.1, vehicle_name=self.drone_name)
            elif config.MANUAL['ENABLE_AUTO_HOVER'] and not self.control_keys:
                self.client.hoverAsync(vehicle_name=self.drone_name)

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ‰‹åŠ¨æ§åˆ¶åº”ç”¨å¤±è´¥: {e}")

    def change_state(self, new_state: FlightState):
        if self.state != new_state:
            old_state = self.state.value
            self.logger.info(f"ğŸ”„ çŠ¶æ€è½¬æ¢: {old_state} â†’ {new_state.value}")
            self.state = new_state
            self.state_history.append((time.time(), new_state))
            self.stats['state_changes'] += 1

            if self.data_logger:
                event_data = {
                    'old_state': old_state,
                    'new_state': new_state.value,
                    'loop_count': self.loop_count
                }
                self.data_logger.record_event('state_change', event_data)

    def run_manual_control(self):
        self.logger.info("=" * 60)
        self.logger.info("å¯åŠ¨æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
        self.logger.info("=" * 60)

        if not self.front_display:
            self.logger.error("âŒ å‰è§†çª—å£æœªåˆå§‹åŒ–")
            return

        try:
            self.change_state(FlightState.MANUAL)
            self.manual_control_start = time.time()

            self.front_display.set_manual_mode(True)

            self.logger.info("ğŸ•¹ï¸ è¿›å…¥æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
            print("\n" + "="*60)
            print("ğŸ® æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼å·²å¯åŠ¨")
            print("="*60)
            print("æ§åˆ¶é”®ä½:")
            print("  W: å‰è¿› | S: åé€€ | A: å·¦ç§» | D: å³ç§»")
            print("  Q: ä¸Šå‡ | E: ä¸‹é™ | Z: å·¦è½¬ | X: å³è½¬")
            print("  ç©ºæ ¼: æ‚¬åœ | ESC: é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")
            print("="*60)
            print("ğŸ’¡ æç¤º: æŒ‰é”®æ—¶æ§åˆ¶æŒç»­ç”Ÿæ•ˆï¼Œæ¾å¼€è‡ªåŠ¨åœæ­¢")
            print("        è¯·åœ¨æ— äººæœºå‰è§†çª—å£æ“ä½œ")
            print("="*60)

            self.control_keys = {}

            manual_active = True
            last_control_time = time.time()
            last_image_time = time.time()

            while manual_active and not self.emergency_flag:
                try:
                    if self.front_display.should_exit_manual():
                        self.logger.info("æ”¶åˆ°é€€å‡ºæ‰‹åŠ¨æ¨¡å¼æŒ‡ä»¤")
                        manual_active = False
                        break

                    if self.front_display:
                        window_keys = self.front_display.get_control_inputs()
                        self.control_keys = window_keys.copy()

                    if not self.front_display.display_active:
                        self.logger.info("å‰è§†çª—å£å·²å…³é—­ï¼Œé€€å‡ºæ‰‹åŠ¨æ¨¡å¼")
                        manual_active = False
                        break

                    current_time = time.time()
                    if current_time - last_control_time >= 0.05:
                        self.apply_manual_control()
                        last_control_time = current_time

                    if current_time - last_image_time >= 0.1:
                        try:
                            camera_name = config.CAMERA['DEFAULT_NAME']
                            responses = self.client.simGetImages([
                                airsim.ImageRequest(
                                    camera_name,
                                    airsim.ImageType.Scene,
                                    False,
                                    False
                                )
                            ])

                            if responses and responses[0] and hasattr(responses[0], 'image_data_uint8'):
                                img_array = np.frombuffer(responses[0].image_data_uint8, dtype=np.uint8)
                                if len(img_array) > 0:
                                    img_rgb = img_array.reshape(responses[0].height, responses[0].width, 3)
                                    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                                    try:
                                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                                        pos = state.kinematics_estimated.position
                                        display_info = {
                                            'state': self.state.value,
                                            'position': (pos.x_val, pos.y_val, pos.z_val),
                                            'loop_count': self.loop_count,
                                        }
                                    except:
                                        display_info = {}

                                    if self.front_display:
                                        manual_info = self._get_manual_control_info()
                                        self.front_display.update_image(img_bgr, display_info, manual_info)
                                        last_image_time = current_time
                        except Exception as img_error:
                            pass

                    try:
                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                        pos = state.kinematics_estimated.position
                        current_pos = (pos.x_val, pos.y_val)
                        self._check_red_object_proximity(current_pos)
                    except:
                        pass

                    time.sleep(0.01)

                except KeyboardInterrupt:
                    self.logger.warning("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ‰‹åŠ¨æ§åˆ¶")
                    manual_active = False
                    break
                except Exception as e:
                    self.logger.error(f"âŒ æ‰‹åŠ¨æ§åˆ¶å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(0.1)

            manual_time = time.time() - self.manual_control_start
            self.stats['manual_control_time'] = manual_time

            self.manual_control_start = 0
            self.control_keys = {}
            if self.front_display:
                self.front_display.set_manual_mode(False)

            try:
                self.client.hoverAsync(vehicle_name=self.drone_name).join()
            except:
                pass

            self.logger.info(f"â±ï¸  æ‰‹åŠ¨æ§åˆ¶ç»“æŸï¼ŒæŒç»­æ—¶é—´: {manual_time:.1f}ç§’")

            self.change_state(FlightState.HOVERING)

            print("\n" + "="*60)
            print("æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼å·²ç»“æŸ")
            print(f"æ§åˆ¶æ—¶é—´: {manual_time:.1f}ç§’")
            print(f"æ£€æµ‹åˆ°çº¢è‰²ç‰©ä½“: {self.stats['red_objects_detected']}ä¸ª")
            print("="*60)
            print("è¯·é€‰æ‹©ä¸‹ä¸€æ­¥:")
            print("  1. ç»§ç»­è‡ªåŠ¨æ¢ç´¢")
            print("  2. å†æ¬¡è¿›å…¥æ‰‹åŠ¨æ¨¡å¼")
            print("  3. é™è½å¹¶ç»“æŸä»»åŠ¡")
            print("="*60)

            choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

            if choice == '1':
                self.logger.info("ğŸ”„ è¿”å›è‡ªåŠ¨æ¢ç´¢æ¨¡å¼")
                remaining_time = self.exploration_time - (time.time() - self.start_time)
                if remaining_time > 10:
                    self.exploration_time = remaining_time
                    self.run_perception_loop()
                else:
                    self.logger.info("â° å‰©ä½™æ¢ç´¢æ—¶é—´ä¸è¶³ï¼Œå¼€å§‹è¿”èˆª")
                    self._finish_mission()
            elif choice == '2':
                self.logger.info("ğŸ”„ é‡æ–°è¿›å…¥æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
                self.run_manual_control()
            else:
                self.logger.info("ğŸ›¬ ç”¨æˆ·é€‰æ‹©ç»“æŸä»»åŠ¡")
                self._finish_mission()

        except Exception as e:
            self.logger.error(f"âŒ æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼å‘ç”Ÿå¼‚å¸¸: {e}")
            self.logger.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            self.emergency_stop()

    def run_perception_loop(self):
        self.logger.info("=" * 60)
        self.logger.info("å¯åŠ¨æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶ä¸»å¾ªç¯")
        self.logger.info("=" * 60)

        try:
            self.logger.info("ğŸš€ èµ·é£ä¸­...")
            self.client.takeoffAsync(vehicle_name=self.drone_name).join()
            time.sleep(2)

            self.client.moveToZAsync(self.takeoff_height, 3, vehicle_name=self.drone_name).join()
            self.change_state(FlightState.HOVERING)
            time.sleep(2)

            exploration_start = time.time()

            while (time.time() - exploration_start < self.exploration_time and
                   not self.emergency_flag):

                self.loop_count += 1
                loop_start = time.time()

                perception = self.get_depth_perception()

                try:
                    state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                    pos = state.kinematics_estimated.position
                    current_pos = (pos.x_val, pos.y_val)
                    if self._check_red_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                except:
                    pass

                decision = self.make_intelligent_decision(perception)

                self._execute_control_decision(decision)

                loop_time = time.time() - loop_start
                self.stats['average_loop_time'] = (self.stats['average_loop_time'] * (self.loop_count-1) + loop_time) / self.loop_count
                self.stats['max_loop_time'] = max(self.stats['max_loop_time'], loop_time)
                self.stats['min_loop_time'] = min(self.stats['min_loop_time'], loop_time)

                if self.data_logger:
                    self.data_logger.record_loop_time(loop_time)

                current_time = time.time()
                if current_time - self.last_performance_report >= self.performance_report_interval:
                    self._generate_performance_report()
                    self.last_performance_report = current_time

                if self.loop_count % config.SYSTEM.get('HEALTH_CHECK_INTERVAL', 20) == 0:
                    self._report_status(exploration_start, perception)

                loop_time = time.time() - loop_start
                if loop_time < 0.1:
                    time.sleep(0.1 - loop_time)

            self.logger.info("â° æ¢ç´¢æ—¶é—´åˆ°ï¼Œå¼€å§‹è¿”èˆª")
            self._finish_mission()

        except KeyboardInterrupt:
            self.logger.warning("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ¢ç´¢")
            self.emergency_stop()
        except Exception as e:
            self.logger.error(f"âŒ ä¸»å¾ªç¯å‘ç”Ÿå¼‚å¸¸: {e}")
            self.logger.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            self.emergency_stop()

    def _generate_performance_report(self):
        try:
            if not config.PERFORMANCE['ENABLE_REALTIME_METRICS']:
                return

            cpu_usage = psutil.cpu_percent(interval=0)
            memory_usage = psutil.virtual_memory().percent

            warnings = []
            if cpu_usage > config.PERFORMANCE['CPU_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_usage:.1f}%")

            if memory_usage > config.PERFORMANCE['MEMORY_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_usage:.1f}%")

            avg_loop_time = self.stats.get('average_loop_time', 0)
            if avg_loop_time > config.PERFORMANCE['LOOP_TIME_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å¹³å‡å¾ªç¯æ—¶é—´è¿‡é•¿: {avg_loop_time*1000:.1f}ms")

            if warnings:
                self.logger.warning("ğŸ“Š æ€§èƒ½è­¦å‘Š:")
                for warning in warnings:
                    self.logger.warning(f"  {warning}")

            if self.data_logger:
                performance_data = {
                    'timestamp': datetime.now().isoformat(),
                    'cpu_usage': cpu_usage,
                    'memory_usage': memory_usage,
                    'average_loop_time': avg_loop_time,
                    'max_loop_time': self.stats.get('max_loop_time', 0),
                    'min_loop_time': self.stats.get('min_loop_time', 0),
                    'warnings': warnings
                }
                self.data_logger.record_event('performance_report', performance_data)

        except Exception as e:
            self.logger.warning(f"âš ï¸ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ—¶å‡ºé”™: {e}")

    def make_intelligent_decision(self, perception: PerceptionResult) -> Tuple[float, float, float, float]:
        self.stats['decision_cycles'] += 1
        decision_start = time.time()

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            vel = state.kinematics_estimated.linear_velocity

            target_vx, target_vy, target_z, target_yaw = 0.0, 0.0, perception.recommended_height, 0.0

            if self.state == FlightState.TAKEOFF:
                target_z = self.takeoff_height
                if pos.z_val < self.takeoff_height + 0.5:
                    self.change_state(FlightState.HOVERING)

            elif self.state == FlightState.HOVERING:
                target_yaw = (time.time() % 10) * 0.2

                current_time = time.time()
                if (self.exploration_target is None or
                    current_time - self.target_update_time > self.target_lifetime):

                    self.exploration_target = self.exploration_grid.get_best_exploration_target(
                        (pos.x_val, pos.y_val),
                        perception.red_objects
                    )
                    self.target_update_time = current_time

                    if self.exploration_target:
                        self.logger.info(f"ğŸ¯ æ–°æ¢ç´¢ç›®æ ‡: {self.exploration_target[0]:.1f}, {self.exploration_target[1]:.1f}")

                if self.exploration_target:
                    self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.EXPLORING:
                if perception.has_obstacle:
                    self.change_state(FlightState.AVOIDING)
                    target_vx, target_vy = -vel.x_val * 2, -vel.y_val * 2
                else:
                    current_pos = (pos.x_val, pos.y_val)

                    if self.exploration_target is None:
                        self.exploration_target = self.exploration_grid.get_best_exploration_target(
                            current_pos,
                            perception.red_objects
                        )
                        self.target_update_time = time.time()

                    vector = self.vector_planner.compute_vector(
                        current_pos,
                        self.exploration_target,
                        perception.obstacle_positions,
                        perception.red_objects
                    )

                    speed_factor = self._calculate_adaptive_speed(perception, vector.magnitude())

                    target_speed = self.preferred_speed * speed_factor
                    current_speed = math.sqrt(vel.x_val**2 + vel.y_val**2)
                    speed_error = target_speed - current_speed
                    speed_adjustment = self.velocity_pid.update(speed_error)

                    final_vector = vector.normalize() * (target_speed + speed_adjustment)
                    target_vx = final_vector.x
                    target_vy = final_vector.y

                    self.stats['vector_field_updates'] += 1

                    self.last_decision_info = {
                        'vector_angle': math.atan2(vector.y, vector.x),
                        'vector_magnitude': vector.magnitude(),
                        'grid_score': len(self.exploration_grid.frontier_cells) / 100.0,
                        'speed_factor': speed_factor,
                        'red_objects_in_view': perception.red_objects_count,
                        'decision_time': time.time() - decision_start
                    }

                    if self.exploration_target:
                        distance_to_target = math.sqrt(
                            (self.exploration_target[0] - current_pos[0])**2 +
                            (self.exploration_target[1] - current_pos[1])**2
                        )
                        if distance_to_target < self.target_reached_distance:
                            self.exploration_target = None
                            self.change_state(FlightState.HOVERING)
                            self.logger.info("âœ… åˆ°è¾¾æ¢ç´¢ç›®æ ‡")

            elif self.state == FlightState.AVOIDING:
                if perception.has_obstacle:
                    current_pos = (pos.x_val, pos.y_val)

                    avoid_vector = self.vector_planner.compute_vector(
                        current_pos,
                        None,
                        perception.obstacle_positions,
                        perception.red_objects
                    )

                    if avoid_vector.magnitude() > 0.1:
                        avoid_vector = avoid_vector.normalize() * 1.5
                        target_vx = avoid_vector.x
                        target_vy = avoid_vector.y

                    target_z = pos.z_val - 3
                else:
                    self.change_state(FlightState.EXPLORING)
                    time.sleep(1)

            elif self.state == FlightState.RED_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.EMERGENCY:
                target_vx, target_vy, target_yaw = 0, 0, 0
                target_z = max(pos.z_val, -20)

            elif self.state == FlightState.PLANNING:
                target_vx, target_vy = 0, 0
                target_z = perception.recommended_height

            height_error = target_z - pos.z_val
            height_adjustment = self.height_pid.update(height_error)
            target_z += height_adjustment

            target_z = max(self.max_altitude, min(self.min_altitude, target_z))

            decision_time = time.time() - decision_start
            self.last_decision_info['total_decision_time'] = decision_time

            return target_vx, target_vy, target_z, target_yaw

        except Exception as e:
            self.logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¼‚å¸¸: {e}")
            if self.data_logger:
                self.data_logger.record_event('decision_exception', {'error': str(e)})
            return 0.0, 0.0, self.base_height, 0.0

    def _calculate_adaptive_speed(self, perception: PerceptionResult, vector_magnitude: float) -> float:
        if not config.INTELLIGENT_DECISION['ADAPTIVE_SPEED_ENABLED']:
            return 1.0

        open_factor = min(1.0, perception.open_space_score * 1.2)

        if perception.obstacle_distance < self.depth_threshold_near * 2:
            obs_factor = max(0.3, perception.obstacle_distance / (self.depth_threshold_near * 2))
        else:
            obs_factor = 1.0

        vector_factor = min(1.0, vector_magnitude * 2)

        red_factor = 0.8 if perception.red_objects_count > 0 else 1.0

        speed_factor = open_factor * obs_factor * vector_factor * red_factor * 0.7

        speed_factor = max(
            config.INTELLIGENT_DECISION['MIN_SPEED_FACTOR'],
            min(config.INTELLIGENT_DECISION['MAX_SPEED_FACTOR'], speed_factor)
        )

        return speed_factor

    def _execute_control_decision(self, decision):
        try:
            target_vx, target_vy, target_z, target_yaw = decision

            if self.state in [FlightState.EXPLORING, FlightState.AVOIDING, FlightState.PLANNING, FlightState.RED_OBJECT_INSPECTION]:
                self.client.moveByVelocityZAsync(
                    target_vx, target_vy, target_z, 0.5,
                    drivetrain=airsim.DrivetrainType.MaxDegreeOfFreedom,
                    yaw_mode=airsim.YawMode(is_rate=False, yaw_or_rate=target_yaw),
                    vehicle_name=self.drone_name
                )
            else:
                self.client.moveToPositionAsync(
                    0, 0, target_z, 2,
                    vehicle_name=self.drone_name
                )

            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            self.visited_positions.append((pos.x_val, pos.y_val, pos.z_val))

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ§åˆ¶æŒ‡ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            if self.data_logger:
                self.data_logger.record_event('control_exception', {'error': str(e)})
            try:
                self.client.hoverAsync(vehicle_name=self.drone_name).join()
            except:
                pass

    def _report_status(self, exploration_start, perception):
        elapsed = time.time() - exploration_start
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            self.logger.info(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š [å¾ªç¯#{self.loop_count}]")
            self.logger.info(f"   è¿è¡Œæ—¶é—´: {elapsed:.1f}s / {self.exploration_time}s")
            self.logger.info(f"   é£è¡ŒçŠ¶æ€: {self.state.value}")
            self.logger.info(f"   å½“å‰ä½ç½®: ({pos.x_val:.1f}, {pos.y_val:.1f}, {-pos.z_val:.1f}m)")
            self.logger.info(f"   ç¯å¢ƒæ„ŸçŸ¥: éšœç¢{'æœ‰' if perception.has_obstacle else 'æ— '} "
                            f"| è·ç¦»={perception.obstacle_distance:.1f}m "
                            f"| å¼€é˜”åº¦={perception.open_space_score:.2f}")
            self.logger.info(f"   çº¢è‰²ç‰©ä½“: æ£€æµ‹åˆ°{perception.red_objects_count}ä¸ª "
                            f"| å·²è®¿é—®{self.stats['red_objects_visited']}ä¸ª")
            self.logger.info(f"   æ™ºèƒ½å†³ç­–: å‘é‡åœº{self.stats['vector_field_updates']}æ¬¡ "
                            f"| ç½‘æ ¼æ›´æ–°{self.stats['grid_updates']}æ¬¡")
            self.logger.info(f"   æ¢ç´¢ç½‘æ ¼: å‰æ²¿{len(self.exploration_grid.frontier_cells)}ä¸ª")
            self.logger.info(f"   ç³»ç»Ÿç»Ÿè®¡: å¼‚å¸¸{self.stats['exceptions_caught']}æ¬¡ "
                            f"| çŠ¶æ€åˆ‡æ¢{self.stats['state_changes']}æ¬¡")
            self.logger.info(f"   æ•°æ®è®°å½•: {self.stats['data_points_recorded']}ä¸ªæ•°æ®ç‚¹")
            self.logger.info(f"   æ€§èƒ½ç»Ÿè®¡: å¹³å‡å¾ªç¯{self.stats['average_loop_time']*1000:.1f}ms "
                            f"| æœ€å¤§{self.stats['max_loop_time']*1000:.1f}ms "
                            f"| æœ€å°{self.stats['min_loop_time']*1000:.1f}ms")
            if self.stats['manual_control_time'] > 0:
                self.logger.info(f"   æ‰‹åŠ¨æ§åˆ¶: {self.stats['manual_control_time']:.1f}ç§’")
        except:
            self.logger.info("çŠ¶æ€æŠ¥å‘Š: æ— æ³•è·å–æ— äººæœºçŠ¶æ€")

    def _finish_mission(self):
        self.logger.info("=" * 60)
        self.logger.info("æ¢ç´¢ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹è¿”èˆªç¨‹åº")
        self.logger.info("=" * 60)

        self.change_state(FlightState.RETURNING)

        try:
            self.logger.info("â†©ï¸ è¿”å›èµ·å§‹åŒºåŸŸ...")
            self.client.moveToPositionAsync(0, 0, -10, 4, vehicle_name=self.drone_name).join()
            time.sleep(2)

            self.logger.info("ğŸ›¬ é™è½ä¸­...")
            self.change_state(FlightState.LANDING)
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(3)

        except Exception as e:
            self.logger.error(f"âŒ é™è½è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")

        finally:
            self._cleanup_system()

            self._generate_summary_report()

    def _cleanup_system(self):
        self.logger.info("ğŸ§¹ æ¸…ç†ç³»ç»Ÿèµ„æº...")

        try:
            self.client.armDisarm(False, vehicle_name=self.drone_name)
            self.client.enableApiControl(False, vehicle_name=self.drone_name)
            self.logger.info("âœ… æ— äººæœºæ§åˆ¶å·²å®‰å…¨é‡Šæ”¾")
        except:
            self.logger.warning("âš ï¸ é‡Šæ”¾æ§åˆ¶æ—¶å‡ºç°å¼‚å¸¸")

        if self.front_display:
            self.front_display.stop()
            self.logger.info("âœ… å‰è§†çª—å£å·²å…³é—­")

        if self.data_logger:
            self.logger.info("ğŸ’¾ æ­£åœ¨ä¿å­˜é£è¡Œæ•°æ®...")
            self.data_logger.save_json_data()

            if config.PERFORMANCE['SAVE_PERFORMANCE_REPORT']:
                performance_report = self.data_logger.generate_performance_report()
                self.logger.info(performance_report)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_filename = f"performance_report_{timestamp}.txt"
                with open(report_filename, 'w', encoding='utf-8') as f:
                    f.write(performance_report)
                self.logger.info(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")

    def _generate_summary_report(self):
        total_time = time.time() - self.start_time

        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ ä»»åŠ¡æ€»ç»“æŠ¥å‘Š")
        self.logger.info("=" * 60)
        self.logger.info(f"   æ€»è¿è¡Œæ—¶é—´: {total_time:.1f}ç§’")
        self.logger.info(f"   æ€»å¾ªç¯æ¬¡æ•°: {self.loop_count}")
        if total_time > 0:
            self.logger.info(f"   å¹³å‡å¾ªç¯é¢‘ç‡: {self.loop_count/total_time:.1f} Hz")
        self.logger.info(f"   æ¢ç´¢èˆªç‚¹æ•°é‡: {len(self.visited_positions)}")
        self.logger.info(f"   çŠ¶æ€åˆ‡æ¢æ¬¡æ•°: {self.stats['state_changes']}")
        self.logger.info(f"   æ£€æµ‹åˆ°éšœç¢æ¬¡æ•°: {self.stats['obstacles_detected']}")
        self.logger.info(f"   çº¢è‰²ç‰©ä½“æ£€æµ‹: {self.stats['red_objects_detected']}ä¸ª")
        self.logger.info(f"   çº¢è‰²ç‰©ä½“è®¿é—®: {self.stats['red_objects_visited']}ä¸ª")
        self.logger.info(f"   å‘é‡åœºè®¡ç®—æ¬¡æ•°: {self.stats['vector_field_updates']}")
        self.logger.info(f"   ç½‘æ ¼æ›´æ–°æ¬¡æ•°: {self.stats['grid_updates']}")
        self.logger.info(f"   æ¢ç´¢å‰æ²¿æ•°é‡: {len(self.exploration_grid.frontier_cells)}")
        self.logger.info(f"   å‰è§†å›¾åƒæ›´æ–°æ¬¡æ•°: {self.stats['front_image_updates']}")
        self.logger.info(f"   æ•°æ®è®°å½•ç‚¹æ•°: {self.stats['data_points_recorded']}")
        self.logger.info(f"   æ‰‹åŠ¨æ§åˆ¶æ—¶é—´: {self.stats['manual_control_time']:.1f}ç§’")
        self.logger.info(f"   æ•è·çš„å¼‚å¸¸æ•°: {self.stats['exceptions_caught']}")
        self.logger.info(f"   é‡è¿å°è¯•æ¬¡æ•°: {self.reconnect_attempts}")
        self.logger.info(f"   å¹³å‡å¾ªç¯æ—¶é—´: {self.stats['average_loop_time']*1000:.1f}ms")
        self.logger.info(f"   æœ€å¤§å¾ªç¯æ—¶é—´: {self.stats['max_loop_time']*1000:.1f}ms")
        self.logger.info(f"   æœ€å°å¾ªç¯æ—¶é—´: {self.stats['min_loop_time']*1000:.1f}ms")

        try:
            report_filename = f"mission_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write("AirSimNH æ— äººæœºä»»åŠ¡æŠ¥å‘Š (æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆ - çº¢è‰²ç‰©ä½“æ£€æµ‹ç‰ˆ)\n")
                f.write("=" * 50 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»è¿è¡Œæ—¶é—´: {total_time:.1f}ç§’\n")
                f.write(f"æ€»å¾ªç¯æ¬¡æ•°: {self.loop_count}\n")
                f.write(f"æ¢ç´¢èˆªç‚¹æ•°é‡: {len(self.visited_positions)}\n")
                f.write(f"çŠ¶æ€åˆ‡æ¢æ¬¡æ•°: {self.stats['state_changes']}\n")
                f.write(f"å‘é‡åœºè®¡ç®—æ¬¡æ•°: {self.stats['vector_field_updates']}\n")
                f.write(f"ç½‘æ ¼æ›´æ–°æ¬¡æ•°: {self.stats['grid_updates']}\n")
                f.write(f"æ¢ç´¢å‰æ²¿æ•°é‡: {len(self.exploration_grid.frontier_cells)}\n")
                f.write(f"æ•°æ®è®°å½•ç‚¹æ•°: {self.stats['data_points_recorded']}\n")
                f.write(f"æ‰‹åŠ¨æ§åˆ¶æ—¶é—´: {self.stats['manual_control_time']:.1f}ç§’\n")
                f.write(f"çº¢è‰²ç‰©ä½“æ£€æµ‹æ€»æ•°: {self.stats['red_objects_detected']}ä¸ª\n")
                f.write(f"çº¢è‰²ç‰©ä½“å·²è®¿é—®æ•°: {self.stats['red_objects_visited']}ä¸ª\n")
                f.write(f"å¼‚å¸¸æ•è·æ¬¡æ•°: {self.stats['exceptions_caught']}\n")
                f.write(f"å‰è§†å›¾åƒæ›´æ–°æ¬¡æ•°: {self.stats['front_image_updates']}\n")
                f.write(f"å¹³å‡å¾ªç¯æ—¶é—´: {self.stats['average_loop_time']*1000:.1f}ms\n")
                f.write(f"æœ€å¤§å¾ªç¯æ—¶é—´: {self.stats['max_loop_time']*1000:.1f}ms\n")
                f.write(f"æœ€å°å¾ªç¯æ—¶é—´: {self.stats['min_loop_time']*1000:.1f}ms\n")
                f.write("=" * 50 + "\n")
                f.write("æ™ºèƒ½å†³ç­–é…ç½®:\n")
                for key, value in config.INTELLIGENT_DECISION.items():
                    f.write(f"  {key}: {value}\n")
                f.write("=" * 50 + "\n")
                f.write("é£è¡Œèˆªç‚¹è®°å½•:\n")
                for i, pos in enumerate(self.visited_positions[:20]):
                    f.write(f"  èˆªç‚¹{i+1}: ({pos[0]:.1f}, {pos[1]:.1f}, {pos[2]:.1f})\n")
                if len(self.visited_positions) > 20:
                    f.write(f"  ... è¿˜æœ‰{len(self.visited_positions)-20}ä¸ªèˆªç‚¹\n")
                f.write("=" * 50 + "\n")
                f.write("æ•°æ®è®°å½•ä¿¡æ¯:\n")
                if self.data_logger and config.DATA_RECORDING['ENABLED']:
                    f.write(f"  CSVæ–‡ä»¶: {self.data_logger.csv_filename}\n")
                    f.write(f"  JSONæ–‡ä»¶: {self.data_logger.json_filename}\n")
                else:
                    f.write("  æ•°æ®è®°å½•æœªå¯ç”¨\n")
            self.logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜æŠ¥å‘Šæ–‡ä»¶: {e}")

    def emergency_stop(self):
        if self.emergency_flag:
            return

        self.logger.error("\nğŸ†˜ ç´§æ€¥åœæ­¢ç¨‹åºå¯åŠ¨!")
        self.emergency_flag = True

        self.change_state(FlightState.EMERGENCY)

        try:
            self.client.hoverAsync(vehicle_name=self.drone_name).join()
            time.sleep(1)
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(2)
            self.logger.info("âœ… ç´§æ€¥é™è½æŒ‡ä»¤å·²å‘é€")
        except Exception as e:
            self.logger.error(f"âš ï¸ ç´§æ€¥é™è½å¼‚å¸¸: {e}")

        if self.front_display:
            self.front_display.stop()

        self._cleanup_system()


# ==================== ä¸»ç¨‹åºå…¥å£ ====================

def main():
    print("=" * 70)
    print("AirSimNH æ— äººæœºæ„ŸçŸ¥æ¢ç´¢ç³»ç»Ÿ - æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆï¼ˆçº¢è‰²ç‰©ä½“æ£€æµ‹ç‰ˆï¼‰")
    print(f"å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"é…ç½®çŠ¶æ€: {'å·²åŠ è½½' if CONFIG_LOADED else 'ä½¿ç”¨é»˜è®¤é…ç½®'}")
    print(f"æ—¥å¿—çº§åˆ«: {config.SYSTEM['LOG_LEVEL']}")
    print(f"æ¢ç´¢æ—¶é—´: {config.EXPLORATION['TOTAL_TIME']}ç§’")
    print("=" * 70)
    print("æ™ºèƒ½å†³ç­–ç‰¹æ€§:")
    print("  â€¢ å‘é‡åœºé¿éšœç®—æ³• (VFH)")
    print("  â€¢ åŸºäºç½‘æ ¼çš„ä¿¡æ¯å¢ç›Šæ¢ç´¢")
    print("  â€¢ PIDå¹³æ»‘é£è¡Œæ§åˆ¶")
    print("  â€¢ è‡ªé€‚åº”é€Ÿåº¦è°ƒæ•´")
    print("  â€¢ æ€§èƒ½ç›‘æ§ä¸æ•°æ®é—­ç¯")
    print("  â€¢ çº¢è‰²ç‰©ä½“æ£€æµ‹ä¸è®°å½•")
    print("=" * 70)
    print("æ•°æ®è®°å½•:")
    print(f"  â€¢ CSVæ ¼å¼: {config.DATA_RECORDING.get('SAVE_TO_CSV', False)}")
    print(f"  â€¢ JSONæ ¼å¼: {config.DATA_RECORDING.get('SAVE_TO_JSON', False)}")
    print(f"  â€¢ æ€§èƒ½ç›‘æ§: {config.DATA_RECORDING.get('PERFORMANCE_MONITORING', False)}")
    print(f"  â€¢ çº¢è‰²ç‰©ä½“è®°å½•: {config.DATA_RECORDING.get('RECORD_RED_OBJECTS', False)}")
    print("=" * 70)

    print("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("  1. æ™ºèƒ½æ¢ç´¢æ¨¡å¼ (AIè‡ªä¸»å†³ç­–ï¼ŒåŒ…å«çº¢è‰²ç‰©ä½“æ£€æµ‹)")
    print("  2. æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼ (é”®ç›˜æ§åˆ¶)")
    print("  3. æ··åˆæ¨¡å¼ (å…ˆè‡ªåŠ¨æ¢ç´¢ï¼Œåå¯åˆ‡æ¢)")
    print("=" * 50)

    mode_choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

    explorer = None
    try:
        explorer = PerceptiveExplorer(drone_name="")

        def signal_handler(sig, frame):
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
            if explorer:
                explorer.emergency_stop()
            sys.exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        if mode_choice == '1':
            print("\n" + "="*50)
            print("å¯åŠ¨æ™ºèƒ½æ¢ç´¢æ¨¡å¼ï¼ˆå«çº¢è‰²ç‰©ä½“æ£€æµ‹ï¼‰")
            print("="*50)
            explorer.run_perception_loop()

        elif mode_choice == '2':
            print("\n" + "="*50)
            print("å¯åŠ¨æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
            print("="*50)

            print("æ­£åœ¨èµ·é£...")
            explorer.client.takeoffAsync(vehicle_name="").join()
            time.sleep(2)
            explorer.client.moveToZAsync(-10, 3, vehicle_name="").join()
            time.sleep(2)
            print("èµ·é£å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ‰‹åŠ¨æ§åˆ¶")
            print("è¯·åˆ‡æ¢åˆ°æ— äººæœºå‰è§†çª—å£ï¼Œä½¿ç”¨WSADé”®æ§åˆ¶")

            explorer.run_manual_control()

        elif mode_choice == '3':
            print("\n" + "="*50)
            print("å¯åŠ¨æ··åˆæ¨¡å¼")
            print("="*50)

            explorer.logger.info("ğŸ” å¼€å§‹æ™ºèƒ½æ¢ç´¢ï¼ˆå«çº¢è‰²ç‰©ä½“æ£€æµ‹ï¼‰...")
            original_time = config.EXPLORATION['TOTAL_TIME']
            explorer.exploration_time = min(60, original_time)

            explorer.run_perception_loop()

            if not explorer.emergency_flag:
                print("\n" + "="*50)
                print("æ™ºèƒ½æ¢ç´¢é˜¶æ®µç»“æŸ")
                print(f"æ£€æµ‹åˆ°çº¢è‰²ç‰©ä½“: {explorer.stats['red_objects_detected']}ä¸ª")
                print(f"å·²è®¿é—®çº¢è‰²ç‰©ä½“: {explorer.stats['red_objects_visited']}ä¸ª")
                print("è¯·é€‰æ‹©ä¸‹ä¸€æ­¥:")
                print("  1. è¿›å…¥æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
                print("  2. ç»§ç»­æ™ºèƒ½æ¢ç´¢")
                print("  3. ç»“æŸä»»åŠ¡è¿”èˆª")
                print("="*50)

                next_choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

                if next_choice == '1':
                    explorer.run_manual_control()
                elif next_choice == '2':
                    explorer.exploration_time = original_time - 60
                    if explorer.exploration_time > 10:
                        explorer.run_perception_loop()
                    else:
                        explorer.logger.info("â° å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œå¼€å§‹è¿”èˆª")
                        explorer._finish_mission()
                else:
                    explorer._finish_mission()

        else:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œç¨‹åºé€€å‡º")
            if explorer:
                explorer._cleanup_system()

    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¯åŠ¨å¼‚å¸¸: {e}")
        traceback.print_exc()

        try:
            if explorer and explorer.client:
                explorer.client.landAsync().join()
                explorer.client.armDisarm(False)
                explorer.client.enableApiControl(False)
        except:
            pass


if __name__ == "__main__":
    main()