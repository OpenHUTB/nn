"""
AirSimNH ÊÑüÁü•È©±Âä®Ëá™‰∏ªÊé¢Á¥¢Êó†‰∫∫Êú∫ - Êô∫ËÉΩÂÜ≥Á≠ñÂ¢ûÂº∫ÁâàÔºàÁ∫¢Ëâ≤„ÄÅËìùËâ≤‰∏éÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµãÁâàÔºâ
Ê†∏ÂøÉÔºöËßÜËßâÊÑüÁü• ‚Üí ËØ≠‰πâÁêÜËß£ ‚Üí Êô∫ËÉΩÂÜ≥Á≠ñ ‚Üí ÂÆâÂÖ®ÊâßË°å
ÈõÜÊàêÔºöÈÖçÁΩÆÁÆ°ÁêÜ„ÄÅÊó•ÂøóÁ≥ªÁªü„ÄÅÂºÇÂ∏∏ÊÅ¢Â§ç„ÄÅÂâçËßÜÁ™óÂè£ÊòæÁ§∫
Êñ∞Â¢ûÔºöÂêëÈáèÂú∫ÈÅøÈöúÁÆóÊ≥ï„ÄÅÂü∫‰∫éÁΩëÊ†ºÁöÑ‰ø°ÊÅØÂ¢ûÁõäÊé¢Á¥¢„ÄÅÂπ≥ÊªëÈ£ûË°åÊéßÂà∂
Êñ∞Â¢ûÔºöÊÄßËÉΩÁõëÊéß‰∏éÊï∞ÊçÆÈó≠ÁéØÁ≥ªÁªü„ÄÅÁ∫¢Ëâ≤„ÄÅËìùËâ≤‰∏éÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµã‰∏éËÆ∞ÂΩï
Êñ∞Â¢ûÔºö‰ø°ÊÅØÊòæÁ§∫Á™óÂè£ÔºåÂàÜÁ¶ªÂâçËßÜÁîªÈù¢‰∏éÁ≥ªÁªü‰ø°ÊÅØ
ÁâàÊú¨: 3.6 (ÂèåÁ™óÂè£‰∏âËâ≤Áâ©‰ΩìÊ£ÄÊµãÁâà)
"""

import airsim
import time
import numpy as np
import cv2
import math
import json
import csv
from collections import deque
from dataclasses import dataclass
from enum import Enum
import threading
import queue
import signal
import sys
from typing import Tuple, List, Optional, Dict, Set, Any
import traceback
import logging
from datetime import datetime
import random
import psutil
import os
import gc

# ============ ÂØºÂÖ•ÈÖçÁΩÆÊñá‰ª∂ ============
try:
    import config
    CONFIG_LOADED = True
except ImportError as e:
    print(f"‚ùå Êó†Ê≥ïÂä†ËΩΩÈÖçÁΩÆÊñá‰ª∂ config.py: {e}")
    print("Ê≠£Âú®‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ...")
    CONFIG_LOADED = False
    class DefaultConfig:
        EXPLORATION = {'TOTAL_TIME': 120, 'PREFERRED_SPEED': 2.5, 'BASE_HEIGHT': -15.0,
                      'MAX_ALTITUDE': -30.0, 'MIN_ALTITUDE': -5.0, 'TAKEOFF_HEIGHT': -10.0}
        PERCEPTION = {'DEPTH_NEAR_THRESHOLD': 5.0, 'DEPTH_SAFE_THRESHOLD': 10.0,
                     'MIN_GROUND_CLEARANCE': 2.0, 'MAX_PITCH_ANGLE_DEG': 15,
                     'SCAN_ANGLES': [-60, -45, -30, -15, 0, 15, 30, 45, 60],
                     'HEIGHT_STRATEGY': {'STEEP_SLOPE': -20.0, 'OPEN_SPACE': -12.0,
                                         'DEFAULT': -15.0, 'SLOPE_THRESHOLD': 5.0,
                                         'OPENNESS_THRESHOLD': 0.7},
                     'RED_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                            'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                            'MEMORY_TIME': 5.0},
                     'BLUE_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                              'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                              'MEMORY_TIME': 5.0},
                     'BLACK_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                               'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                               'MEMORY_TIME': 5.0}}
        DISPLAY = {'FRONT_VIEW_WINDOW': {'NAME': "Êó†‰∫∫Êú∫ÂâçËßÜÁîªÈù¢", 'WIDTH': 640, 'HEIGHT': 480,
                                        'ENABLE_SHARPENING': True, 'SHOW_INFO_OVERLAY': True,
                                        'REFRESH_RATE_MS': 30, 'SHOW_RED_OBJECTS': True,
                                        'SHOW_BLUE_OBJECTS': True, 'SHOW_BLACK_OBJECTS': True},
                   'INFO_WINDOW': {'NAME': "Êó†‰∫∫Êú∫‰ø°ÊÅØÈù¢Êùø", 'WIDTH': 800, 'HEIGHT': 600,
                                  'BACKGROUND_COLOR': (20, 20, 30), 'TEXT_COLOR': (220, 220, 255),
                                  'HIGHLIGHT_COLOR': (0, 200, 255), 'WARNING_COLOR': (0, 100, 255),
                                  'SUCCESS_COLOR': (0, 255, 150), 'REFRESH_RATE_MS': 100,
                                  'SHOW_GRID': True, 'GRID_SIZE': 300,
                                  'SHOW_OBJECTS_STATS': True, 'SHOW_SYSTEM_STATS': True,
                                  'SHOW_PERFORMANCE': True}}
        SYSTEM = {'LOG_LEVEL': 'INFO', 'LOG_TO_FILE': True, 'LOG_FILENAME': 'drone_log.txt',
                 'MAX_RECONNECT_ATTEMPTS': 3, 'RECONNECT_DELAY': 2.0,
                 'ENABLE_HEALTH_CHECK': True, 'HEALTH_CHECK_INTERVAL': 20}
        CAMERA = {'DEFAULT_NAME': "0",
                 'RED_COLOR_RANGE': {'LOWER1': [0, 120, 70], 'UPPER1': [10, 255, 255],
                                    'LOWER2': [170, 120, 70], 'UPPER2': [180, 255, 255]},
                 'BLUE_COLOR_RANGE': {'LOWER': [100, 150, 50], 'UPPER': [130, 255, 255]},
                 'BLACK_COLOR_RANGE': {'LOWER': [0, 0, 0], 'UPPER': [180, 255, 50]}}
        MANUAL = {
            'CONTROL_SPEED': 3.0,
            'ALTITUDE_SPEED': 2.0,
            'YAW_SPEED': 30.0,
            'ENABLE_AUTO_HOVER': True,
            'DISPLAY_CONTROLS': True,
            'SAFETY_ENABLED': True,
            'MAX_MANUAL_SPEED': 5.0,
            'MIN_ALTITUDE_LIMIT': -5.0,
            'MAX_ALTITUDE_LIMIT': -30.0
        }
        INTELLIGENT_DECISION = {
            'VECTOR_FIELD_RADIUS': 8.0,
            'OBSTACLE_REPULSION_GAIN': 3.0,
            'GOAL_ATTRACTION_GAIN': 2.0,
            'SMOOTHING_FACTOR': 0.3,
            'MIN_TURN_ANGLE_DEG': 10,
            'MAX_TURN_ANGLE_DEG': 60,
            'GRID_RESOLUTION': 2.0,
            'GRID_SIZE': 50,
            'INFORMATION_GAIN_DECAY': 0.95,
            'EXPLORATION_FRONTIER_THRESHOLD': 0.3,
            'PID_KP': 1.5,
            'PID_KI': 0.05,
            'PID_KD': 0.2,
            'SMOOTHING_WINDOW_SIZE': 5,
            'ADAPTIVE_SPEED_ENABLED': True,
            'MIN_SPEED_FACTOR': 0.3,
            'MAX_SPEED_FACTOR': 1.5,
            'MEMORY_WEIGHT': 0.7,
            'CURIOUSITY_WEIGHT': 0.3,
            'TARGET_LIFETIME': 15.0,
            'TARGET_REACHED_DISTANCE': 3.0,
            'RED_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.5, 'DETECTION_RADIUS': 10.0,
                                      'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.5},
            'BLUE_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.2, 'DETECTION_RADIUS': 8.0,
                                       'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.3},
            'BLACK_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.0, 'DETECTION_RADIUS': 8.0,
                                         'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.2}
        }
        DEBUG = {
            'SAVE_PERCEPTION_IMAGES': False,
            'IMAGE_SAVE_INTERVAL': 50,
            'LOG_DECISION_DETAILS': False,
            'SAVE_RED_OBJECT_IMAGES': False,
            'SAVE_BLUE_OBJECT_IMAGES': False,
            'SAVE_BLACK_OBJECT_IMAGES': False
        }
        DATA_RECORDING = {
            'ENABLED': True,
            'RECORD_INTERVAL': 0.2,
            'SAVE_TO_CSV': True,
            'SAVE_TO_JSON': True,
            'CSV_FILENAME': 'flight_data.csv',
            'JSON_FILENAME': 'flight_data.json',
            'PERFORMANCE_MONITORING': True,
            'SYSTEM_METRICS_INTERVAL': 5.0,
            'RECORD_RED_OBJECTS': True,
            'RECORD_BLUE_OBJECTS': True,
            'RECORD_BLACK_OBJECTS': True
        }
        PERFORMANCE = {
            'ENABLE_REALTIME_METRICS': True,
            'CPU_WARNING_THRESHOLD': 80.0,
            'MEMORY_WARNING_THRESHOLD': 80.0,
            'LOOP_TIME_WARNING_THRESHOLD': 0.2,
            'SAVE_PERFORMANCE_REPORT': True,
            'REPORT_INTERVAL': 30.0,
        }
    config = DefaultConfig()


class FlightState(Enum):
    """Êó†‰∫∫Êú∫È£ûË°åÁä∂ÊÄÅÊûö‰∏æ"""
    TAKEOFF = "Ëµ∑È£û"
    HOVERING = "ÊÇ¨ÂÅúËßÇÊµã"
    EXPLORING = "‰∏ªÂä®Êé¢Á¥¢"
    AVOIDING = "ÈÅøÈöúÊú∫Âä®"
    RETURNING = "ËøîËà™‰∏≠"
    LANDING = "ÈôçËêΩ"
    EMERGENCY = "Á¥ßÊÄ•Áä∂ÊÄÅ"
    MANUAL = "ÊâãÂä®ÊéßÂà∂"
    PLANNING = "Ë∑ØÂæÑËßÑÂàí"
    RED_OBJECT_INSPECTION = "Á∫¢Ëâ≤Áâ©‰ΩìÊ£ÄÊü•"
    BLUE_OBJECT_INSPECTION = "ËìùËâ≤Áâ©‰ΩìÊ£ÄÊü•"
    BLACK_OBJECT_INSPECTION = "ÈªëËâ≤Áâ©‰ΩìÊ£ÄÊü•"


@dataclass
class RedObject:
    """Á∫¢Ëâ≤Áâ©‰ΩìÊï∞ÊçÆÁªìÊûÑ"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


@dataclass
class BlueObject:
    """ËìùËâ≤Áâ©‰ΩìÊï∞ÊçÆÁªìÊûÑ"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


@dataclass
class BlackObject:
    """ÈªëËâ≤Áâ©‰ΩìÊï∞ÊçÆÁªìÊûÑ"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


class Vector2D:
    """‰∫åÁª¥ÂêëÈáèÁ±ª"""
    def __init__(self, x=0.0, y=0.0):
        self.x = x
        self.y = y

    def __add__(self, other):
        return Vector2D(self.x + other.x, self.y + other.y)

    def __sub__(self, other):
        return Vector2D(self.x - other.x, self.y - other.y)

    def __mul__(self, scalar):
        return Vector2D(self.x * scalar, self.y * scalar)

    def __truediv__(self, scalar):
        return Vector2D(self.x / scalar, self.y / scalar)

    def magnitude(self):
        return math.sqrt(self.x**2 + self.y**2)

    def normalize(self):
        mag = self.magnitude()
        if mag > 0:
            return Vector2D(self.x / mag, self.y / mag)
        return Vector2D()

    def rotate(self, angle):
        cos_a = math.cos(angle)
        sin_a = math.sin(angle)
        return Vector2D(
            self.x * cos_a - self.y * sin_a,
            self.x * sin_a + self.y * cos_a
        )

    def to_tuple(self):
        return (self.x, self.y)

    @staticmethod
    def from_angle(angle, magnitude=1.0):
        return Vector2D(magnitude * math.cos(angle), magnitude * math.sin(angle))


class PIDController:
    """PIDÊéßÂà∂Âô®Á±ª"""
    def __init__(self, kp, ki, kd, integral_limit=5.0, output_limit=10.0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.integral_limit = integral_limit
        self.output_limit = output_limit

        self.previous_error = 0.0
        self.integral = 0.0
        self.previous_time = time.time()

    def update(self, error, dt=None):
        if dt is None:
            current_time = time.time()
            dt = current_time - self.previous_time
            self.previous_time = current_time

        self.integral += error * dt
        self.integral = max(-self.integral_limit, min(self.integral_limit, self.integral))

        derivative = (error - self.previous_error) / dt if dt > 0 else 0.0
        self.previous_error = error

        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        return max(-self.output_limit, min(self.output_limit, output))


class ExplorationGrid:
    """Êé¢Á¥¢ÁΩëÊ†ºÂú∞ÂõæÁ±ª"""
    def __init__(self, resolution=2.0, grid_size=50):
        self.resolution = resolution
        self.grid_size = grid_size
        self.half_size = grid_size // 2

        self.grid = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.information_gain = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.obstacle_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.visit_time = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.red_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.blue_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.black_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.current_idx = (self.half_size, self.half_size)
        self.frontier_cells = set()

        print(f"üó∫Ô∏è ÂàùÂßãÂåñÊé¢Á¥¢ÁΩëÊ†º: {grid_size}x{grid_size}, ÂàÜËæ®Áéá: {resolution}m")

    def world_to_grid(self, world_x, world_y):
        grid_x = int(world_x / self.resolution) + self.half_size
        grid_y = int(world_y / self.resolution) + self.half_size

        grid_x = max(0, min(self.grid_size - 1, grid_x))
        grid_y = max(0, min(self.grid_size - 1, grid_y))

        return (grid_x, grid_y)

    def grid_to_world(self, grid_x, grid_y):
        world_x = (grid_x - self.half_size) * self.resolution
        world_y = (grid_y - self.half_size) * self.resolution
        return (world_x, world_y)

    def update_position(self, world_x, world_y):
        self.current_idx = self.world_to_grid(world_x, world_y)

        x, y = self.current_idx
        radius = 3

        for dx in range(-radius, radius + 1):
            for dy in range(-radius, radius + 1):
                nx, ny = x + dx, y + dy
                if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                    distance = math.sqrt(dx**2 + dy**2)
                    exploration_value = max(0, 1.0 - distance / radius)
                    self.grid[nx, ny] = max(self.grid[nx, ny], exploration_value)
                    self.visit_time[nx, ny] = time.time()

        self._update_frontiers()

    def _update_frontiers(self):
        self.frontier_cells.clear()

        for x in range(1, self.grid_size - 1):
            for y in range(1, self.grid_size - 1):
                if self.grid[x, y] > 0.7:
                    neighbors = [
                        (x-1, y), (x+1, y), (x, y-1), (x, y+1),
                        (x-1, y-1), (x-1, y+1), (x+1, y-1), (x+1, y+1)
                    ]

                    for nx, ny in neighbors:
                        if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                            if self.grid[nx, ny] < 0.3 and not self.obstacle_grid[nx, ny]:
                                unexplored_neighbors = 0
                                for nnx in range(nx-1, nx+2):
                                    for nny in range(ny-1, ny+2):
                                        if 0 <= nnx < self.grid_size and 0 <= nny < self.grid_size:
                                            if self.grid[nnx, nny] < 0.3:
                                                unexplored_neighbors += 1

                                self.information_gain[nx, ny] = unexplored_neighbors / 9.0
                                self.frontier_cells.add((nx, ny))

    def update_obstacles(self, obstacles_world):
        for obs_x, obs_y in obstacles_world:
            grid_x, grid_y = self.world_to_grid(obs_x, obs_y)

            radius = 2
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.obstacle_grid[nx, ny] = True
                        self.grid[nx, ny] = 0.0

    def update_red_objects(self, red_objects):
        self.red_object_grid.fill(False)

        for obj in red_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.red_object_grid[nx, ny] = True

    def update_blue_objects(self, blue_objects):
        self.blue_object_grid.fill(False)

        for obj in blue_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.blue_object_grid[nx, ny] = True

    def update_black_objects(self, black_objects):
        self.black_object_grid.fill(False)

        for obj in black_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.black_object_grid[nx, ny] = True

    def get_best_exploration_target(self, current_pos, red_objects=None, blue_objects=None, black_objects=None):
        # ‰ºòÂÖàÊ£ÄÊü•Á∫¢Ëâ≤Áâ©‰Ωì
        if red_objects and len(red_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in red_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 15.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        # ÂÖ∂Ê¨°Ê£ÄÊü•ËìùËâ≤Áâ©‰Ωì
        if blue_objects and len(blue_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in blue_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 12.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        # ÂÜçÊ¨°Ê£ÄÊü•ÈªëËâ≤Áâ©‰Ωì
        if black_objects and len(black_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in black_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 12.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        if not self.frontier_cells:
            angle = random.uniform(0, 2 * math.pi)
            distance = 10.0
            return (
                current_pos[0] + distance * math.cos(angle),
                current_pos[1] + distance * math.sin(angle)
            )

        best_score = -1
        best_target = None
        current_x, current_y = current_pos

        for fx, fy in self.frontier_cells:
            info_gain = self.information_gain[fx, fy]

            world_x, world_y = self.grid_to_world(fx, fy)
            distance = math.sqrt((world_x - current_x)**2 + (world_y - current_y)**2)
            distance_cost = min(1.0, distance / 30.0)

            time_since_visit = time.time() - self.visit_time[fx, fy]
            time_factor = min(1.0, time_since_visit / 60.0)

            red_bonus = 0.0
            if self.red_object_grid[fx, fy]:
                red_bonus = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            blue_bonus = 0.0
            if self.blue_object_grid[fx, fy]:
                blue_bonus = config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            black_bonus = 0.0
            if self.black_object_grid[fx, fy]:
                black_bonus = config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            score = (
                config.INTELLIGENT_DECISION['CURIOUSITY_WEIGHT'] * info_gain +
                (1 - config.INTELLIGENT_DECISION['MEMORY_WEIGHT'] * time_factor) -
                distance_cost * 0.3 +
                red_bonus + blue_bonus + black_bonus
            )

            if score > best_score:
                best_score = score
                best_target = (world_x, world_y)

        return best_target

    def visualize_grid(self, size=300):
        if self.grid.size == 0:
            return None

        img_size = min(size, self.grid_size * 5)
        img = np.zeros((img_size, img_size, 3), dtype=np.uint8)

        cell_size = img_size // self.grid_size

        for x in range(self.grid_size):
            for y in range(self.grid_size):
                color = (0, 0, 0)

                if (x, y) == self.current_idx:
                    color = (0, 255, 0)
                elif self.obstacle_grid[x, y]:
                    color = (0, 0, 255)
                elif self.red_object_grid[x, y]:
                    color = (0, 100, 255)  # Á∫¢Ëâ≤Áâ©‰ΩìÊòæÁ§∫‰∏∫Ê©ôËâ≤
                elif self.blue_object_grid[x, y]:
                    color = (255, 100, 0)  # ËìùËâ≤Áâ©‰ΩìÊòæÁ§∫‰∏∫ÈùíËâ≤
                elif self.black_object_grid[x, y]:
                    color = (128, 128, 128)  # ÈªëËâ≤Áâ©‰ΩìÊòæÁ§∫‰∏∫ÁÅ∞Ëâ≤
                elif self.grid[x, y] > 0.7:
                    color = (200, 200, 200)
                elif self.grid[x, y] > 0.3:
                    color = (100, 100, 100)
                elif (x, y) in self.frontier_cells:
                    gain = self.information_gain[x, y]
                    color = (0, int(255 * gain), int(255 * (1 - gain)))

                x1 = x * cell_size
                y1 = y * cell_size
                x2 = (x + 1) * cell_size
                y2 = (y + 1) * cell_size

                cv2.rectangle(img, (y1, x1), (y2, x2), color, -1)

        return img


class DataLogger:
    """Êï∞ÊçÆËÆ∞ÂΩïÂô®Á±ª"""

    def __init__(self, enable_csv=True, enable_json=True, csv_filename=None, json_filename=None):
        self.enable_csv = enable_csv
        self.enable_json = enable_json

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if csv_filename:
            self.csv_filename = csv_filename
        else:
            self.csv_filename = f"flight_data_{timestamp}.csv"

        if json_filename:
            self.json_filename = json_filename
        else:
            self.json_filename = f"flight_data_{timestamp}.json"

        self.data_buffer = []
        self.json_data = {
            "flight_info": {
                "start_time": datetime.now().isoformat(),
                "config_loaded": CONFIG_LOADED,
                "system": config.SYSTEM,
                "exploration": config.EXPLORATION,
                "perception": config.PERCEPTION,
                "intelligent_decision": config.INTELLIGENT_DECISION,
                "performance": config.PERFORMANCE
            },
            "flight_data": []
        }

        self.performance_metrics = {
            "start_time": time.time(),
            "cpu_usage": [],
            "memory_usage": [],
            "loop_times": [],
            "data_points": 0
        }

        self.red_objects_detected = []
        self.blue_objects_detected = []
        self.black_objects_detected = []

        # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂ÁºìÂÜ≤Âå∫Â§ßÂ∞è
        self.max_flight_data = config.DATA_RECORDING.get('MAX_FLIGHT_DATA_BUFFER', 500)
        self.max_objects_buffer = config.DATA_RECORDING.get('MAX_OBJECTS_BUFFER', 200)
        self.max_events_buffer = config.DATA_RECORDING.get('MAX_EVENTS_BUFFER', 100)
        self.auto_save_interval = config.DATA_RECORDING.get('AUTO_SAVE_INTERVAL', 60.0)
        self.last_auto_save_time = time.time()
        self.max_metrics_buffer = config.PERFORMANCE.get('MAX_METRICS_BUFFER', 500)

        self.csv_columns = [
            'timestamp', 'loop_count', 'state', 'pos_x', 'pos_y', 'pos_z',
            'vel_x', 'vel_y', 'vel_z', 'yaw', 'pitch', 'roll',
            'obstacle_distance', 'open_space_score', 'terrain_slope',
            'has_obstacle', 'obstacle_direction', 'recommended_height',
            'target_x', 'target_y', 'target_z', 'velocity_command_x',
            'velocity_command_y', 'velocity_command_z', 'yaw_command',
            'battery_level', 'cpu_usage', 'memory_usage', 'loop_time',
            'grid_frontiers', 'grid_explored', 'vector_field_magnitude',
            'adaptive_speed_factor', 'decision_making_time', 'perception_time',
            'red_objects_count', 'red_objects_detected', 'red_objects_visited',
            'blue_objects_count', 'blue_objects_detected', 'blue_objects_visited',
            'black_objects_count', 'black_objects_detected', 'black_objects_visited'
        ]

        if self.enable_csv:
            self._init_csv_file()

        print(f"üìä Êï∞ÊçÆËÆ∞ÂΩïÂô®ÂàùÂßãÂåñÂÆåÊàê")
        print(f"  CSVÊñá‰ª∂: {self.csv_filename}")
        print(f"  JSONÊñá‰ª∂: {self.json_filename}")

    def _init_csv_file(self):
        try:
            with open(self.csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=self.csv_columns)
                writer.writeheader()
        except Exception as e:
            print(f"‚ùå Êó†Ê≥ïÂàùÂßãÂåñCSVÊñá‰ª∂: {e}")
            self.enable_csv = False

    def record_flight_data(self, data_dict):
        if not config.DATA_RECORDING['ENABLED']:
            return

        try:
            data_dict['timestamp'] = datetime.now().isoformat()

            if self.enable_csv:
                with open(self.csv_filename, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=self.csv_columns)
                    row = {col: data_dict.get(col, '') for col in self.csv_columns}
                    writer.writerow(row)

            if self.enable_json:
                self.json_data['flight_data'].append(data_dict)
                # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂flight_dataÈïøÂ∫¶ÔºåË∂ÖËøáÈôêÂà∂Êó∂‰øùÂ≠òÂπ∂Ê∏ÖÁ©∫
                if len(self.json_data['flight_data']) >= self.max_flight_data:
                    self._auto_save_and_clear()

            self.performance_metrics['data_points'] += 1

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÂÆöÊúüËá™Âä®‰øùÂ≠ò
            current_time = time.time()
            if current_time - self.last_auto_save_time >= self.auto_save_interval:
                self._auto_save_and_clear()
                self.last_auto_save_time = current_time

            if self.performance_metrics['data_points'] % 10 == 0:
                self._collect_system_metrics()

        except Exception as e:
            print(f"‚ö†Ô∏è ËÆ∞ÂΩïÈ£ûË°åÊï∞ÊçÆÊó∂Âá∫Èîô: {e}")

    def record_red_object(self, red_object):
        try:
            red_object_data = {
                'id': red_object.id,
                'position': red_object.position,
                'pixel_position': red_object.pixel_position,
                'size': red_object.size,
                'confidence': red_object.confidence,
                'timestamp': red_object.timestamp,
                'visited': red_object.visited
            }

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂Áâ©‰ΩìËÆ∞ÂΩïÂàóË°®ÈïøÂ∫¶
            if len(self.red_objects_detected) >= self.max_objects_buffer:
                self.red_objects_detected = self.red_objects_detected[-self.max_objects_buffer//2:]
            self.red_objects_detected.append(red_object_data)

            if 'red_objects' not in self.json_data:
                self.json_data['red_objects'] = []

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂JSON‰∏≠ÁöÑÁâ©‰ΩìÂàóË°®ÈïøÂ∫¶
            if len(self.json_data['red_objects']) >= self.max_objects_buffer:
                self.json_data['red_objects'] = self.json_data['red_objects'][-self.max_objects_buffer//2:]
            self.json_data['red_objects'].append(red_object_data)

        except Exception as e:
            print(f"‚ö†Ô∏è ËÆ∞ÂΩïÁ∫¢Ëâ≤Áâ©‰ΩìÊó∂Âá∫Èîô: {e}")

    def record_blue_object(self, blue_object):
        try:
            blue_object_data = {
                'id': blue_object.id,
                'position': blue_object.position,
                'pixel_position': blue_object.pixel_position,
                'size': blue_object.size,
                'confidence': blue_object.confidence,
                'timestamp': blue_object.timestamp,
                'visited': blue_object.visited
            }

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂Áâ©‰ΩìËÆ∞ÂΩïÂàóË°®ÈïøÂ∫¶
            if len(self.blue_objects_detected) >= self.max_objects_buffer:
                self.blue_objects_detected = self.blue_objects_detected[-self.max_objects_buffer//2:]
            self.blue_objects_detected.append(blue_object_data)

            if 'blue_objects' not in self.json_data:
                self.json_data['blue_objects'] = []

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂JSON‰∏≠ÁöÑÁâ©‰ΩìÂàóË°®ÈïøÂ∫¶
            if len(self.json_data['blue_objects']) >= self.max_objects_buffer:
                self.json_data['blue_objects'] = self.json_data['blue_objects'][-self.max_objects_buffer//2:]
            self.json_data['blue_objects'].append(blue_object_data)

        except Exception as e:
            print(f"‚ö†Ô∏è ËÆ∞ÂΩïËìùËâ≤Áâ©‰ΩìÊó∂Âá∫Èîô: {e}")

    def record_black_object(self, black_object):
        try:
            black_object_data = {
                'id': black_object.id,
                'position': black_object.position,
                'pixel_position': black_object.pixel_position,
                'size': black_object.size,
                'confidence': black_object.confidence,
                'timestamp': black_object.timestamp,
                'visited': black_object.visited
            }

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂Áâ©‰ΩìËÆ∞ÂΩïÂàóË°®ÈïøÂ∫¶
            if len(self.black_objects_detected) >= self.max_objects_buffer:
                self.black_objects_detected = self.black_objects_detected[-self.max_objects_buffer//2:]
            self.black_objects_detected.append(black_object_data)

            if 'black_objects' not in self.json_data:
                self.json_data['black_objects'] = []

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂JSON‰∏≠ÁöÑÁâ©‰ΩìÂàóË°®ÈïøÂ∫¶
            if len(self.json_data['black_objects']) >= self.max_objects_buffer:
                self.json_data['black_objects'] = self.json_data['black_objects'][-self.max_objects_buffer//2:]
            self.json_data['black_objects'].append(black_object_data)

        except Exception as e:
            print(f"‚ö†Ô∏è ËÆ∞ÂΩïÈªëËâ≤Áâ©‰ΩìÊó∂Âá∫Èîô: {e}")

    def _collect_system_metrics(self):
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            self.performance_metrics['cpu_usage'].append(cpu_percent)

            memory_info = psutil.virtual_memory()
            memory_percent = memory_info.percent
            self.performance_metrics['memory_usage'].append(memory_percent)

            # ÂÜÖÂ≠ò‰ºòÂåñÔºö‰ΩøÁî®ÈÖçÁΩÆÁöÑÊúÄÂ§ßÁºìÂÜ≤Âå∫Â§ßÂ∞è
            max_length = self.max_metrics_buffer
            if len(self.performance_metrics['cpu_usage']) > max_length:
                self.performance_metrics['cpu_usage'] = self.performance_metrics['cpu_usage'][-max_length:]
            if len(self.performance_metrics['memory_usage']) > max_length:
                self.performance_metrics['memory_usage'] = self.performance_metrics['memory_usage'][-max_length:]

        except Exception as e:
            print(f"‚ö†Ô∏è Êî∂ÈõÜÁ≥ªÁªüÊåáÊ†áÊó∂Âá∫Èîô: {e}")

    def record_loop_time(self, loop_time):
        self.performance_metrics['loop_times'].append(loop_time)

        # ÂÜÖÂ≠ò‰ºòÂåñÔºö‰ΩøÁî®ÈÖçÁΩÆÁöÑÊúÄÂ§ßÁºìÂÜ≤Âå∫Â§ßÂ∞è
        max_length = self.max_metrics_buffer
        if len(self.performance_metrics['loop_times']) > max_length:
            self.performance_metrics['loop_times'] = self.performance_metrics['loop_times'][-max_length:]

    def record_event(self, event_type, event_data):
        try:
            event_record = {
                'timestamp': datetime.now().isoformat(),
                'event_type': event_type,
                'event_data': event_data
            }

            if 'events' not in self.json_data:
                self.json_data['events'] = []

            # ÂÜÖÂ≠ò‰ºòÂåñÔºöÈôêÂà∂eventsÂàóË°®ÈïøÂ∫¶
            if len(self.json_data['events']) >= self.max_events_buffer:
                self.json_data['events'] = self.json_data['events'][-self.max_events_buffer//2:]
            self.json_data['events'].append(event_record)

        except Exception as e:
            print(f"‚ö†Ô∏è ËÆ∞ÂΩï‰∫ã‰ª∂Êó∂Âá∫Èîô: {e}")

    def _auto_save_and_clear(self):
        """Ëá™Âä®‰øùÂ≠òÊï∞ÊçÆÂπ∂Ê∏ÖÁ©∫ÁºìÂÜ≤Âå∫ÔºàÂÜÖÂ≠ò‰ºòÂåñÔºâ"""
        if not self.enable_json or len(self.json_data['flight_data']) == 0:
            return

        try:
            # ÂàõÂª∫‰∏¥Êó∂Êñá‰ª∂Âêç
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_filename = self.json_filename.replace('.json', f'_temp_{timestamp}.json')
            
            # ‰øùÂ≠òÂΩìÂâçÊï∞ÊçÆ
            with open(temp_filename, 'w', encoding='utf-8') as f:
                json.dump(self.json_data, f, indent=2, ensure_ascii=False)
            
            # Ê∏ÖÁ©∫flight_dataÔºå‰øùÁïôÂÖ∂‰ªñÊï∞ÊçÆ
            saved_count = len(self.json_data['flight_data'])
            self.json_data['flight_data'] = []
            
            # Âº∫Âà∂ÂûÉÂúæÂõûÊî∂
            gc.collect()
            
            print(f"üíæ Ëá™Âä®‰øùÂ≠ò {saved_count} Êù°Êï∞ÊçÆÂà∞: {temp_filename} (Â∑≤Ê∏ÖÁ©∫ÁºìÂÜ≤Âå∫)")
        except Exception as e:
            print(f"‚ö†Ô∏è Ëá™Âä®‰øùÂ≠òÊï∞ÊçÆÊó∂Âá∫Èîô: {e}")

    def save_json_data(self):
        if not self.enable_json:
            return

        try:
            self._calculate_performance_stats()

            # Á∫¢Ëâ≤Áâ©‰ΩìÁªüËÆ°
            if 'red_objects' in self.json_data:
                red_count = len(self.json_data['red_objects'])
                visited_count = sum(1 for obj in self.json_data['red_objects'] if obj.get('visited', False))
                self.json_data['red_objects_summary'] = {
                    'total_detected': red_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / red_count if red_count > 0 else 0
                }

            # ËìùËâ≤Áâ©‰ΩìÁªüËÆ°
            if 'blue_objects' in self.json_data:
                blue_count = len(self.json_data['blue_objects'])
                visited_count = sum(1 for obj in self.json_data['blue_objects'] if obj.get('visited', False))
                self.json_data['blue_objects_summary'] = {
                    'total_detected': blue_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / blue_count if blue_count > 0 else 0
                }

            # ÈªëËâ≤Áâ©‰ΩìÁªüËÆ°
            if 'black_objects' in self.json_data:
                black_count = len(self.json_data['black_objects'])
                visited_count = sum(1 for obj in self.json_data['black_objects'] if obj.get('visited', False))
                self.json_data['black_objects_summary'] = {
                    'total_detected': black_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / black_count if black_count > 0 else 0
                }

            with open(self.json_filename, 'w', encoding='utf-8') as f:
                json.dump(self.json_data, f, indent=2, ensure_ascii=False)

            print(f"‚úÖ JSONÊï∞ÊçÆÂ∑≤‰øùÂ≠ò: {self.json_filename}")

        except Exception as e:
            print(f"‚ùå ‰øùÂ≠òJSONÊï∞ÊçÆÊó∂Âá∫Èîô: {e}")

    def _calculate_performance_stats(self):
        if not self.performance_metrics['cpu_usage']:
            return

        cpu_avg = np.mean(self.performance_metrics['cpu_usage'])
        cpu_max = np.max(self.performance_metrics['cpu_usage'])
        cpu_min = np.min(self.performance_metrics['cpu_usage'])

        mem_avg = np.mean(self.performance_metrics['memory_usage'])
        mem_max = np.max(self.performance_metrics['memory_usage'])
        mem_min = np.min(self.performance_metrics['memory_usage'])

        if self.performance_metrics['loop_times']:
            loop_avg = np.mean(self.performance_metrics['loop_times'])
            loop_max = np.max(self.performance_metrics['loop_times'])
            loop_min = np.min(self.performance_metrics['loop_times'])
        else:
            loop_avg = loop_max = loop_min = 0

        self.json_data['performance_summary'] = {
            'total_data_points': self.performance_metrics['data_points'],
            'total_time_seconds': time.time() - self.performance_metrics['start_time'],
            'cpu_usage': {
                'average': float(cpu_avg),
                'maximum': float(cpu_max),
                'minimum': float(cpu_min)
            },
            'memory_usage': {
                'average': float(mem_avg),
                'maximum': float(mem_max),
                'minimum': float(mem_min)
            },
            'loop_times': {
                'average_seconds': float(loop_avg),
                'maximum_seconds': float(loop_max),
                'minimum_seconds': float(loop_min)
            }
        }

    def generate_performance_report(self):
        try:
            if not self.performance_metrics['cpu_usage']:
                return "Êó†ÊÄßËÉΩÊï∞ÊçÆÂèØÁî®"

            self._calculate_performance_stats()

            report = "\n" + "="*60 + "\n"
            report += "üìä Á≥ªÁªüÊÄßËÉΩÊä•Âëä\n"
            report += "="*60 + "\n"

            report += f"ÊÄªÊï∞ÊçÆÁÇπÊï∞: {self.performance_metrics['data_points']}\n"
            report += f"ËøêË°åÊó∂Èó¥: {time.time() - self.performance_metrics['start_time']:.1f}Áßí\n"

            if self.performance_metrics['cpu_usage']:
                cpu_avg = np.mean(self.performance_metrics['cpu_usage'])
                cpu_max = np.max(self.performance_metrics['cpu_usage'])
                report += f"CPU‰ΩøÁî®Áéá: Âπ≥Âùá{cpu_avg:.1f}%, ÊúÄÂ§ß{cpu_max:.1f}%\n"

            if self.performance_metrics['memory_usage']:
                mem_avg = np.mean(self.performance_metrics['memory_usage'])
                mem_max = np.max(self.performance_metrics['memory_usage'])
                report += f"ÂÜÖÂ≠ò‰ΩøÁî®Áéá: Âπ≥Âùá{mem_avg:.1f}%, ÊúÄÂ§ß{mem_max:.1f}%\n"

            if self.performance_metrics['loop_times']:
                loop_avg = np.mean(self.performance_metrics['loop_times'])
                loop_max = np.max(self.performance_metrics['loop_times'])
                report += f"Âæ™ÁéØÊó∂Èó¥: Âπ≥Âùá{loop_avg*1000:.1f}ms, ÊúÄÂ§ß{loop_max*1000:.1f}ms\n"

            if 'red_objects' in self.json_data:
                red_count = len(self.json_data['red_objects'])
                visited_count = sum(1 for obj in self.json_data['red_objects'] if obj.get('visited', False))
                report += f"Á∫¢Ëâ≤Áâ©‰ΩìÊ£ÄÊµã: ÊÄªÊï∞{red_count}‰∏™, Â∑≤ËÆøÈóÆ{visited_count}‰∏™\n"

            if 'blue_objects' in self.json_data:
                blue_count = len(self.json_data['blue_objects'])
                visited_count = sum(1 for obj in self.json_data['blue_objects'] if obj.get('visited', False))
                report += f"ËìùËâ≤Áâ©‰ΩìÊ£ÄÊµã: ÊÄªÊï∞{blue_count}‰∏™, Â∑≤ËÆøÈóÆ{visited_count}‰∏™\n"

            if 'black_objects' in self.json_data:
                black_count = len(self.json_data['black_objects'])
                visited_count = sum(1 for obj in self.json_data['black_objects'] if obj.get('visited', False))
                report += f"ÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµã: ÊÄªÊï∞{black_count}‰∏™, Â∑≤ËÆøÈóÆ{visited_count}‰∏™\n"

            report += "="*60 + "\n"

            warnings = []
            if cpu_avg > config.PERFORMANCE['CPU_WARNING_THRESHOLD']:
                warnings.append(f"‚ö†Ô∏è CPU‰ΩøÁî®ÁéáËøáÈ´ò: {cpu_avg:.1f}%")

            if mem_avg > config.PERFORMANCE['MEMORY_WARNING_THRESHOLD']:
                warnings.append(f"‚ö†Ô∏è ÂÜÖÂ≠ò‰ΩøÁî®ÁéáËøáÈ´ò: {mem_avg:.1f}%")

            if loop_avg > config.PERFORMANCE['LOOP_TIME_WARNING_THRESHOLD']:
                warnings.append(f"‚ö†Ô∏è Âæ™ÁéØÊó∂Èó¥ËøáÈïø: {loop_avg*1000:.1f}ms")

            if warnings:
                report += "\n‚ö†Ô∏è ÊÄßËÉΩË≠¶Âëä:\n"
                for warning in warnings:
                    report += f"  {warning}\n"

            return report

        except Exception as e:
            return f"ÁîüÊàêÊÄßËÉΩÊä•ÂëäÊó∂Âá∫Èîô: {e}"


@dataclass
class PerceptionResult:
    """ÊÑüÁü•ÁªìÊûúÊï∞ÊçÆÁªìÊûÑ"""
    has_obstacle: bool = False
    obstacle_distance: float = 100.0
    obstacle_direction: float = 0.0
    terrain_slope: float = 0.0
    open_space_score: float = 0.0
    recommended_height: float = config.PERCEPTION['HEIGHT_STRATEGY']['DEFAULT']
    safe_directions: List[float] = None
    front_image: Optional[np.ndarray] = None
    obstacle_positions: List[Tuple[float, float]] = None
    red_objects: List[RedObject] = None
    red_objects_count: int = 0
    red_objects_image: Optional[np.ndarray] = None
    blue_objects: List[BlueObject] = None
    blue_objects_count: int = 0
    blue_objects_image: Optional[np.ndarray] = None
    black_objects: List[BlackObject] = None
    black_objects_count: int = 0
    black_objects_image: Optional[np.ndarray] = None

    def __post_init__(self):
        if self.safe_directions is None:
            self.safe_directions = []
        if self.obstacle_positions is None:
            self.obstacle_positions = []
        if self.red_objects is None:
            self.red_objects = []
        if self.blue_objects is None:
            self.blue_objects = []
        if self.black_objects is None:
            self.black_objects = []


class VectorFieldPlanner:
    """ÂêëÈáèÂú∫ËßÑÂàíÂô®"""
    def __init__(self):
        self.repulsion_gain = config.INTELLIGENT_DECISION['OBSTACLE_REPULSION_GAIN']
        self.attraction_gain = config.INTELLIGENT_DECISION['GOAL_ATTRACTION_GAIN']
        self.field_radius = config.INTELLIGENT_DECISION['VECTOR_FIELD_RADIUS']
        self.smoothing_factor = config.INTELLIGENT_DECISION['SMOOTHING_FACTOR']
        self.red_attraction_gain = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['ATTRACTION_GAIN']
        self.blue_attraction_gain = config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['ATTRACTION_GAIN']
        self.black_attraction_gain = config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['ATTRACTION_GAIN']

        self.min_turn_angle = math.radians(config.INTELLIGENT_DECISION['MIN_TURN_ANGLE_DEG'])
        self.max_turn_angle = math.radians(config.INTELLIGENT_DECISION['MAX_TURN_ANGLE_DEG'])

        self.vector_history = deque(maxlen=config.INTELLIGENT_DECISION['SMOOTHING_WINDOW_SIZE'])
        self.current_vector = Vector2D()

    def compute_vector(self, current_pos, goal_pos, obstacles, red_objects=None, blue_objects=None, black_objects=None):
        attraction_vector = self._compute_attraction(current_pos, goal_pos)
        repulsion_vector = self._compute_repulsion(current_pos, obstacles)
        red_attraction_vector = Vector2D()
        blue_attraction_vector = Vector2D()
        black_attraction_vector = Vector2D()

        if red_objects:
            red_attraction_vector = self._compute_red_attraction(current_pos, red_objects)

        if blue_objects:
            blue_attraction_vector = self._compute_blue_attraction(current_pos, blue_objects)

        if black_objects:
            black_attraction_vector = self._compute_black_attraction(current_pos, black_objects)

        combined_vector = attraction_vector + repulsion_vector + red_attraction_vector + blue_attraction_vector + black_attraction_vector
        smoothed_vector = self._smooth_vector(combined_vector)
        limited_vector = self._limit_turn_angle(smoothed_vector)

        self.current_vector = limited_vector
        return limited_vector

    def _compute_attraction(self, current_pos, goal_pos):
        if goal_pos is None:
            return Vector2D()

        dx = goal_pos[0] - current_pos[0]
        dy = goal_pos[1] - current_pos[1]
        distance = math.sqrt(dx**2 + dy**2)

        if distance < 0.1:
            return Vector2D()

        strength = min(self.attraction_gain, self.attraction_gain / max(1.0, distance))
        return Vector2D(dx, dy).normalize() * strength

    def _compute_repulsion(self, current_pos, obstacles):
        repulsion = Vector2D()

        for obs_x, obs_y in obstacles:
            dx = current_pos[0] - obs_x
            dy = current_pos[1] - obs_y
            distance = math.sqrt(dx**2 + dy**2)

            if distance < self.field_radius and distance > 0.1:
                strength = self.repulsion_gain * (1.0 / distance**2)
                direction = Vector2D(dx, dy).normalize()
                repulsion += direction * strength

        return repulsion

    def _compute_red_attraction(self, current_pos, red_objects):
        attraction = Vector2D()

        for obj in red_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.red_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _compute_blue_attraction(self, current_pos, blue_objects):
        attraction = Vector2D()

        for obj in blue_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.blue_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _compute_black_attraction(self, current_pos, black_objects):
        attraction = Vector2D()

        for obj in black_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.black_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _smooth_vector(self, new_vector):
        self.vector_history.append(new_vector)

        if len(self.vector_history) < 2:
            return new_vector

        smoothed = Vector2D()
        total_weight = 0.0

        for i, vec in enumerate(reversed(self.vector_history)):
            weight = math.exp(-i * self.smoothing_factor)
            smoothed += vec * weight
            total_weight += weight

        if total_weight > 0:
            smoothed = smoothed / total_weight

        return smoothed

    def _limit_turn_angle(self, vector):
        if self.current_vector.magnitude() < 0.1:
            return vector

        current_angle = math.atan2(self.current_vector.y, self.current_vector.x)
        new_angle = math.atan2(vector.y, vector.x)

        angle_diff = new_angle - current_angle
        angle_diff = (angle_diff + math.pi) % (2 * math.pi) - math.pi

        if abs(angle_diff) > self.max_turn_angle:
            angle_diff = math.copysign(self.max_turn_angle, angle_diff)
        elif abs(angle_diff) < self.min_turn_angle and vector.magnitude() > 0.1:
            angle_diff = math.copysign(self.min_turn_angle, angle_diff)

        magnitude = vector.magnitude()
        limited_angle = current_angle + angle_diff

        return Vector2D.from_angle(limited_angle, magnitude)


class FrontViewWindow:
    """ÂâçËßÜÁ™óÂè£ - ÊòæÁ§∫ÊëÑÂÉèÂ§¥ÁîªÈù¢ÂíåÊâãÂä®ÊéßÂà∂"""

    def __init__(self, window_name=None, width=None, height=None,
                 enable_sharpening=None, show_info=None):
        self.window_name = window_name if window_name else config.DISPLAY['FRONT_VIEW_WINDOW']['NAME']
        self.window_width = width if width is not None else config.DISPLAY['FRONT_VIEW_WINDOW']['WIDTH']
        self.window_height = height if height is not None else config.DISPLAY['FRONT_VIEW_WINDOW']['HEIGHT']
        self.enable_sharpening = (enable_sharpening if enable_sharpening is not None
                                 else config.DISPLAY['FRONT_VIEW_WINDOW']['ENABLE_SHARPENING'])
        self.show_info = (show_info if show_info is not None
                         else config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_INFO_OVERLAY'])

        # ÂÜÖÂ≠ò‰ºòÂåñÔºö‰ΩøÁî®ÈÖçÁΩÆÁöÑÈòüÂàóÂ§ßÂ∞è
        queue_maxsize = config.DISPLAY['FRONT_VIEW_WINDOW'].get('QUEUE_MAXSIZE', 2)
        self.image_queue = queue.Queue(maxsize=queue_maxsize)
        self.reduce_image_copy = config.DISPLAY['FRONT_VIEW_WINDOW'].get('REDUCE_IMAGE_COPY', True)
        self.display_active = True
        self.display_thread = None
        self.paused = False

        self.manual_mode = False
        self.key_states = {}
        self.last_keys = {}

        self.exit_manual_flag = False
        self.exit_display_flag = False

        self.display_stats = {
            'fps': 0.0,
            'last_update': time.time(),
            'frame_count': 0
        }

        self.start()

    def start(self):
        if self.display_thread and self.display_thread.is_alive():
            return

        self.display_active = True
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="FrontViewWindow"
        )
        self.display_thread.start()

    def stop(self):
        self.display_active = False
        self.exit_display_flag = True
        if self.display_thread:
            self.display_thread.join(timeout=2.0)

    def update_image(self, image_data: np.ndarray, info: Optional[Dict] = None,
                     manual_info: Optional[List[str]] = None):
        if not self.display_active or self.paused or image_data is None:
            return

        try:
            if self.enable_sharpening and image_data is not None and image_data.size > 0:
                kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
                image_data = cv2.filter2D(image_data, -1, kernel)

            if self.image_queue.full():
                try:
                    self.image_queue.get_nowait()
                except queue.Empty:
                    pass

            # ÂÜÖÂ≠ò‰ºòÂåñÔºö‰ªÖÂú®ÂøÖË¶ÅÊó∂Â§çÂà∂ÂõæÂÉè
            if self.reduce_image_copy and image_data is not None:
                # Â¶ÇÊûúÈòüÂàó‰∏∫Á©∫ÊàñÂè™Êúâ‰∏Ä‰∏™ÂÖÉÁ¥†ÔºåÁõ¥Êé•‰ΩøÁî®ÂºïÁî®ÔºàÈÅøÂÖçÂ§çÂà∂Ôºâ
                if self.image_queue.qsize() == 0:
                    display_image = image_data
                else:
                    display_image = image_data.copy()
            else:
                display_image = image_data.copy() if image_data is not None else None
            
            display_packet = {
                'image': display_image,
                'info': info.copy() if info else {},
                'manual_info': manual_info.copy() if manual_info else [],
                'timestamp': time.time()
            }

            self.image_queue.put_nowait(display_packet)

        except Exception as e:
            print(f"‚ö†Ô∏è Êõ¥Êñ∞ÂõæÂÉèÊó∂Âá∫Èîô: {e}")

    def set_manual_mode(self, manual_mode):
        self.manual_mode = manual_mode
        self.exit_manual_flag = False
        self.key_states = {}
        self.last_keys = {}
        print(f"üîÑ {'ËøõÂÖ•' if manual_mode else 'ÈÄÄÂá∫'}ÊâãÂä®ÊéßÂà∂Ê®°Âºè")

    def get_control_inputs(self):
        return self.key_states.copy()

    def should_exit_manual(self):
        return self.exit_manual_flag

    def _display_loop(self):
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        wait_img = np.zeros((300, 400, 3), dtype=np.uint8)
        cv2.putText(wait_img, "Á≠âÂæÖÊó†‰∫∫Êú∫ÂõæÂÉè...", (50, 150),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        cv2.imshow(self.window_name, wait_img)
        cv2.waitKey(100)

        print("üí° ÂâçËßÜÁ™óÂè£ÊéßÂà∂:")
        print("   - ÈÄöÁî®ÊéßÂà∂: P=ÊöÇÂÅú/ÁªßÁª≠, I=‰ø°ÊÅØÊòæÁ§∫, H=ÈîêÂåñÊïàÊûú")
        print("   - ÈùûÊâãÂä®Ê®°Âºè: Q=ÂÖ≥Èó≠Á™óÂè£, S=‰øùÂ≠òÊà™Âõæ")
        print("   - ÊâãÂä®Ê®°Âºè: ESC=ÈÄÄÂá∫ÊâãÂä®Ê®°Âºè")
        print("\nüéÆ ÊâãÂä®ÊéßÂà∂ÈîÆ‰Ωç:")
        print("   - W/S: ÂâçËøõ/ÂêéÈÄÄ, A/D: Â∑¶Áßª/Âè≥Áßª")
        print("   - Q/E: ‰∏äÂçá/‰∏ãÈôç, Z/X: Â∑¶ËΩ¨/Âè≥ËΩ¨")
        print("   - Á©∫Ê†º: ÊÇ¨ÂÅú, ESC: ÈÄÄÂá∫ÊâãÂä®Ê®°Âºè")

        while self.display_active and not self.exit_display_flag:
            display_image = None
            info = {}
            manual_info = []

            try:
                if not self.image_queue.empty():
                    packet = self.image_queue.get_nowait()
                    display_image = packet['image']
                    info = packet['info']
                    manual_info = packet['manual_info']

                    self._update_stats()

                    while not self.image_queue.empty():
                        try:
                            self.image_queue.get_nowait()
                        except queue.Empty:
                            break
            except queue.Empty:
                pass

            if display_image is not None:
                if self.show_info:
                    display_image = self._add_info_overlay(display_image, info, manual_info)

                cv2.imshow(self.window_name, display_image)
            elif self.paused:
                blank = np.zeros((300, 400, 3), dtype=np.uint8)
                cv2.putText(blank, "PAUSED", (120, 150),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
                cv2.imshow(self.window_name, blank)

            key = cv2.waitKey(config.DISPLAY['FRONT_VIEW_WINDOW'].get('REFRESH_RATE_MS', 30)) & 0xFF

            current_keys = {}
            if key != 255:
                current_keys[key] = True

                if self.manual_mode:
                    self._handle_manual_mode_key(key)
                else:
                    self._handle_window_control_key(key, display_image)

            self._update_key_states(current_keys)

            try:
                if cv2.getWindowProperty(self.window_name, cv2.WND_PROP_VISIBLE) < 1:
                    print("üîÑ Áî®Êà∑ÂÖ≥Èó≠‰∫ÜÂâçËßÜÁ™óÂè£")
                    self.display_active = False
                    break
            except:
                self.display_active = False
                break

        try:
            cv2.destroyWindow(self.window_name)
        except:
            pass
        cv2.waitKey(1)

    def _handle_manual_mode_key(self, key):
        if key == 27:
            print("Êî∂Âà∞ÈÄÄÂá∫ÊâãÂä®Ê®°ÂºèÊåá‰ª§")
            self.exit_manual_flag = True
            return

        self.key_states[key] = True

        if key == 32:
            print("‚è∏Ô∏è ÊÇ¨ÂÅúÊåá‰ª§")

    def _handle_window_control_key(self, key, display_image):
        key_char = chr(key).lower() if 0 <= key <= 255 else ''

        if key_char == 'q':
            print("üîÑ Áî®Êà∑ÂÖ≥Èó≠ÊòæÁ§∫Á™óÂè£")
            self.display_active = False
        elif key_char == 's' and display_image is not None:
            self._save_screenshot(display_image)
        elif key_char == 'p':
            self.paused = not self.paused
            status = "Â∑≤ÊöÇÂÅú" if self.paused else "Â∑≤ÊÅ¢Â§ç"
            print(f"‚è∏Ô∏è ËßÜÈ¢ëÊµÅ{status}")
        elif key_char == 'i':
            self.show_info = not self.show_info
            status = "ÂºÄÂêØ" if self.show_info else "ÂÖ≥Èó≠"
            print(f"üìä ‰ø°ÊÅØÂè†Âä†Â±Ç{status}")
        elif key_char == 'h':
            self.enable_sharpening = not self.enable_sharpening
            status = "ÂºÄÂêØ" if self.enable_sharpening else "ÂÖ≥Èó≠"
            print(f"üîç ÂõæÂÉèÈîêÂåñ{status}")

    def _update_key_states(self, current_keys):
        released_keys = []
        for key in list(self.key_states.keys()):
            if key not in current_keys:
                released_keys.append(key)

        for key in released_keys:
            del self.key_states[key]

        self.last_keys = current_keys.copy()

    def _update_stats(self):
        now = time.time()
        self.display_stats['frame_count'] += 1

        if now - self.display_stats['last_update'] >= 1.0:
            self.display_stats['fps'] = self.display_stats['frame_count'] / (now - self.display_stats['last_update'])
            self.display_stats['frame_count'] = 0
            self.display_stats['last_update'] = now

    def _add_info_overlay(self, image: np.ndarray, info: Dict, manual_info: List[str] = None) -> np.ndarray:
        if image is None or image.size == 0:
            return image

        try:
            overlay = image.copy()
            height, width = image.shape[:2]

            is_manual = info.get('state', '') == "ÊâãÂä®ÊéßÂà∂"

            info_height = 180 if is_manual and manual_info else 100

            cv2.rectangle(overlay, (0, 0), (width, info_height), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)

            state = info.get('state', 'UNKNOWN')
            state_color = (0, 255, 0) if 'Êé¢Á¥¢' in state else (0, 255, 255) if 'ÊÇ¨ÂÅú' in state else (255, 255, 0) if 'ÊâãÂä®' in state else (0, 0, 255)
            cv2.putText(image, f"Áä∂ÊÄÅ: {state}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, state_color, 2)

            pos = info.get('position', (0, 0, 0))
            cv2.putText(image, f"‰ΩçÁΩÆ: ({pos[0]:.1f}, {pos[1]:.1f}, {-pos[2]:.1f}m)", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

            red_objects_count = info.get('red_objects_count', 0)
            red_objects_visited = info.get('red_objects_visited', 0)
            blue_objects_count = info.get('blue_objects_count', 0)
            blue_objects_visited = info.get('blue_objects_visited', 0)
            black_objects_count = info.get('black_objects_count', 0)
            black_objects_visited = info.get('black_objects_visited', 0)

            if red_objects_count > 0 or blue_objects_count > 0 or black_objects_count > 0:
                red_text = f"Á∫¢Ëâ≤Áâ©‰Ωì: {red_objects_visited}/{red_objects_count}"
                blue_text = f"ËìùËâ≤Áâ©‰Ωì: {blue_objects_visited}/{blue_objects_count}"
                black_text = f"ÈªëËâ≤Áâ©‰Ωì: {black_objects_visited}/{black_objects_count}"
                cv2.putText(image, red_text, (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 100, 255), 2)
                cv2.putText(image, blue_text, (10, 110),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 100, 0), 2)
                cv2.putText(image, black_text, (10, 130),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)

            if is_manual and manual_info:
                y_start = 170 if (red_objects_count > 0 or blue_objects_count > 0 or black_objects_count > 0) else 100
                for i, line in enumerate(manual_info):
                    y_pos = y_start + i * 20
                    cv2.putText(image, line, (10, y_pos),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 255, 200), 1)

                cv2.putText(image, "ÊâãÂä®ÊéßÂà∂‰∏≠...", (width - 150, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)
            elif not is_manual and red_objects_count == 0 and blue_objects_count == 0 and black_objects_count == 0:
                obs_dist = info.get('obstacle_distance', 0.0)
                obs_color = (0, 0, 255) if obs_dist < 5.0 else (0, 165, 255) if obs_dist < 10.0 else (0, 255, 0)
                cv2.putText(image, f"ÈöúÁ¢ç: {obs_dist:.1f}m", (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, obs_color, 2)

            fps_text = f"FPS: {self.display_stats['fps']:.1f}"
            cv2.putText(image, fps_text, (width - 120, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)

            return image
        except Exception as e:
            print(f"‚ö†Ô∏è Ê∑ªÂä†‰ø°ÊÅØÂè†Âä†Â±ÇÂá∫Èîô: {e}")
            return image

    def _save_screenshot(self, image: Optional[np.ndarray]):
        if image is not None and image.size > 0:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"drone_snapshot_{timestamp}.png"
            cv2.imwrite(filename, image)
            print(f"üì∏ Êà™ÂõæÂ∑≤‰øùÂ≠ò: {filename}")
        else:
            print("‚ö†Ô∏è Êó†Ê≥ï‰øùÂ≠òÊà™ÂõæÔºöÊó†ÊúâÊïàÂõæÂÉèÊï∞ÊçÆ")


class InfoDisplayWindow:
    """‰ø°ÊÅØÊòæÁ§∫Á™óÂè£ - ÊòæÁ§∫Á≥ªÁªüÁä∂ÊÄÅ„ÄÅÊé¢Á¥¢ÁΩëÊ†º„ÄÅÁâ©‰ΩìÁªüËÆ°Á≠â‰ø°ÊÅØ"""

    def __init__(self, window_name=None, width=None, height=None):
        self.window_name = window_name if window_name else config.DISPLAY['INFO_WINDOW']['NAME']
        self.window_width = width if width is not None else config.DISPLAY['INFO_WINDOW']['WIDTH']
        self.window_height = height if height is not None else config.DISPLAY['INFO_WINDOW']['HEIGHT']

        self.display_config = config.DISPLAY['INFO_WINDOW']
        self.info_queue = queue.Queue(maxsize=3)
        self.display_active = True
        self.display_thread = None
        self.last_update = time.time()

        self.start()

    def start(self):
        if self.display_thread and self.display_thread.is_alive():
            return

        self.display_active = True
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="InfoDisplayWindow"
        )
        self.display_thread.start()
        print(f"üìä ‰ø°ÊÅØÊòæÁ§∫Á™óÂè£Â∑≤ÂêØÂä®: {self.window_name}")

    def stop(self):
        self.display_active = False
        if self.display_thread:
            self.display_thread.join(timeout=2.0)

    def update_info(self, info_data: Dict):
        if not self.display_active:
            return

        try:
            if self.info_queue.full():
                try:
                    self.info_queue.get_nowait()
                except queue.Empty:
                    pass

            self.info_queue.put_nowait(info_data.copy())

        except Exception as e:
            print(f"‚ö†Ô∏è Êõ¥Êñ∞‰ø°ÊÅØÊï∞ÊçÆÊó∂Âá∫Èîô: {e}")

    def _display_loop(self):
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        wait_img = self._create_waiting_screen()
        cv2.imshow(self.window_name, wait_img)
        cv2.waitKey(100)

        print("üìä ‰ø°ÊÅØÊòæÁ§∫Á™óÂè£Â∑≤Â∞±Áª™")
        print("  ÊòæÁ§∫ÂÜÖÂÆπ: Êé¢Á¥¢ÁΩëÊ†º„ÄÅÁ≥ªÁªüÁä∂ÊÄÅ„ÄÅÁâ©‰ΩìÁªüËÆ°„ÄÅÊÄßËÉΩ‰ø°ÊÅØ")

        last_render_time = time.time()
        info_data = {}

        while self.display_active:
            current_time = time.time()

            # ‰ªéÈòüÂàóËé∑ÂèñÊúÄÊñ∞‰ø°ÊÅØ
            try:
                while not self.info_queue.empty():
                    info_data = self.info_queue.get_nowait()
            except queue.Empty:
                pass

            # ÂÆöÊúüÂà∑Êñ∞ÊòæÁ§∫
            if current_time - last_render_time >= self.display_config['REFRESH_RATE_MS'] / 1000.0:
                display_image = self._render_info_display(info_data)
                if display_image is not None:
                    cv2.imshow(self.window_name, display_image)
                last_render_time = current_time

            # Â§ÑÁêÜÁ™óÂè£‰∫ã‰ª∂
            key = cv2.waitKey(10) & 0xFF
            if key == ord('q') or key == 27:  # QÊàñESCÂÖ≥Èó≠Á™óÂè£
                print("üîÑ Áî®Êà∑ÂÖ≥Èó≠‰ø°ÊÅØÁ™óÂè£")
                self.display_active = False
                break

            try:
                if cv2.getWindowProperty(self.window_name, cv2.WND_PROP_VISIBLE) < 1:
                    print("üîÑ ‰ø°ÊÅØÁ™óÂè£Ë¢´ÂÖ≥Èó≠")
                    self.display_active = False
                    break
            except:
                self.display_active = False
                break

        try:
            cv2.destroyWindow(self.window_name)
        except:
            pass
        cv2.waitKey(1)

    def _create_waiting_screen(self):
        """ÂàõÂª∫Á≠âÂæÖÂ±èÂπï"""
        img = np.zeros((self.window_height, self.window_width, 3), dtype=np.uint8)
        bg_color = self.display_config['BACKGROUND_COLOR']
        img[:, :] = bg_color

        center_x = self.window_width // 2
        center_y = self.window_height // 2

        # Ê†áÈ¢ò
        title = "Êó†‰∫∫Êú∫‰ø°ÊÅØÈù¢Êùø"
        cv2.putText(img, title, (center_x - 150, center_y - 100),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, self.display_config['HIGHLIGHT_COLOR'], 2)

        # Áä∂ÊÄÅ‰ø°ÊÅØ
        status = "Á≠âÂæÖÊï∞ÊçÆ..."
        cv2.putText(img, status, (center_x - 80, center_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, self.display_config['TEXT_COLOR'], 1)

        # ÊèêÁ§∫
        tip = "Á≥ªÁªüÊ≠£Âú®ÂàùÂßãÂåñÔºåËØ∑Á®çÂÄô..."
        cv2.putText(img, tip, (center_x - 120, center_y + 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.display_config['TEXT_COLOR'], 1)

        return img

    def _render_info_display(self, info_data: Dict) -> np.ndarray:
        """Ê∏≤Êüì‰ø°ÊÅØÊòæÁ§∫"""
        try:
            # ÂàõÂª∫ËÉåÊôØ
            img = np.zeros((self.window_height, self.window_width, 3), dtype=np.uint8)
            bg_color = self.display_config['BACKGROUND_COLOR']
            img[:, :] = bg_color

            text_color = self.display_config['TEXT_COLOR']
            highlight_color = self.display_config['HIGHLIGHT_COLOR']
            warning_color = self.display_config['WARNING_COLOR']
            success_color = self.display_config['SUCCESS_COLOR']

            y_offset = 40
            x_offset = 20

            # Ê†áÈ¢òÊ†è
            title = "Êó†‰∫∫Êú∫‰ø°ÊÅØÈù¢Êùø"
            cv2.putText(img, title, (self.window_width // 2 - 100, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, highlight_color, 2)

            # ÂàÜÈöîÁ∫ø
            cv2.line(img, (10, 50), (self.window_width - 10, 50), text_color, 1)

            y_offset = 80

            # 1. È£ûË°åÁä∂ÊÄÅ‰ø°ÊÅØ
            if 'state' in info_data:
                state = info_data['state']
                state_color = success_color if 'Êé¢Á¥¢' in state else highlight_color if 'ÊÇ¨ÂÅú' in state else warning_color if 'Á¥ßÊÄ•' in state else text_color
                cv2.putText(img, f"È£ûË°åÁä∂ÊÄÅ: {state}", (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, state_color, 2)
                y_offset += 30

            # 2. ‰ΩçÁΩÆ‰ø°ÊÅØ
            if 'position' in info_data:
                pos = info_data['position']
                pos_text = f"‰ΩçÁΩÆ: X:{pos[0]:.1f}m Y:{pos[1]:.1f}m È´òÂ∫¶:{-pos[2]:.1f}m"
                cv2.putText(img, pos_text, (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)
                y_offset += 25

            # 3. ÁéØÂ¢ÉÊÑüÁü•‰ø°ÊÅØ
            if 'perception' in info_data:
                perception = info_data['perception']
                obs_text = f"ÈöúÁ¢çË∑ùÁ¶ª: {perception.get('obstacle_distance', 0):.1f}m"
                obs_color = warning_color if perception.get('obstacle_distance', 0) < 5.0 else text_color
                cv2.putText(img, obs_text, (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, obs_color, 1)
                y_offset += 25

                open_text = f"ÂºÄÈòîÂ∫¶: {perception.get('open_space_score', 0):.2f}"
                cv2.putText(img, open_text, (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)
                y_offset += 25

            # 4. Áâ©‰ΩìÊ£ÄÊµãÁªüËÆ°
            if 'objects_stats' in info_data:
                objects_stats = info_data['objects_stats']

                # Á∫¢Ëâ≤Áâ©‰ΩìÁªüËÆ°
                red_total = objects_stats.get('red_total', 0)
                red_visited = objects_stats.get('red_visited', 0)
                red_text = f"Á∫¢Ëâ≤Áâ©‰Ωì: {red_visited}/{red_total}"
                red_color = success_color if red_visited > 0 else text_color
                cv2.putText(img, red_text, (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, red_color, 1)
                y_offset += 30

                # ËìùËâ≤Áâ©‰ΩìÁªüËÆ°
                blue_total = objects_stats.get('blue_total', 0)
                blue_visited = objects_stats.get('blue_visited', 0)
                blue_text = f"ËìùËâ≤Áâ©‰Ωì: {blue_visited}/{blue_total}"
                blue_color = success_color if blue_visited > 0 else text_color
                cv2.putText(img, blue_text, (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, blue_color, 1)
                y_offset += 30

            # 5. Êé¢Á¥¢ÁΩëÊ†º‰ø°ÊÅØ
            if 'grid_stats' in info_data:
                grid_stats = info_data['grid_stats']
                frontiers = grid_stats.get('frontiers', 0)
                explored = grid_stats.get('explored', 0)
                total = grid_stats.get('total', 1)

                grid_text = f"Êé¢Á¥¢ÁΩëÊ†º: {frontiers}ÂâçÊ≤ø | {explored}/{total}Â∑≤Êé¢Á¥¢"
                cv2.putText(img, grid_text, (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)
                y_offset += 25

                # Êé¢Á¥¢ËøõÂ∫¶Êù°
                progress = explored / total if total > 0 else 0
                bar_width = 200
                bar_height = 15
                bar_x = x_offset
                bar_y = y_offset

                # ËÉåÊôØÊù°
                cv2.rectangle(img, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (50, 50, 50), -1)
                # ËøõÂ∫¶Êù°
                progress_width = int(bar_width * progress)
                progress_color = (0, int(255 * progress), int(255 * (1 - progress)))
                cv2.rectangle(img, (bar_x, bar_y), (bar_x + progress_width, bar_y + bar_height), progress_color, -1)
                # ËæπÊ°Ü
                cv2.rectangle(img, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), text_color, 1)
                # ËøõÂ∫¶ÊñáÊú¨
                progress_text = f"{progress*100:.1f}%"
                cv2.putText(img, progress_text, (bar_x + bar_width + 10, bar_y + 12),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)
                y_offset += 35

            # 6. Á≥ªÁªüÊÄßËÉΩ‰ø°ÊÅØ
            if 'performance' in info_data:
                performance = info_data['performance']
                cpu_usage = performance.get('cpu_usage', 0)
                memory_usage = performance.get('memory_usage', 0)
                loop_time = performance.get('loop_time', 0) * 1000  # ËΩ¨Êç¢‰∏∫ÊØ´Áßí

                cpu_color = warning_color if cpu_usage > 80 else text_color
                mem_color = warning_color if memory_usage > 80 else text_color
                loop_color = warning_color if loop_time > 200 else text_color

                cv2.putText(img, f"CPU‰ΩøÁî®Áéá: {cpu_usage:.1f}%", (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, cpu_color, 1)
                y_offset += 25

                cv2.putText(img, f"ÂÜÖÂ≠ò‰ΩøÁî®Áéá: {memory_usage:.1f}%", (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, mem_color, 1)
                y_offset += 25

                cv2.putText(img, f"Âæ™ÁéØÊó∂Èó¥: {loop_time:.1f}ms", (x_offset, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, loop_color, 1)
                y_offset += 25

            # 7. Êé¢Á¥¢ÁΩëÊ†ºÂõæÂÉèÔºàÂè≥‰æßÔºâ
            if self.display_config['SHOW_GRID'] and 'grid_image' in info_data:
                grid_img = info_data['grid_image']
                if grid_img is not None and grid_img.size > 0:
                    grid_size = self.display_config['GRID_SIZE']
                    grid_resized = cv2.resize(grid_img, (grid_size, grid_size))

                    grid_x = self.window_width - grid_size - 20
                    grid_y = 80

                    # Ê∑ªÂä†ÁΩëÊ†ºÊ†áÈ¢ò
                    cv2.putText(img, "Êé¢Á¥¢ÁΩëÊ†º", (grid_x, grid_y - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, highlight_color, 1)

                    # Ê∑ªÂä†Âõæ‰æã
                    legend_y = grid_y + grid_size + 20
                    cv2.putText(img, "Âõæ‰æã:", (grid_x, legend_y),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)
                    legend_y += 20

                    # ÂΩìÂâç‰ΩçÁΩÆ
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 255, 0), -1)
                    cv2.putText(img, "ÂΩìÂâç‰ΩçÁΩÆ", (grid_x + 20, legend_y + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
                    legend_y += 25

                    # ÈöúÁ¢çÁâ©
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 0, 255), -1)
                    cv2.putText(img, "ÈöúÁ¢çÁâ©", (grid_x + 20, legend_y + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
                    legend_y += 25

                    # Á∫¢Ëâ≤Áâ©‰Ωì
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 100, 255), -1)
                    cv2.putText(img, "Á∫¢Ëâ≤Áâ©‰Ωì", (grid_x + 20, legend_y + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
                    legend_y += 25

                    # ËìùËâ≤Áâ©‰Ωì
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (255, 100, 0), -1)
                    cv2.putText(img, "ËìùËâ≤Áâ©‰Ωì", (grid_x + 20, legend_y + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
                    legend_y += 25

                    # ÈªëËâ≤Áâ©‰Ωì
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (128, 128, 128), -1)
                    cv2.putText(img, "ÈªëËâ≤Áâ©‰Ωì", (grid_x + 20, legend_y + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
                    legend_y += 25

                    # ÂâçÊ≤øÂå∫Âüü
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 200, 0), -1)
                    cv2.putText(img, "Êé¢Á¥¢ÂâçÊ≤ø", (grid_x + 20, legend_y + 12),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)

                    # Â∞ÜÁΩëÊ†ºÂõæÂÉèÊîæÂà∞‰∏ªÂõæÂÉè‰∏ä
                    img[grid_y:grid_y+grid_size, grid_x:grid_x+grid_size] = grid_resized

            # 8. Êó∂Èó¥Êà≥
            if 'timestamp' in info_data:
                timestamp = info_data['timestamp']
                time_text = f"Êõ¥Êñ∞Êó∂Èó¥: {timestamp}"
                cv2.putText(img, time_text, (self.window_width - 200, self.window_height - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)

            # 9. Â∫ïÈÉ®ÊèêÁ§∫
            hint_text = "Êåâ Q Êàñ ESC ÂÖ≥Èó≠Á™óÂè£"
            cv2.putText(img, hint_text, (self.window_width // 2 - 80, self.window_height - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)

            return img

        except Exception as e:
            print(f"‚ö†Ô∏è Ê∏≤Êüì‰ø°ÊÅØÊòæÁ§∫Êó∂Âá∫Èîô: {e}")
            error_img = np.zeros((self.window_height, self.window_width, 3), dtype=np.uint8)
            error_img[:, :] = self.display_config['BACKGROUND_COLOR']
            cv2.putText(error_img, "Ê∏≤ÊüìÈîôËØØ", (self.window_width // 2 - 50, self.window_height // 2),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, warning_color, 2)
            return error_img


class PerceptiveExplorer:
    """Âü∫‰∫éÊÑüÁü•ÁöÑËá™‰∏ªÊé¢Á¥¢Êó†‰∫∫Êú∫ - Êô∫ËÉΩÂÜ≥Á≠ñÂ¢ûÂº∫ÁâàÔºàÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµãÁâàÔºâ"""

    def __init__(self, drone_name=""):
        self._setup_logging()
        self.logger.info("=" * 60)
        self.logger.info("AirSimNH ÊÑüÁü•È©±Âä®Ëá™‰∏ªÊé¢Á¥¢Á≥ªÁªü - ÂèåÁ™óÂè£ÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµãÁâà")
        self.logger.info("=" * 60)

        self.client = None
        self.drone_name = drone_name
        self._connect_to_airsim()

        try:
            self.client.enableApiControl(True, vehicle_name=drone_name)
            self.client.armDisarm(True, vehicle_name=drone_name)
            self.logger.info("‚úÖ APIÊéßÂà∂Â∑≤ÂêØÁî®")
        except Exception as e:
            self.logger.error(f"‚ùå ÂêØÁî®APIÊéßÂà∂Â§±Ë¥•: {e}")
            raise

        self.state = FlightState.TAKEOFF
        self.state_history = deque(maxlen=20)
        self.emergency_flag = False

        self.depth_threshold_near = config.PERCEPTION['DEPTH_NEAR_THRESHOLD']
        self.depth_threshold_safe = config.PERCEPTION['DEPTH_SAFE_THRESHOLD']
        self.min_ground_clearance = config.PERCEPTION['MIN_GROUND_CLEARANCE']
        self.max_pitch_angle = math.radians(config.PERCEPTION['MAX_PITCH_ANGLE_DEG'])
        self.scan_angles = config.PERCEPTION['SCAN_ANGLES']

        self.exploration_time = config.EXPLORATION['TOTAL_TIME']
        self.preferred_speed = config.EXPLORATION['PREFERRED_SPEED']
        self.max_altitude = config.EXPLORATION['MAX_ALTITUDE']
        self.min_altitude = config.EXPLORATION['MIN_ALTITUDE']
        self.base_height = config.EXPLORATION['BASE_HEIGHT']
        self.takeoff_height = config.EXPLORATION['TAKEOFF_HEIGHT']

        self.vector_planner = VectorFieldPlanner()
        self.exploration_grid = ExplorationGrid(
            resolution=config.INTELLIGENT_DECISION['GRID_RESOLUTION'],
            grid_size=config.INTELLIGENT_DECISION['GRID_SIZE']
        )

        self.velocity_pid = PIDController(
            config.INTELLIGENT_DECISION['PID_KP'],
            config.INTELLIGENT_DECISION['PID_KI'],
            config.INTELLIGENT_DECISION['PID_KD']
        )
        self.height_pid = PIDController(1.0, 0.1, 0.3)

        self.exploration_target = None
        self.target_update_time = 0
        self.target_lifetime = config.INTELLIGENT_DECISION.get('TARGET_LIFETIME', 15.0)
        self.target_reached_distance = config.INTELLIGENT_DECISION.get('TARGET_REACHED_DISTANCE', 3.0)

        self.red_objects = []
        self.red_object_id_counter = 0
        self.last_red_detection_time = 0
        self.red_detection_interval = config.PERCEPTION['RED_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.red_object_memory_time = config.PERCEPTION['RED_OBJECT_DETECTION']['MEMORY_TIME']

        self.blue_objects = []
        self.blue_object_id_counter = 0
        self.last_blue_detection_time = 0
        self.blue_detection_interval = config.PERCEPTION['BLUE_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.blue_object_memory_time = config.PERCEPTION['BLUE_OBJECT_DETECTION']['MEMORY_TIME']

        self.black_objects = []
        self.black_object_id_counter = 0
        self.last_black_detection_time = 0
        self.black_detection_interval = config.PERCEPTION['BLACK_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.black_object_memory_time = config.PERCEPTION['BLACK_OBJECT_DETECTION']['MEMORY_TIME']

        self.visited_positions = deque(maxlen=100)

        self.loop_count = 0
        self.start_time = time.time()
        self.last_health_check = 0
        self.reconnect_attempts = 0
        self.last_successful_loop = time.time()

        self.data_logger = None
        self.last_data_record_time = 0
        self.data_record_interval = config.DATA_RECORDING.get('RECORD_INTERVAL', 0.2)
        if config.DATA_RECORDING['ENABLED']:
            self._setup_data_logger()

        self.last_performance_report = time.time()
        self.performance_report_interval = config.PERFORMANCE.get('REPORT_INTERVAL', 30.0)

        self.stats = {
            'perception_cycles': 0,
            'decision_cycles': 0,
            'exceptions_caught': 0,
            'obstacles_detected': 0,
            'state_changes': 0,
            'front_image_updates': 0,
            'manual_control_time': 0.0,
            'vector_field_updates': 0,
            'grid_updates': 0,
            'data_points_recorded': 0,
            'average_loop_time': 0.0,
            'max_loop_time': 0.0,
            'min_loop_time': 100.0,
            'red_objects_detected': 0,
            'red_objects_visited': 0,
            'blue_objects_detected': 0,
            'blue_objects_visited': 0,
            'black_objects_detected': 0,
            'black_objects_visited': 0,
        }

        # ÂàùÂßãÂåñ‰∏§‰∏™Á™óÂè£
        self.front_window = None
        self.info_window = None
        self._setup_windows()

        self.manual_control_start = 0
        self.control_keys = {}

        self.logger.info("‚úÖ Á≥ªÁªüÂàùÂßãÂåñÂÆåÊàê")
        self.logger.info(f"   ÂºÄÂßãÊó∂Èó¥: {datetime.now().strftime('%H:%M:%S')}")
        self.logger.info(f"   È¢ÑËÆ°Êé¢Á¥¢Êó∂Èïø: {self.exploration_time}Áßí")
        self.logger.info(f"   Êô∫ËÉΩÂÜ≥Á≠ñ: ÂêëÈáèÂú∫ÈÅøÈöú + ÁΩëÊ†ºÊé¢Á¥¢ + ‰∏âËâ≤Áâ©‰ΩìÊ£ÄÊµã")
        self.logger.info(f"   ÊòæÁ§∫Á≥ªÁªü: ÂèåÁ™óÂè£Ê®°Âºè (ÂâçËßÜÁ™óÂè£ + ‰ø°ÊÅØÁ™óÂè£)")
        if config.DATA_RECORDING['ENABLED']:
            self.logger.info(f"   Êï∞ÊçÆËÆ∞ÂΩï: CSV + JSON Ê†ºÂºè")
        if config.PERCEPTION['RED_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   Á∫¢Ëâ≤Áâ©‰ΩìÊ£ÄÊµã: Â∑≤ÂêØÁî®")
        if config.PERCEPTION['BLUE_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   ËìùËâ≤Áâ©‰ΩìÊ£ÄÊµã: Â∑≤ÂêØÁî®")
        if config.PERCEPTION['BLACK_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   ÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµã: Â∑≤ÂêØÁî®")

    def _setup_logging(self):
        self.logger = logging.getLogger('DroneExplorer')
        self.logger.setLevel(getattr(logging, config.SYSTEM['LOG_LEVEL']))

        if self.logger.hasHandlers():
            self.logger.handlers.clear()

        console_handler = logging.StreamHandler(sys.stdout)
        console_format = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s', datefmt='%H:%M:%S')
        console_handler.setFormatter(console_format)
        self.logger.addHandler(console_handler)

        if config.SYSTEM['LOG_TO_FILE']:
            try:
                file_handler = logging.FileHandler(config.SYSTEM['LOG_FILENAME'], encoding='utf-8')
                file_format = logging.Formatter('%(asctime)s | %(name)s | %(levelname)-8s | %(message)s')
                file_handler.setFormatter(file_format)
                self.logger.addHandler(file_handler)
                self.logger.info(f"üìù Êó•ÂøóÂ∞Ü‰øùÂ≠òËá≥: {config.SYSTEM['LOG_FILENAME']}")
            except Exception as e:
                print(f"‚ö†Ô∏è Êó†Ê≥ïÂàõÂª∫Êó•ÂøóÊñá‰ª∂: {e}")

    def _setup_data_logger(self):
        try:
            self.data_logger = DataLogger(
                enable_csv=config.DATA_RECORDING['SAVE_TO_CSV'],
                enable_json=config.DATA_RECORDING['SAVE_TO_JSON'],
                csv_filename=config.DATA_RECORDING.get('CSV_FILENAME'),
                json_filename=config.DATA_RECORDING.get('JSON_FILENAME')
            )
            self.logger.info("üìä Êï∞ÊçÆËÆ∞ÂΩïÂô®ÂàùÂßãÂåñÂÆåÊàê")
        except Exception as e:
            self.logger.error(f"‚ùå Êï∞ÊçÆËÆ∞ÂΩïÂô®ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            self.data_logger = None

    def _connect_to_airsim(self):
        max_attempts = config.SYSTEM['MAX_RECONNECT_ATTEMPTS']
        for attempt in range(1, max_attempts + 1):
            try:
                self.logger.info(f"üîÑ Â∞ùËØïËøûÊé•Âà∞AirSim (Á¨¨{attempt}Ê¨°)...")
                self.client = airsim.MultirotorClient()
                self.client.confirmConnection()
                self.logger.info("‚úÖ ÊàêÂäüËøûÊé•Âà∞AirSim")
                self.reconnect_attempts = 0
                return
            except ConnectionRefusedError:
                self.logger.warning(f"‚ùå ËøûÊé•Ë¢´ÊãíÁªùÔºåËØ∑Á°Æ‰øùAirSimÊ≠£Âú®ËøêË°å")
            except Exception as e:
                self.logger.warning(f"‚ùå ËøûÊé•Â§±Ë¥•: {e}")

            if attempt < max_attempts:
                self.logger.info(f"‚è≥ {config.SYSTEM['RECONNECT_DELAY']}ÁßíÂêéÈáçËØï...")
                time.sleep(config.SYSTEM['RECONNECT_DELAY'])

        self.logger.error(f"‚ùå ÁªèËøá{max_attempts}Ê¨°Â∞ùËØïÂêé‰ªçÊó†Ê≥ïËøûÊé•Âà∞AirSim")
        self.logger.error("ËØ∑Ê£ÄÊü•Ôºö1. AirSimÊòØÂê¶ÂêØÂä® 2. ÁΩëÁªúËÆæÁΩÆ 3. Èò≤ÁÅ´Â¢ô")
        sys.exit(1)

    def _check_connection_health(self):
        try:
            self.client.ping()
            self.logger.debug("‚úÖ ËøûÊé•ÂÅ•Â∫∑Ê£ÄÊü•ÈÄöËøá")
            return True
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ËøûÊé•ÂÅ•Â∫∑Ê£ÄÊü•Â§±Ë¥•: {e}")
            try:
                self._connect_to_airsim()
                return True
            except:
                return False

    def _setup_windows(self):
        """ÂàùÂßãÂåñ‰∏§‰∏™ÊòæÁ§∫Á™óÂè£"""
        try:
            # ÂâçËßÜÁ™óÂè£
            self.front_window = FrontViewWindow(
                window_name=f"{config.DISPLAY['FRONT_VIEW_WINDOW']['NAME']} - {self.drone_name or 'AirSimNH'}",
                width=config.DISPLAY['FRONT_VIEW_WINDOW']['WIDTH'],
                height=config.DISPLAY['FRONT_VIEW_WINDOW']['HEIGHT'],
                enable_sharpening=config.DISPLAY['FRONT_VIEW_WINDOW']['ENABLE_SHARPENING'],
                show_info=config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_INFO_OVERLAY']
            )
            self.logger.info("üé• ÂâçËßÜÁ™óÂè£Â∑≤ÂàùÂßãÂåñ")

            # ‰ø°ÊÅØÊòæÁ§∫Á™óÂè£
            self.info_window = InfoDisplayWindow(
                window_name=f"{config.DISPLAY['INFO_WINDOW']['NAME']} - {self.drone_name or 'AirSimNH'}",
                width=config.DISPLAY['INFO_WINDOW']['WIDTH'],
                height=config.DISPLAY['INFO_WINDOW']['HEIGHT']
            )
            self.logger.info("üìä ‰ø°ÊÅØÊòæÁ§∫Á™óÂè£Â∑≤ÂàùÂßãÂåñ")

        except Exception as e:
            self.logger.error(f"‚ùå Á™óÂè£ÂàùÂßãÂåñÂ§±Ë¥•: {e}")

    def _update_info_window(self, perception: PerceptionResult):
        """Êõ¥Êñ∞‰ø°ÊÅØÊòæÁ§∫Á™óÂè£"""
        if not self.info_window:
            return

        try:
            # Ëé∑ÂèñÊó†‰∫∫Êú∫Áä∂ÊÄÅ
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            # Êî∂ÈõÜÊÄßËÉΩ‰ø°ÊÅØ
            cpu_usage = psutil.cpu_percent(interval=0) if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0
            memory_usage = psutil.virtual_memory().percent if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0

            # ÂáÜÂ§á‰ø°ÊÅØÊï∞ÊçÆ
            info_data = {
                'timestamp': datetime.now().strftime("%H:%M:%S"),
                'state': self.state.value,
                'position': (pos.x_val, pos.y_val, pos.z_val),
                'perception': {
                    'obstacle_distance': perception.obstacle_distance,
                    'open_space_score': perception.open_space_score,
                    'has_obstacle': perception.has_obstacle
                },
                'objects_stats': {
                    'red_total': len(self.red_objects),
                    'red_visited': sum(1 for obj in self.red_objects if obj.visited),
                    'blue_total': len(self.blue_objects),
                    'blue_visited': sum(1 for obj in self.blue_objects if obj.visited),
                    'black_total': len(self.black_objects),
                    'black_visited': sum(1 for obj in self.black_objects if obj.visited),
                    'red_in_view': perception.red_objects_count,
                    'blue_in_view': perception.blue_objects_count,
                    'black_in_view': perception.black_objects_count
                },
                'grid_stats': {
                    'frontiers': len(self.exploration_grid.frontier_cells),
                    'explored': np.sum(self.exploration_grid.grid > 0.7),
                    'total': self.exploration_grid.grid_size * self.exploration_grid.grid_size
                },
                'performance': {
                    'cpu_usage': cpu_usage,
                    'memory_usage': memory_usage,
                    'loop_time': self.stats.get('average_loop_time', 0)
                }
            }

            # Ê∑ªÂä†ÁΩëÊ†ºÂõæÂÉè
            if config.DISPLAY['INFO_WINDOW']['SHOW_GRID']:
                grid_img = self.exploration_grid.visualize_grid(size=config.DISPLAY['INFO_WINDOW']['GRID_SIZE'])
                info_data['grid_image'] = grid_img

            # Êõ¥Êñ∞‰ø°ÊÅØÁ™óÂè£
            self.info_window.update_info(info_data)

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Êõ¥Êñ∞‰ø°ÊÅØÁ™óÂè£Êó∂Âá∫Èîô: {e}")

    def _detect_red_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[RedObject], np.ndarray]:
        red_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['RED_OBJECT_DETECTION']['ENABLED'] or image is None:
            return red_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_red1 = np.array(config.CAMERA['RED_COLOR_RANGE']['LOWER1'])
            upper_red1 = np.array(config.CAMERA['RED_COLOR_RANGE']['UPPER1'])
            lower_red2 = np.array(config.CAMERA['RED_COLOR_RANGE']['LOWER2'])
            upper_red2 = np.array(config.CAMERA['RED_COLOR_RANGE']['UPPER2'])

            mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            red_mask = cv2.bitwise_or(mask1, mask2)

            kernel = np.ones((5, 5), np.uint8)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['RED_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['RED_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    red_object = RedObject(
                        id=self.red_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.red_objects:
                        if self._is_same_object(red_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = red_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            red_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.red_object_id_counter += 1
                        red_objects.append(red_object)
                        self.stats['red_objects_detected'] += 1
                        self.logger.info(f"üî¥ Ê£ÄÊµãÂà∞Á∫¢Ëâ≤Áâ©‰Ωì #{red_object.id} (ÁΩÆ‰ø°Â∫¶: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_RED_OBJECTS']:
                            self.data_logger.record_red_object(red_object)
                    else:
                        red_objects.append(red_object)

                    if marked_image is not None:
                        color = (0, 100, 255)
                        if red_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"R:{red_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.red_objects = [obj for obj in self.red_objects
                              if current_time - obj.last_seen < self.red_object_memory_time]

            visited_count = sum(1 for obj in self.red_objects if obj.visited)
            if len(red_objects) > 0:
                self.logger.debug(f"üî¥ ÂΩìÂâçÁ∫¢Ëâ≤Áâ©‰Ωì: {len(self.red_objects)}‰∏™, Â∑≤ËÆøÈóÆ: {visited_count}‰∏™")

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Á∫¢Ëâ≤Áâ©‰ΩìÊ£ÄÊµãÂ§±Ë¥•: {e}")

        return red_objects, marked_image

    def _detect_blue_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[BlueObject], np.ndarray]:
        blue_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['BLUE_OBJECT_DETECTION']['ENABLED'] or image is None:
            return blue_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_blue = np.array(config.CAMERA['BLUE_COLOR_RANGE']['LOWER'])
            upper_blue = np.array(config.CAMERA['BLUE_COLOR_RANGE']['UPPER'])

            blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)

            kernel = np.ones((5, 5), np.uint8)
            blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel)
            blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['BLUE_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['BLUE_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    blue_object = BlueObject(
                        id=self.blue_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.blue_objects:
                        if self._is_same_object_blue(blue_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = blue_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            blue_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.blue_object_id_counter += 1
                        blue_objects.append(blue_object)
                        self.stats['blue_objects_detected'] += 1
                        self.logger.info(f"üîµ Ê£ÄÊµãÂà∞ËìùËâ≤Áâ©‰Ωì #{blue_object.id} (ÁΩÆ‰ø°Â∫¶: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_BLUE_OBJECTS']:
                            self.data_logger.record_blue_object(blue_object)
                    else:
                        blue_objects.append(blue_object)

                    if marked_image is not None:
                        color = (255, 100, 0)
                        if blue_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"B:{blue_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.blue_objects = [obj for obj in self.blue_objects
                               if current_time - obj.last_seen < self.blue_object_memory_time]

            visited_count = sum(1 for obj in self.blue_objects if obj.visited)
            if len(blue_objects) > 0:
                self.logger.debug(f"üîµ ÂΩìÂâçËìùËâ≤Áâ©‰Ωì: {len(self.blue_objects)}‰∏™, Â∑≤ËÆøÈóÆ: {visited_count}‰∏™")

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ËìùËâ≤Áâ©‰ΩìÊ£ÄÊµãÂ§±Ë¥•: {e}")

        return blue_objects, marked_image

    def _detect_black_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[BlackObject], np.ndarray]:
        black_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['BLACK_OBJECT_DETECTION']['ENABLED'] or image is None:
            return black_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_black = np.array(config.CAMERA['BLACK_COLOR_RANGE']['LOWER'])
            upper_black = np.array(config.CAMERA['BLACK_COLOR_RANGE']['UPPER'])

            black_mask = cv2.inRange(hsv, lower_black, upper_black)

            kernel = np.ones((5, 5), np.uint8)
            black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_CLOSE, kernel)
            black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['BLACK_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['BLACK_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    black_object = BlackObject(
                        id=self.black_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.black_objects:
                        if self._is_same_object_black(black_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = black_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            black_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.black_object_id_counter += 1
                        black_objects.append(black_object)
                        self.stats['black_objects_detected'] += 1
                        self.logger.info(f"‚ö´ Ê£ÄÊµãÂà∞ÈªëËâ≤Áâ©‰Ωì #{black_object.id} (ÁΩÆ‰ø°Â∫¶: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_BLACK_OBJECTS']:
                            self.data_logger.record_black_object(black_object)
                    else:
                        black_objects.append(black_object)

                    if marked_image is not None:
                        color = (128, 128, 128)
                        if black_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"K:{black_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.black_objects = [obj for obj in self.black_objects
                               if current_time - obj.last_seen < self.black_object_memory_time]

            visited_count = sum(1 for obj in self.black_objects if obj.visited)
            if len(black_objects) > 0:
                self.logger.debug(f"‚ö´ ÂΩìÂâçÈªëËâ≤Áâ©‰Ωì: {len(self.black_objects)}‰∏™, Â∑≤ËÆøÈóÆ: {visited_count}‰∏™")

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµãÂ§±Ë¥•: {e}")

        return black_objects, marked_image

    def _is_same_object(self, obj1: RedObject, obj2: RedObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _is_same_object_blue(self, obj1: BlueObject, obj2: BlueObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _is_same_object_black(self, obj1: BlackObject, obj2: BlackObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _check_red_object_proximity(self, current_pos):
        for obj in self.red_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['red_objects_visited'] += 1

                    self.logger.info(f"‚úÖ Â∑≤ËÆøÈóÆÁ∫¢Ëâ≤Áâ©‰Ωì #{obj.id} (Ë∑ùÁ¶ª: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('red_object_visited', event_data)

                    self.change_state(FlightState.RED_OBJECT_INSPECTION)
                    return True

        return False

    def _check_blue_object_proximity(self, current_pos):
        for obj in self.blue_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['blue_objects_visited'] += 1

                    self.logger.info(f"‚úÖ Â∑≤ËÆøÈóÆËìùËâ≤Áâ©‰Ωì #{obj.id} (Ë∑ùÁ¶ª: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('blue_object_visited', event_data)

                    self.change_state(FlightState.BLUE_OBJECT_INSPECTION)
                    return True

        return False

    def _check_black_object_proximity(self, current_pos):
        for obj in self.black_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['black_objects_visited'] += 1

                    self.logger.info(f"‚úÖ Â∑≤ËÆøÈóÆÈªëËâ≤Áâ©‰Ωì #{obj.id} (Ë∑ùÁ¶ª: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('black_object_visited', event_data)

                    self.change_state(FlightState.BLACK_OBJECT_INSPECTION)
                    return True

        return False

    def get_depth_perception(self) -> PerceptionResult:
        result = PerceptionResult()
        self.stats['perception_cycles'] += 1

        try:
            if config.SYSTEM['ENABLE_HEALTH_CHECK']:
                current_time = time.time()
                if current_time - self.last_successful_loop > 10.0:
                    self.logger.warning("‚ö†Ô∏è ÊÑüÁü•Âæ™ÁéØÈïøÊó∂Èó¥Êó†ÂìçÂ∫îÔºåÂ∞ùËØïÊÅ¢Â§ç...")
                    self._check_connection_health()

            camera_name = config.CAMERA['DEFAULT_NAME']
            responses = self.client.simGetImages([
                airsim.ImageRequest(
                    camera_name,
                    airsim.ImageType.DepthPlanar,
                    pixels_as_float=True,
                    compress=False
                ),
                airsim.ImageRequest(
                    camera_name,
                    airsim.ImageType.Scene,
                    False,
                    False
                )
            ])

            if not responses or len(responses) < 2:
                self.logger.warning("‚ö†Ô∏è ÂõæÂÉèËé∑ÂèñÂ§±Ë¥•ÔºöÂìçÂ∫î‰∏∫Á©∫ÊàñÊï∞Èáè‰∏çË∂≥")
                return result

            depth_img = responses[0]
            depth_array = None
            if depth_img and hasattr(depth_img, 'image_data_float'):
                try:
                    depth_array = np.array(depth_img.image_data_float, dtype=np.float32)
                    depth_array = depth_array.reshape(depth_img.height, depth_img.width)

                    h, w = depth_array.shape

                    front_near = depth_array[h // 2:, w // 3:2 * w // 3]
                    min_front_distance = np.min(front_near) if front_near.size > 0 else 100

                    directions = []
                    for angle_deg in self.scan_angles:
                        angle_rad = math.radians(angle_deg)
                        col = int(w / 2 + (w / 2) * math.tan(angle_rad) * 0.5)
                        col = max(0, min(w - 1, col))

                        col_data = depth_array[h // 2:, col]
                        if col_data.size > 0:
                            dir_distance = np.percentile(col_data, 25)
                            directions.append((angle_rad, dir_distance))

                            if dir_distance > self.depth_threshold_safe:
                                result.safe_directions.append(angle_rad)

                    result.obstacle_positions = self._extract_obstacle_positions(depth_array, h, w)

                    ground_region = depth_array[3 * h // 4:, :]
                    if ground_region.size > 10:
                        row_variances = np.var(ground_region, axis=1)
                        result.terrain_slope = np.mean(row_variances) * 100

                    open_pixels = np.sum(depth_array[h // 2:, :] > self.depth_threshold_safe)
                    total_pixels = depth_array[h // 2:, :].size
                    result.open_space_score = open_pixels / total_pixels if total_pixels > 0 else 0

                    result.has_obstacle = min_front_distance < self.depth_threshold_near
                    result.obstacle_distance = min_front_distance
                    if result.has_obstacle:
                        self.stats['obstacles_detected'] += 1

                    if directions:
                        closest_dir = min(directions, key=lambda x: x[1])
                        result.obstacle_direction = closest_dir[0]

                    if result.terrain_slope > config.PERCEPTION['HEIGHT_STRATEGY']['SLOPE_THRESHOLD']:
                        result.recommended_height = config.PERCEPTION['HEIGHT_STRATEGY']['STEEP_SLOPE']
                    elif result.open_space_score > config.PERCEPTION['HEIGHT_STRATEGY']['OPENNESS_THRESHOLD']:
                        result.recommended_height = config.PERCEPTION['HEIGHT_STRATEGY']['OPEN_SPACE']

                except ValueError as e:
                    self.logger.error(f"‚ùå Ê∑±Â∫¶ÂõæÂÉèÊï∞ÊçÆËΩ¨Êç¢ÈîôËØØ: {e}")
                except Exception as e:
                    self.logger.error(f"‚ùå Ê∑±Â∫¶ÂõæÂÉèÂ§ÑÁêÜÂºÇÂ∏∏: {e}")

            front_response = responses[1]
            if front_response and hasattr(front_response, 'image_data_uint8'):
                try:
                    img_array = np.frombuffer(front_response.image_data_uint8, dtype=np.uint8)

                    if len(img_array) > 0:
                        img_rgb = img_array.reshape(front_response.height, front_response.width, 3)
                        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                        current_time = time.time()

                        # Ê£ÄÊµãÁ∫¢Ëâ≤Áâ©‰Ωì
                        if current_time - self.last_red_detection_time >= self.red_detection_interval:
                            red_objects, red_marked_image = self._detect_red_objects(img_bgr, depth_array)
                            result.red_objects = red_objects
                            result.red_objects_count = len(red_objects)
                            result.red_objects_image = red_marked_image
                            self.last_red_detection_time = current_time

                        # Ê£ÄÊµãËìùËâ≤Áâ©‰Ωì
                        if current_time - self.last_blue_detection_time >= self.blue_detection_interval:
                            blue_objects, blue_marked_image = self._detect_blue_objects(img_bgr, depth_array)
                            result.blue_objects = blue_objects
                            result.blue_objects_count = len(blue_objects)
                            result.blue_objects_image = blue_marked_image
                            self.last_blue_detection_time = current_time

                        # Ê£ÄÊµãÈªëËâ≤Áâ©‰Ωì
                        if current_time - self.last_black_detection_time >= self.black_detection_interval:
                            black_objects, black_marked_image = self._detect_black_objects(img_bgr, depth_array)
                            result.black_objects = black_objects
                            result.black_objects_count = len(black_objects)
                            result.black_objects_image = black_marked_image
                            self.last_black_detection_time = current_time

                        result.front_image = img_bgr

                        display_info = self._prepare_display_info(result)

                        self._update_exploration_grid(result)

                        self._record_flight_data(result)

                        # Êõ¥Êñ∞‰ø°ÊÅØÁ™óÂè£
                        self._update_info_window(result)

                        if self.front_window:
                            manual_info = None
                            if self.state == FlightState.MANUAL:
                                manual_info = self._get_manual_control_info()

                            # ÂÜÖÂ≠ò‰ºòÂåñÔºö‰ªÖÂú®ÈúÄË¶ÅÊ†áËÆ∞Êó∂ÊâçÂ§çÂà∂ÂõæÂÉè
                            has_markers = (config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_RED_OBJECTS'] and result.red_objects_image is not None) or \
                                         (config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLUE_OBJECTS'] and result.blue_objects_image is not None) or \
                                         (config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLACK_OBJECTS'] and result.black_objects_image is not None)
                            
                            if has_markers:
                                display_image = img_bgr.copy()
                                if config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_RED_OBJECTS'] and result.red_objects_image is not None:
                                    red_mask = cv2.inRange(result.red_objects_image, (0, 100, 0), (0, 255, 255))
                                    display_image[red_mask > 0] = result.red_objects_image[red_mask > 0]

                                if config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLUE_OBJECTS'] and result.blue_objects_image is not None:
                                    blue_mask = cv2.inRange(result.blue_objects_image, (255, 100, 0), (255, 255, 255))
                                    display_image[blue_mask > 0] = result.blue_objects_image[blue_mask > 0]

                                if config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLACK_OBJECTS'] and result.black_objects_image is not None:
                                    black_mask = cv2.inRange(result.black_objects_image, (128, 128, 0), (128, 255, 255))
                                    display_image[black_mask > 0] = result.black_objects_image[black_mask > 0]
                            else:
                                # Ê≤°ÊúâÊ†áËÆ∞Êó∂Áõ¥Êé•‰ΩøÁî®ÂéüÂõæÂÉèÂºïÁî®
                                display_image = img_bgr

                            self.front_window.update_image(display_image, display_info, manual_info)
                            self.stats['front_image_updates'] += 1

                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è ÂâçËßÜÂõæÂÉèÂ§ÑÁêÜÂºÇÂ∏∏: {e}")

            self.last_successful_loop = time.time()

            if self.loop_count % 50 == 0 and config.DEBUG.get('LOG_DECISION_DETAILS', False):
                self.logger.debug(f"ÊÑüÁü•ÁªìÊûú: ÈöúÁ¢ç={result.has_obstacle}, Ë∑ùÁ¶ª={result.obstacle_distance:.1f}m, "
                                f"ÂºÄÈòîÂ∫¶={result.open_space_score:.2f}, Á∫¢Ëâ≤Áâ©‰Ωì={result.red_objects_count}‰∏™, "
                                f"ËìùËâ≤Áâ©‰Ωì={result.blue_objects_count}‰∏™, ÈªëËâ≤Áâ©‰Ωì={result.black_objects_count}‰∏™")

        except Exception as e:
            if "ClientException" in str(type(e)) or "Connection" in str(e):
                self.logger.error(f"‚ùå AirSimÂÆ¢Êà∑Á´ØÂºÇÂ∏∏: {e}")
                self.stats['exceptions_caught'] += 1
                if self.data_logger:
                    self.data_logger.record_event('airsim_exception', {'error': str(e)})
                self._check_connection_health()
            else:
                self.logger.error(f"‚ùå ÊÑüÁü•ËøáÁ®ã‰∏≠ÂèëÁîüÊú™Áü•ÂºÇÂ∏∏: {e}")
                self.logger.debug(f"ÂºÇÂ∏∏ËØ¶ÊÉÖ: {traceback.format_exc()}")
                self.stats['exceptions_caught'] += 1
                if self.data_logger:
                    self.data_logger.record_event('perception_exception', {'error': str(e)})

        return result

    def _record_flight_data(self, perception: PerceptionResult):
        if not config.DATA_RECORDING['ENABLED'] or not self.data_logger:
            return

        current_time = time.time()
        if current_time - self.last_data_record_time < self.data_record_interval:
            return

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            vel = state.kinematics_estimated.linear_velocity
            orientation = state.kinematics_estimated.orientation

            roll, pitch, yaw = airsim.to_eularian_angles(orientation)

            cpu_usage = psutil.cpu_percent(interval=0) if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0
            memory_usage = psutil.virtual_memory().percent if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0

            red_objects_count = perception.red_objects_count
            red_objects_visited = sum(1 for obj in self.red_objects if obj.visited)

            blue_objects_count = perception.blue_objects_count
            blue_objects_visited = sum(1 for obj in self.blue_objects if obj.visited)

            black_objects_count = perception.black_objects_count
            black_objects_visited = sum(1 for obj in self.black_objects if obj.visited)

            data_dict = {
                'timestamp': datetime.now().isoformat(),
                'loop_count': self.loop_count,
                'state': self.state.value,
                'pos_x': pos.x_val,
                'pos_y': pos.y_val,
                'pos_z': pos.z_val,
                'vel_x': vel.x_val,
                'vel_y': vel.y_val,
                'vel_z': vel.z_val,
                'yaw': yaw,
                'pitch': pitch,
                'roll': roll,
                'obstacle_distance': perception.obstacle_distance,
                'open_space_score': perception.open_space_score,
                'terrain_slope': perception.terrain_slope,
                'has_obstacle': perception.has_obstacle,
                'obstacle_direction': perception.obstacle_direction,
                'recommended_height': perception.recommended_height,
                'target_x': self.exploration_target[0] if self.exploration_target else 0.0,
                'target_y': self.exploration_target[1] if self.exploration_target else 0.0,
                'target_z': perception.recommended_height,
                'cpu_usage': cpu_usage,
                'memory_usage': memory_usage,
                'grid_frontiers': len(self.exploration_grid.frontier_cells),
                'grid_explored': np.sum(self.exploration_grid.grid > 0.7),
                'adaptive_speed_factor': self._calculate_adaptive_speed(perception, 0) if hasattr(self, '_calculate_adaptive_speed') else 1.0,
                'red_objects_count': red_objects_count,
                'red_objects_detected': self.stats['red_objects_detected'],
                'red_objects_visited': red_objects_visited,
                'blue_objects_count': blue_objects_count,
                'blue_objects_detected': self.stats['blue_objects_detected'],
                'blue_objects_visited': blue_objects_visited,
                'black_objects_count': black_objects_count,
                'black_objects_detected': self.stats['black_objects_detected'],
                'black_objects_visited': black_objects_visited,
            }

            self.data_logger.record_flight_data(data_dict)
            self.stats['data_points_recorded'] += 1
            self.last_data_record_time = current_time

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ËÆ∞ÂΩïÈ£ûË°åÊï∞ÊçÆÊó∂Âá∫Èîô: {e}")

    def _extract_obstacle_positions(self, depth_array, height, width):
        obstacles = []

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            orientation = state.kinematics_estimated.orientation
            roll, pitch, yaw = airsim.to_eularian_angles(orientation)

            near_mask = depth_array < self.depth_threshold_near * 1.5

            step = 4
            for i in range(0, height, step):
                for j in range(0, width, step):
                    if near_mask[i, j]:
                        distance = depth_array[i, j]

                        fov_h = math.radians(90)
                        pixel_angle_x = (j - width/2) / (width/2) * (fov_h/2)
                        pixel_angle_y = (i - height/2) / (height/2) * (fov_h/2)

                        z = distance
                        x = z * math.tan(pixel_angle_x)
                        y = z * math.tan(pixel_angle_y)

                        world_x = x * math.cos(yaw) - y * math.sin(yaw) + pos.x_val
                        world_y = x * math.sin(yaw) + y * math.cos(yaw) + pos.y_val

                        obstacles.append((world_x, world_y))

            max_obstacles = 20
            if len(obstacles) > max_obstacles:
                obstacles = random.sample(obstacles, max_obstacles)

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ÊèêÂèñÈöúÁ¢çÁâ©‰ΩçÁΩÆÂ§±Ë¥•: {e}")

        return obstacles

    def _update_exploration_grid(self, perception: PerceptionResult):
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            self.exploration_grid.update_position(pos.x_val, pos.y_val)

            if perception.obstacle_positions:
                self.exploration_grid.update_obstacles(perception.obstacle_positions)

            if perception.red_objects:
                self.exploration_grid.update_red_objects(perception.red_objects)

            if perception.blue_objects:
                self.exploration_grid.update_blue_objects(perception.blue_objects)

            if perception.black_objects:
                self.exploration_grid.update_black_objects(perception.black_objects)

            self.stats['grid_updates'] += 1

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Êõ¥Êñ∞Êé¢Á¥¢ÁΩëÊ†ºÂ§±Ë¥•: {e}")

    def _prepare_display_info(self, perception: PerceptionResult) -> Dict:
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            info = {
                'state': self.state.value,
                'obstacle_distance': perception.obstacle_distance,
                'position': (pos.x_val, pos.y_val, pos.z_val),
                'loop_count': self.loop_count,
                'red_objects_count': perception.red_objects_count,
                'red_objects_visited': sum(1 for obj in self.red_objects if obj.visited),
                'blue_objects_count': perception.blue_objects_count,
                'blue_objects_visited': sum(1 for obj in self.blue_objects if obj.visited),
                'black_objects_count': perception.black_objects_count,
                'black_objects_visited': sum(1 for obj in self.black_objects if obj.visited),
            }

            if hasattr(self, 'last_decision_info'):
                info['decision_info'] = self.last_decision_info

            if config.DATA_RECORDING['ENABLED']:
                info['data_points'] = self.stats['data_points_recorded']

            return info
        except:
            return {}

    def _get_manual_control_info(self):
        info_lines = []

        if self.control_keys:
            key_names = []
            for key in self.control_keys:
                if key == ord('w'):
                    key_names.append("ÂâçËøõ")
                elif key == ord('s'):
                    key_names.append("ÂêéÈÄÄ")
                elif key == ord('a'):
                    key_names.append("Â∑¶Áßª")
                elif key == ord('d'):
                    key_names.append("Âè≥Áßª")
                elif key == ord('q'):
                    key_names.append("‰∏äÂçá")
                elif key == ord('e'):
                    key_names.append("‰∏ãÈôç")
                elif key == ord('z'):
                    key_names.append("Â∑¶ËΩ¨")
                elif key == ord('x'):
                    key_names.append("Âè≥ËΩ¨")
                elif key == 32:
                    key_names.append("ÊÇ¨ÂÅú")

            if key_names:
                info_lines.append(f"ÊéßÂà∂: {', '.join(key_names)}")
        else:
            info_lines.append("ÊéßÂà∂: ÊÇ¨ÂÅú")

        if self.red_objects:
            visited_count = sum(1 for obj in self.red_objects if obj.visited)
            info_lines.append(f"Á∫¢Ëâ≤Áâ©‰Ωì: {visited_count}/{len(self.red_objects)}")

        if self.blue_objects:
            visited_count = sum(1 for obj in self.blue_objects if obj.visited)
            info_lines.append(f"ËìùËâ≤Áâ©‰Ωì: {visited_count}/{len(self.blue_objects)}")

        if self.black_objects:
            visited_count = sum(1 for obj in self.black_objects if obj.visited)
            info_lines.append(f"ÈªëËâ≤Áâ©‰Ωì: {visited_count}/{len(self.black_objects)}")

        if self.manual_control_start > 0:
            elapsed = time.time() - self.manual_control_start
            info_lines.append(f"ÊâãÂä®Ê®°Âºè: {elapsed:.1f}Áßí")

        info_lines.append("ESC: ÈÄÄÂá∫ÊâãÂä®Ê®°Âºè")

        return info_lines

    def apply_manual_control(self):
        if self.state != FlightState.MANUAL:
            return

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            orientation = state.kinematics_estimated.orientation

            _, _, yaw = airsim.to_eularian_angles(orientation)

            vx, vy, vz, yaw_rate = 0.0, 0.0, 0.0, 0.0

            for key in list(self.control_keys.keys()):
                key_char = chr(key).lower() if 0 <= key <= 255 else ''

                if key_char == 'w':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw)
                elif key_char == 's':
                    vx -= config.MANUAL['CONTROL_SPEED'] * math.cos(yaw)
                    vy -= config.MANUAL['CONTROL_SPEED'] * math.sin(yaw)

                if key_char == 'a':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw + math.pi/2)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw + math.pi/2)
                elif key_char == 'd':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw - math.pi/2)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw - math.pi/2)

                if key_char == 'q':
                    vz = -config.MANUAL['ALTITUDE_SPEED']
                elif key_char == 'e':
                    vz = config.MANUAL['ALTITUDE_SPEED']

                if key_char == 'z':
                    yaw_rate = -math.radians(config.MANUAL['YAW_SPEED'])
                elif key_char == 'x':
                    yaw_rate = math.radians(config.MANUAL['YAW_SPEED'])

                if key == 32:
                    self.client.hoverAsync(vehicle_name=self.drone_name)
                    self.control_keys = {}
                    return

            if config.MANUAL['SAFETY_ENABLED']:
                speed = math.sqrt(vx**2 + vy**2)
                if speed > config.MANUAL['MAX_MANUAL_SPEED']:
                    scale = config.MANUAL['MAX_MANUAL_SPEED'] / speed
                    vx *= scale
                    vy *= scale

                target_z = pos.z_val + vz * 0.1
                if target_z > config.MANUAL['MIN_ALTITUDE_LIMIT']:
                    vz = max(vz, (config.MANUAL['MIN_ALTITUDE_LIMIT'] - pos.z_val) * 10)
                if target_z < config.MANUAL['MAX_ALTITUDE_LIMIT']:
                    vz = min(vz, (config.MANUAL['MAX_ALTITUDE_LIMIT'] - pos.z_val) * 10)

            if vx != 0.0 or vy != 0.0 or vz != 0.0:
                self.client.moveByVelocityAsync(vx, vy, vz, 0.1, vehicle_name=self.drone_name)
            elif yaw_rate != 0.0:
                self.client.rotateByYawRateAsync(yaw_rate, 0.1, vehicle_name=self.drone_name)
            elif config.MANUAL['ENABLE_AUTO_HOVER'] and not self.control_keys:
                self.client.hoverAsync(vehicle_name=self.drone_name)

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ÊâãÂä®ÊéßÂà∂Â∫îÁî®Â§±Ë¥•: {e}")

    def change_state(self, new_state: FlightState):
        if self.state != new_state:
            old_state = self.state.value
            self.logger.info(f"üîÑ Áä∂ÊÄÅËΩ¨Êç¢: {old_state} ‚Üí {new_state.value}")
            self.state = new_state
            self.state_history.append((time.time(), new_state))
            self.stats['state_changes'] += 1

            if self.data_logger:
                event_data = {
                    'old_state': old_state,
                    'new_state': new_state.value,
                    'loop_count': self.loop_count
                }
                self.data_logger.record_event('state_change', event_data)

    def run_manual_control(self):
        self.logger.info("=" * 60)
        self.logger.info("ÂêØÂä®ÊâãÂä®ÊéßÂà∂Ê®°Âºè")
        self.logger.info("=" * 60)

        if not self.front_window:
            self.logger.error("‚ùå ÂâçËßÜÁ™óÂè£Êú™ÂàùÂßãÂåñ")
            return

        try:
            self.change_state(FlightState.MANUAL)
            self.manual_control_start = time.time()

            self.front_window.set_manual_mode(True)

            self.logger.info("üïπÔ∏è ËøõÂÖ•ÊâãÂä®ÊéßÂà∂Ê®°Âºè")
            print("\n" + "="*60)
            print("üéÆ ÊâãÂä®ÊéßÂà∂Ê®°ÂºèÂ∑≤ÂêØÂä®")
            print("="*60)
            print("ÊéßÂà∂ÈîÆ‰Ωç:")
            print("  W: ÂâçËøõ | S: ÂêéÈÄÄ | A: Â∑¶Áßª | D: Âè≥Áßª")
            print("  Q: ‰∏äÂçá | E: ‰∏ãÈôç | Z: Â∑¶ËΩ¨ | X: Âè≥ËΩ¨")
            print("  Á©∫Ê†º: ÊÇ¨ÂÅú | ESC: ÈÄÄÂá∫ÊâãÂä®Ê®°Âºè")
            print("="*60)
            print("üí° ÊèêÁ§∫: ÊåâÈîÆÊó∂ÊéßÂà∂ÊåÅÁª≠ÁîüÊïàÔºåÊùæÂºÄËá™Âä®ÂÅúÊ≠¢")
            print("        ËØ∑Âú®Êó†‰∫∫Êú∫ÂâçËßÜÁ™óÂè£Êìç‰Ωú")
            print("="*60)

            self.control_keys = {}

            manual_active = True
            last_control_time = time.time()
            last_image_time = time.time()

            while manual_active and not self.emergency_flag:
                try:
                    if self.front_window.should_exit_manual():
                        self.logger.info("Êî∂Âà∞ÈÄÄÂá∫ÊâãÂä®Ê®°ÂºèÊåá‰ª§")
                        manual_active = False
                        break

                    if self.front_window:
                        window_keys = self.front_window.get_control_inputs()
                        self.control_keys = window_keys.copy()

                    if not self.front_window.display_active:
                        self.logger.info("ÂâçËßÜÁ™óÂè£Â∑≤ÂÖ≥Èó≠ÔºåÈÄÄÂá∫ÊâãÂä®Ê®°Âºè")
                        manual_active = False
                        break

                    current_time = time.time()
                    if current_time - last_control_time >= 0.05:
                        self.apply_manual_control()
                        last_control_time = current_time

                    if current_time - last_image_time >= 0.1:
                        try:
                            camera_name = config.CAMERA['DEFAULT_NAME']
                            responses = self.client.simGetImages([
                                airsim.ImageRequest(
                                    camera_name,
                                    airsim.ImageType.Scene,
                                    False,
                                    False
                                )
                            ])

                            if responses and responses[0] and hasattr(responses[0], 'image_data_uint8'):
                                img_array = np.frombuffer(responses[0].image_data_uint8, dtype=np.uint8)
                                if len(img_array) > 0:
                                    img_rgb = img_array.reshape(responses[0].height, responses[0].width, 3)
                                    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                                    try:
                                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                                        pos = state.kinematics_estimated.position
                                        display_info = {
                                            'state': self.state.value,
                                            'position': (pos.x_val, pos.y_val, pos.z_val),
                                            'loop_count': self.loop_count,
                                        }
                                    except:
                                        display_info = {}

                                    if self.front_window:
                                        manual_info = self._get_manual_control_info()
                                        self.front_window.update_image(img_bgr, display_info, manual_info)
                                        last_image_time = current_time
                        except Exception as img_error:
                            pass

                    try:
                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                        pos = state.kinematics_estimated.position
                        current_pos = (pos.x_val, pos.y_val)
                        self._check_red_object_proximity(current_pos)
                        self._check_blue_object_proximity(current_pos)
                        self._check_black_object_proximity(current_pos)
                    except:
                        pass

                    time.sleep(0.01)

                except KeyboardInterrupt:
                    self.logger.warning("‚èπÔ∏è Áî®Êà∑‰∏≠Êñ≠ÊâãÂä®ÊéßÂà∂")
                    manual_active = False
                    break
                except Exception as e:
                    self.logger.error(f"‚ùå ÊâãÂä®ÊéßÂà∂Âæ™ÁéØÂºÇÂ∏∏: {e}")
                    time.sleep(0.1)

            manual_time = time.time() - self.manual_control_start
            self.stats['manual_control_time'] = manual_time

            self.manual_control_start = 0
            self.control_keys = {}
            if self.front_window:
                self.front_window.set_manual_mode(False)

            try:
                self.client.hoverAsync(vehicle_name=self.drone_name).join()
            except:
                pass

            self.logger.info(f"‚è±Ô∏è  ÊâãÂä®ÊéßÂà∂ÁªìÊùüÔºåÊåÅÁª≠Êó∂Èó¥: {manual_time:.1f}Áßí")

            self.change_state(FlightState.HOVERING)

            print("\n" + "="*60)
            print("ÊâãÂä®ÊéßÂà∂Ê®°ÂºèÂ∑≤ÁªìÊùü")
            print(f"ÊéßÂà∂Êó∂Èó¥: {manual_time:.1f}Áßí")
            print(f"Ê£ÄÊµãÂà∞Á∫¢Ëâ≤Áâ©‰Ωì: {self.stats['red_objects_detected']}‰∏™")
            print(f"Ê£ÄÊµãÂà∞ËìùËâ≤Áâ©‰Ωì: {self.stats['blue_objects_detected']}‰∏™")
            print("="*60)
            print("ËØ∑ÈÄâÊã©‰∏ã‰∏ÄÊ≠•:")
            print("  1. ÁªßÁª≠Ëá™Âä®Êé¢Á¥¢")
            print("  2. ÂÜçÊ¨°ËøõÂÖ•ÊâãÂä®Ê®°Âºè")
            print("  3. ÈôçËêΩÂπ∂ÁªìÊùü‰ªªÂä°")
            print("="*60)

            choice = input("ËØ∑ËæìÂÖ•ÈÄâÊã© (1/2/3): ").strip()

            if choice == '1':
                self.logger.info("üîÑ ËøîÂõûËá™Âä®Êé¢Á¥¢Ê®°Âºè")
                remaining_time = self.exploration_time - (time.time() - self.start_time)
                if remaining_time > 10:
                    self.exploration_time = remaining_time
                    self.run_perception_loop()
                else:
                    self.logger.info("‚è∞ Ââ©‰ΩôÊé¢Á¥¢Êó∂Èó¥‰∏çË∂≥ÔºåÂºÄÂßãËøîËà™")
                    self._finish_mission()
            elif choice == '2':
                self.logger.info("üîÑ ÈáçÊñ∞ËøõÂÖ•ÊâãÂä®ÊéßÂà∂Ê®°Âºè")
                self.run_manual_control()
            else:
                self.logger.info("üõ¨ Áî®Êà∑ÈÄâÊã©ÁªìÊùü‰ªªÂä°")
                self._finish_mission()

        except Exception as e:
            self.logger.error(f"‚ùå ÊâãÂä®ÊéßÂà∂Ê®°ÂºèÂèëÁîüÂºÇÂ∏∏: {e}")
            self.logger.debug(f"ÂºÇÂ∏∏Â†ÜÊ†à: {traceback.format_exc()}")
            self.emergency_stop()

    def run_perception_loop(self):
        self.logger.info("=" * 60)
        self.logger.info("ÂêØÂä®ÊÑüÁü•-ÂÜ≥Á≠ñ-ÊéßÂà∂‰∏ªÂæ™ÁéØ")
        self.logger.info("=" * 60)

        try:
            self.logger.info("üöÄ Ëµ∑È£û‰∏≠...")
            self.client.takeoffAsync(vehicle_name=self.drone_name).join()
            time.sleep(2)

            self.client.moveToZAsync(self.takeoff_height, 3, vehicle_name=self.drone_name).join()
            self.change_state(FlightState.HOVERING)
            time.sleep(2)

            exploration_start = time.time()

            while (time.time() - exploration_start < self.exploration_time and
                   not self.emergency_flag):

                self.loop_count += 1
                loop_start = time.time()

                perception = self.get_depth_perception()

                try:
                    state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                    pos = state.kinematics_estimated.position
                    current_pos = (pos.x_val, pos.y_val)
                    if self._check_red_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                    if self._check_blue_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                    if self._check_black_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                except:
                    pass

                decision = self.make_intelligent_decision(perception)

                self._execute_control_decision(decision)

                loop_time = time.time() - loop_start
                self.stats['average_loop_time'] = (self.stats['average_loop_time'] * (self.loop_count-1) + loop_time) / self.loop_count
                self.stats['max_loop_time'] = max(self.stats['max_loop_time'], loop_time)
                self.stats['min_loop_time'] = min(self.stats['min_loop_time'], loop_time)

                if self.data_logger:
                    self.data_logger.record_loop_time(loop_time)

                current_time = time.time()
                if current_time - self.last_performance_report >= self.performance_report_interval:
                    self._generate_performance_report()
                    self.last_performance_report = current_time

                if self.loop_count % config.SYSTEM.get('HEALTH_CHECK_INTERVAL', 20) == 0:
                    self._report_status(exploration_start, perception)
                    # ÂÜÖÂ≠ò‰ºòÂåñÔºöÂÆöÊúüÂûÉÂúæÂõûÊî∂
                    gc.collect()

                loop_time = time.time() - loop_start
                if loop_time < 0.1:
                    time.sleep(0.1 - loop_time)

            self.logger.info("‚è∞ Êé¢Á¥¢Êó∂Èó¥Âà∞ÔºåÂºÄÂßãËøîËà™")
            self._finish_mission()

        except KeyboardInterrupt:
            self.logger.warning("‚èπÔ∏è Áî®Êà∑‰∏≠Êñ≠Êé¢Á¥¢")
            self.emergency_stop()
        except Exception as e:
            self.logger.error(f"‚ùå ‰∏ªÂæ™ÁéØÂèëÁîüÂºÇÂ∏∏: {e}")
            self.logger.debug(f"ÂºÇÂ∏∏Â†ÜÊ†à: {traceback.format_exc()}")
            self.emergency_stop()

    def _generate_performance_report(self):
        try:
            if not config.PERFORMANCE['ENABLE_REALTIME_METRICS']:
                return

            cpu_usage = psutil.cpu_percent(interval=0)
            memory_usage = psutil.virtual_memory().percent

            warnings = []
            if cpu_usage > config.PERFORMANCE['CPU_WARNING_THRESHOLD']:
                warnings.append(f"‚ö†Ô∏è CPU‰ΩøÁî®ÁéáËøáÈ´ò: {cpu_usage:.1f}%")

            if memory_usage > config.PERFORMANCE['MEMORY_WARNING_THRESHOLD']:
                warnings.append(f"‚ö†Ô∏è ÂÜÖÂ≠ò‰ΩøÁî®ÁéáËøáÈ´ò: {memory_usage:.1f}%")

            avg_loop_time = self.stats.get('average_loop_time', 0)
            if avg_loop_time > config.PERFORMANCE['LOOP_TIME_WARNING_THRESHOLD']:
                warnings.append(f"‚ö†Ô∏è Âπ≥ÂùáÂæ™ÁéØÊó∂Èó¥ËøáÈïø: {avg_loop_time*1000:.1f}ms")

            if warnings:
                self.logger.warning("üìä ÊÄßËÉΩË≠¶Âëä:")
                for warning in warnings:
                    self.logger.warning(f"  {warning}")

            if self.data_logger:
                performance_data = {
                    'timestamp': datetime.now().isoformat(),
                    'cpu_usage': cpu_usage,
                    'memory_usage': memory_usage,
                    'average_loop_time': avg_loop_time,
                    'max_loop_time': self.stats.get('max_loop_time', 0),
                    'min_loop_time': self.stats.get('min_loop_time', 0),
                    'warnings': warnings
                }
                self.data_logger.record_event('performance_report', performance_data)

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ÁîüÊàêÊÄßËÉΩÊä•ÂëäÊó∂Âá∫Èîô: {e}")

    def make_intelligent_decision(self, perception: PerceptionResult) -> Tuple[float, float, float, float]:
        self.stats['decision_cycles'] += 1
        decision_start = time.time()

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            vel = state.kinematics_estimated.linear_velocity

            target_vx, target_vy, target_z, target_yaw = 0.0, 0.0, perception.recommended_height, 0.0

            if self.state == FlightState.TAKEOFF:
                target_z = self.takeoff_height
                if pos.z_val < self.takeoff_height + 0.5:
                    self.change_state(FlightState.HOVERING)

            elif self.state == FlightState.HOVERING:
                target_yaw = (time.time() % 10) * 0.2

                current_time = time.time()
                if (self.exploration_target is None or
                    current_time - self.target_update_time > self.target_lifetime):

                    self.exploration_target = self.exploration_grid.get_best_exploration_target(
                        (pos.x_val, pos.y_val),
                        perception.red_objects,
                        perception.blue_objects,
                        perception.black_objects
                    )
                    self.target_update_time = current_time

                    if self.exploration_target:
                        self.logger.info(f"üéØ Êñ∞Êé¢Á¥¢ÁõÆÊ†á: {self.exploration_target[0]:.1f}, {self.exploration_target[1]:.1f}")

                if self.exploration_target:
                    self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.EXPLORING:
                if perception.has_obstacle:
                    self.change_state(FlightState.AVOIDING)
                    target_vx, target_vy = -vel.x_val * 2, -vel.y_val * 2
                else:
                    current_pos = (pos.x_val, pos.y_val)

                    if self.exploration_target is None:
                        self.exploration_target = self.exploration_grid.get_best_exploration_target(
                            current_pos,
                            perception.red_objects,
                            perception.blue_objects,
                            perception.black_objects
                        )
                        self.target_update_time = time.time()

                    vector = self.vector_planner.compute_vector(
                        current_pos,
                        self.exploration_target,
                        perception.obstacle_positions,
                        perception.red_objects,
                        perception.blue_objects,
                        perception.black_objects
                    )

                    speed_factor = self._calculate_adaptive_speed(perception, vector.magnitude())

                    target_speed = self.preferred_speed * speed_factor
                    current_speed = math.sqrt(vel.x_val**2 + vel.y_val**2)
                    speed_error = target_speed - current_speed
                    speed_adjustment = self.velocity_pid.update(speed_error)

                    final_vector = vector.normalize() * (target_speed + speed_adjustment)
                    target_vx = final_vector.x
                    target_vy = final_vector.y

                    self.stats['vector_field_updates'] += 1

                    self.last_decision_info = {
                        'vector_angle': math.atan2(vector.y, vector.x),
                        'vector_magnitude': vector.magnitude(),
                        'grid_score': len(self.exploration_grid.frontier_cells) / 100.0,
                        'speed_factor': speed_factor,
                        'red_objects_in_view': perception.red_objects_count,
                        'blue_objects_in_view': perception.blue_objects_count,
                        'black_objects_in_view': perception.black_objects_count,
                        'decision_time': time.time() - decision_start
                    }

                    if self.exploration_target:
                        distance_to_target = math.sqrt(
                            (self.exploration_target[0] - current_pos[0])**2 +
                            (self.exploration_target[1] - current_pos[1])**2
                        )
                        if distance_to_target < self.target_reached_distance:
                            self.exploration_target = None
                            self.change_state(FlightState.HOVERING)
                            self.logger.info("‚úÖ Âà∞ËææÊé¢Á¥¢ÁõÆÊ†á")

            elif self.state == FlightState.AVOIDING:
                if perception.has_obstacle:
                    current_pos = (pos.x_val, pos.y_val)

                    avoid_vector = self.vector_planner.compute_vector(
                        current_pos,
                        None,
                        perception.obstacle_positions,
                        perception.red_objects,
                        perception.blue_objects,
                        perception.black_objects
                    )

                    if avoid_vector.magnitude() > 0.1:
                        avoid_vector = avoid_vector.normalize() * 1.5
                        target_vx = avoid_vector.x
                        target_vy = avoid_vector.y

                    target_z = pos.z_val - 3
                else:
                    self.change_state(FlightState.EXPLORING)
                    time.sleep(1)

            elif self.state == FlightState.RED_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.BLUE_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.BLACK_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.EMERGENCY:
                target_vx, target_vy, target_yaw = 0, 0, 0
                target_z = max(pos.z_val, -20)

            elif self.state == FlightState.PLANNING:
                target_vx, target_vy = 0, 0
                target_z = perception.recommended_height

            height_error = target_z - pos.z_val
            height_adjustment = self.height_pid.update(height_error)
            target_z += height_adjustment

            target_z = max(self.max_altitude, min(self.min_altitude, target_z))

            decision_time = time.time() - decision_start
            self.last_decision_info['total_decision_time'] = decision_time

            return target_vx, target_vy, target_z, target_yaw

        except Exception as e:
            self.logger.error(f"‚ùå ÂÜ≥Á≠ñËøáÁ®ãÂºÇÂ∏∏: {e}")
            if self.data_logger:
                self.data_logger.record_event('decision_exception', {'error': str(e)})
            return 0.0, 0.0, self.base_height, 0.0

    def _calculate_adaptive_speed(self, perception: PerceptionResult, vector_magnitude: float) -> float:
        if not config.INTELLIGENT_DECISION['ADAPTIVE_SPEED_ENABLED']:
            return 1.0

        open_factor = min(1.0, perception.open_space_score * 1.2)

        if perception.obstacle_distance < self.depth_threshold_near * 2:
            obs_factor = max(0.3, perception.obstacle_distance / (self.depth_threshold_near * 2))
        else:
            obs_factor = 1.0

        vector_factor = min(1.0, vector_magnitude * 2)

        red_factor = 0.8 if perception.red_objects_count > 0 else 1.0
        blue_factor = 0.8 if perception.blue_objects_count > 0 else 1.0
        black_factor = 0.8 if perception.black_objects_count > 0 else 1.0
        color_factor = min(red_factor, blue_factor, black_factor)

        speed_factor = open_factor * obs_factor * vector_factor * color_factor * 0.7

        speed_factor = max(
            config.INTELLIGENT_DECISION['MIN_SPEED_FACTOR'],
            min(config.INTELLIGENT_DECISION['MAX_SPEED_FACTOR'], speed_factor)
        )

        return speed_factor

    def _execute_control_decision(self, decision):
        try:
            target_vx, target_vy, target_z, target_yaw = decision

            if self.state in [FlightState.EXPLORING, FlightState.AVOIDING, FlightState.PLANNING,
                              FlightState.RED_OBJECT_INSPECTION, FlightState.BLUE_OBJECT_INSPECTION,
                              FlightState.BLACK_OBJECT_INSPECTION]:
                self.client.moveByVelocityZAsync(
                    target_vx, target_vy, target_z, 0.5,
                    drivetrain=airsim.DrivetrainType.MaxDegreeOfFreedom,
                    yaw_mode=airsim.YawMode(is_rate=False, yaw_or_rate=target_yaw),
                    vehicle_name=self.drone_name
                )
            else:
                self.client.moveToPositionAsync(
                    0, 0, target_z, 2,
                    vehicle_name=self.drone_name
                )

            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            self.visited_positions.append((pos.x_val, pos.y_val, pos.z_val))

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è ÊéßÂà∂Êåá‰ª§ÊâßË°åÂ§±Ë¥•: {e}")
            if self.data_logger:
                self.data_logger.record_event('control_exception', {'error': str(e)})
            try:
                self.client.hoverAsync(vehicle_name=self.drone_name).join()
            except:
                pass

    def _report_status(self, exploration_start, perception):
        elapsed = time.time() - exploration_start
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            self.logger.info(f"\nüìä Á≥ªÁªüÁä∂ÊÄÅÊä•Âëä [Âæ™ÁéØ#{self.loop_count}]")
            self.logger.info(f"   ËøêË°åÊó∂Èó¥: {elapsed:.1f}s / {self.exploration_time}s")
            self.logger.info(f"   È£ûË°åÁä∂ÊÄÅ: {self.state.value}")
            self.logger.info(f"   ÂΩìÂâç‰ΩçÁΩÆ: ({pos.x_val:.1f}, {pos.y_val:.1f}, {-pos.z_val:.1f}m)")
            self.logger.info(f"   ÁéØÂ¢ÉÊÑüÁü•: ÈöúÁ¢ç{'Êúâ' if perception.has_obstacle else 'Êó†'} "
                            f"| Ë∑ùÁ¶ª={perception.obstacle_distance:.1f}m "
                            f"| ÂºÄÈòîÂ∫¶={perception.open_space_score:.2f}")
            self.logger.info(f"   Á∫¢Ëâ≤Áâ©‰Ωì: Ê£ÄÊµãÂà∞{perception.red_objects_count}‰∏™ "
                            f"| Â∑≤ËÆøÈóÆ{self.stats['red_objects_visited']}‰∏™")
            self.logger.info(f"   ËìùËâ≤Áâ©‰Ωì: Ê£ÄÊµãÂà∞{perception.blue_objects_count}‰∏™ "
                            f"| Â∑≤ËÆøÈóÆ{self.stats['blue_objects_visited']}‰∏™")
            self.logger.info(f"   ÈªëËâ≤Áâ©‰Ωì: Ê£ÄÊµãÂà∞{perception.black_objects_count}‰∏™ "
                            f"| Â∑≤ËÆøÈóÆ{self.stats['black_objects_visited']}‰∏™")
            self.logger.info(f"   Êô∫ËÉΩÂÜ≥Á≠ñ: ÂêëÈáèÂú∫{self.stats['vector_field_updates']}Ê¨° "
                            f"| ÁΩëÊ†ºÊõ¥Êñ∞{self.stats['grid_updates']}Ê¨°")
            self.logger.info(f"   Êé¢Á¥¢ÁΩëÊ†º: ÂâçÊ≤ø{len(self.exploration_grid.frontier_cells)}‰∏™")
            self.logger.info(f"   Á≥ªÁªüÁªüËÆ°: ÂºÇÂ∏∏{self.stats['exceptions_caught']}Ê¨° "
                            f"| Áä∂ÊÄÅÂàáÊç¢{self.stats['state_changes']}Ê¨°")
            self.logger.info(f"   Êï∞ÊçÆËÆ∞ÂΩï: {self.stats['data_points_recorded']}‰∏™Êï∞ÊçÆÁÇπ")
            self.logger.info(f"   ÊÄßËÉΩÁªüËÆ°: Âπ≥ÂùáÂæ™ÁéØ{self.stats['average_loop_time']*1000:.1f}ms "
                            f"| ÊúÄÂ§ß{self.stats['max_loop_time']*1000:.1f}ms "
                            f"| ÊúÄÂ∞è{self.stats['min_loop_time']*1000:.1f}ms")
            if self.stats['manual_control_time'] > 0:
                self.logger.info(f"   ÊâãÂä®ÊéßÂà∂: {self.stats['manual_control_time']:.1f}Áßí")
        except:
            self.logger.info("Áä∂ÊÄÅÊä•Âëä: Êó†Ê≥ïËé∑ÂèñÊó†‰∫∫Êú∫Áä∂ÊÄÅ")

    def _finish_mission(self):
        self.logger.info("=" * 60)
        self.logger.info("Êé¢Á¥¢‰ªªÂä°ÂÆåÊàêÔºåÂºÄÂßãËøîËà™Á®ãÂ∫è")
        self.logger.info("=" * 60)

        self.change_state(FlightState.RETURNING)

        try:
            self.logger.info("‚Ü©Ô∏è ËøîÂõûËµ∑ÂßãÂå∫Âüü...")
            self.client.moveToPositionAsync(0, 0, -10, 4, vehicle_name=self.drone_name).join()
            time.sleep(2)

            self.logger.info("üõ¨ ÈôçËêΩ‰∏≠...")
            self.change_state(FlightState.LANDING)
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(3)

        except Exception as e:
            self.logger.error(f"‚ùå ÈôçËêΩËøáÁ®ã‰∏≠Âá∫Áé∞ÂºÇÂ∏∏: {e}")

        finally:
            self._cleanup_system()

            self._generate_summary_report()

    def _cleanup_system(self):
        self.logger.info("üßπ Ê∏ÖÁêÜÁ≥ªÁªüËµÑÊ∫ê...")

        try:
            self.client.armDisarm(False, vehicle_name=self.drone_name)
            self.client.enableApiControl(False, vehicle_name=self.drone_name)
            self.logger.info("‚úÖ Êó†‰∫∫Êú∫ÊéßÂà∂Â∑≤ÂÆâÂÖ®ÈáäÊîæ")
        except:
            self.logger.warning("‚ö†Ô∏è ÈáäÊîæÊéßÂà∂Êó∂Âá∫Áé∞ÂºÇÂ∏∏")

        if self.front_window:
            self.front_window.stop()
            self.logger.info("‚úÖ ÂâçËßÜÁ™óÂè£Â∑≤ÂÖ≥Èó≠")

        if self.info_window:
            self.info_window.stop()
            self.logger.info("‚úÖ ‰ø°ÊÅØÁ™óÂè£Â∑≤ÂÖ≥Èó≠")

        if self.data_logger:
            self.logger.info("üíæ Ê≠£Âú®‰øùÂ≠òÈ£ûË°åÊï∞ÊçÆ...")
            self.data_logger.save_json_data()

            if config.PERFORMANCE['SAVE_PERFORMANCE_REPORT']:
                performance_report = self.data_logger.generate_performance_report()
                self.logger.info(performance_report)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_filename = f"performance_report_{timestamp}.txt"
                with open(report_filename, 'w', encoding='utf-8') as f:
                    f.write(performance_report)
                self.logger.info(f"üìÑ ÊÄßËÉΩÊä•ÂëäÂ∑≤‰øùÂ≠òËá≥: {report_filename}")

    def _generate_summary_report(self):
        total_time = time.time() - self.start_time

        self.logger.info("\n" + "=" * 60)
        self.logger.info("üèÅ ‰ªªÂä°ÊÄªÁªìÊä•Âëä")
        self.logger.info("=" * 60)
        self.logger.info(f"   ÊÄªËøêË°åÊó∂Èó¥: {total_time:.1f}Áßí")
        self.logger.info(f"   ÊÄªÂæ™ÁéØÊ¨°Êï∞: {self.loop_count}")
        if total_time > 0:
            self.logger.info(f"   Âπ≥ÂùáÂæ™ÁéØÈ¢ëÁéá: {self.loop_count/total_time:.1f} Hz")
        self.logger.info(f"   Êé¢Á¥¢Ëà™ÁÇπÊï∞Èáè: {len(self.visited_positions)}")
        self.logger.info(f"   Áä∂ÊÄÅÂàáÊç¢Ê¨°Êï∞: {self.stats['state_changes']}")
        self.logger.info(f"   Ê£ÄÊµãÂà∞ÈöúÁ¢çÊ¨°Êï∞: {self.stats['obstacles_detected']}")
        self.logger.info(f"   Á∫¢Ëâ≤Áâ©‰ΩìÊ£ÄÊµã: {self.stats['red_objects_detected']}‰∏™")
        self.logger.info(f"   Á∫¢Ëâ≤Áâ©‰ΩìËÆøÈóÆ: {self.stats['red_objects_visited']}‰∏™")
        self.logger.info(f"   ËìùËâ≤Áâ©‰ΩìÊ£ÄÊµã: {self.stats['blue_objects_detected']}‰∏™")
        self.logger.info(f"   ËìùËâ≤Áâ©‰ΩìËÆøÈóÆ: {self.stats['blue_objects_visited']}‰∏™")
        self.logger.info(f"   ÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµã: {self.stats['black_objects_detected']}‰∏™")
        self.logger.info(f"   ÈªëËâ≤Áâ©‰ΩìËÆøÈóÆ: {self.stats['black_objects_visited']}‰∏™")
        self.logger.info(f"   ÂêëÈáèÂú∫ËÆ°ÁÆóÊ¨°Êï∞: {self.stats['vector_field_updates']}")
        self.logger.info(f"   ÁΩëÊ†ºÊõ¥Êñ∞Ê¨°Êï∞: {self.stats['grid_updates']}")
        self.logger.info(f"   Êé¢Á¥¢ÂâçÊ≤øÊï∞Èáè: {len(self.exploration_grid.frontier_cells)}")
        self.logger.info(f"   ÂâçËßÜÂõæÂÉèÊõ¥Êñ∞Ê¨°Êï∞: {self.stats['front_image_updates']}")
        self.logger.info(f"   Êï∞ÊçÆËÆ∞ÂΩïÁÇπÊï∞: {self.stats['data_points_recorded']}")
        self.logger.info(f"   ÊâãÂä®ÊéßÂà∂Êó∂Èó¥: {self.stats['manual_control_time']:.1f}Áßí")
        self.logger.info(f"   ÊçïËé∑ÁöÑÂºÇÂ∏∏Êï∞: {self.stats['exceptions_caught']}")
        self.logger.info(f"   ÈáçËøûÂ∞ùËØïÊ¨°Êï∞: {self.reconnect_attempts}")
        self.logger.info(f"   Âπ≥ÂùáÂæ™ÁéØÊó∂Èó¥: {self.stats['average_loop_time']*1000:.1f}ms")
        self.logger.info(f"   ÊúÄÂ§ßÂæ™ÁéØÊó∂Èó¥: {self.stats['max_loop_time']*1000:.1f}ms")
        self.logger.info(f"   ÊúÄÂ∞èÂæ™ÁéØÊó∂Èó¥: {self.stats['min_loop_time']*1000:.1f}ms")

        try:
            report_filename = f"mission_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write("AirSimNH Êó†‰∫∫Êú∫‰ªªÂä°Êä•Âëä (Êô∫ËÉΩÂÜ≥Á≠ñÂ¢ûÂº∫Áâà - ÂèåÁ™óÂè£ÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµãÁâà)\n")
                f.write("=" * 50 + "\n")
                f.write(f"ÁîüÊàêÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ÊÄªËøêË°åÊó∂Èó¥: {total_time:.1f}Áßí\n")
                f.write(f"ÊÄªÂæ™ÁéØÊ¨°Êï∞: {self.loop_count}\n")
                f.write(f"Êé¢Á¥¢Ëà™ÁÇπÊï∞Èáè: {len(self.visited_positions)}\n")
                f.write(f"Áä∂ÊÄÅÂàáÊç¢Ê¨°Êï∞: {self.stats['state_changes']}\n")
                f.write(f"ÂêëÈáèÂú∫ËÆ°ÁÆóÊ¨°Êï∞: {self.stats['vector_field_updates']}\n")
                f.write(f"ÁΩëÊ†ºÊõ¥Êñ∞Ê¨°Êï∞: {self.stats['grid_updates']}\n")
                f.write(f"Êé¢Á¥¢ÂâçÊ≤øÊï∞Èáè: {len(self.exploration_grid.frontier_cells)}\n")
                f.write(f"Êï∞ÊçÆËÆ∞ÂΩïÁÇπÊï∞: {self.stats['data_points_recorded']}\n")
                f.write(f"ÊâãÂä®ÊéßÂà∂Êó∂Èó¥: {self.stats['manual_control_time']:.1f}Áßí\n")
                f.write(f"Á∫¢Ëâ≤Áâ©‰ΩìÊ£ÄÊµãÊÄªÊï∞: {self.stats['red_objects_detected']}‰∏™\n")
                f.write(f"Á∫¢Ëâ≤Áâ©‰ΩìÂ∑≤ËÆøÈóÆÊï∞: {self.stats['red_objects_visited']}‰∏™\n")
                f.write(f"ËìùËâ≤Áâ©‰ΩìÊ£ÄÊµãÊÄªÊï∞: {self.stats['blue_objects_detected']}‰∏™\n")
                f.write(f"ËìùËâ≤Áâ©‰ΩìÂ∑≤ËÆøÈóÆÊï∞: {self.stats['blue_objects_visited']}‰∏™\n")
                f.write(f"ÈªëËâ≤Áâ©‰ΩìÊ£ÄÊµãÊÄªÊï∞: {self.stats['black_objects_detected']}‰∏™\n")
                f.write(f"ÈªëËâ≤Áâ©‰ΩìÂ∑≤ËÆøÈóÆÊï∞: {self.stats['black_objects_visited']}‰∏™\n")
                f.write(f"ÂºÇÂ∏∏ÊçïËé∑Ê¨°Êï∞: {self.stats['exceptions_caught']}\n")
                f.write(f"ÂâçËßÜÂõæÂÉèÊõ¥Êñ∞Ê¨°Êï∞: {self.stats['front_image_updates']}\n")
                f.write(f"Âπ≥ÂùáÂæ™ÁéØÊó∂Èó¥: {self.stats['average_loop_time']*1000:.1f}ms\n")
                f.write(f"ÊúÄÂ§ßÂæ™ÁéØÊó∂Èó¥: {self.stats['max_loop_time']*1000:.1f}ms\n")
                f.write(f"ÊúÄÂ∞èÂæ™ÁéØÊó∂Èó¥: {self.stats['min_loop_time']*1000:.1f}ms\n")
                f.write("=" * 50 + "\n")
                f.write("Êô∫ËÉΩÂÜ≥Á≠ñÈÖçÁΩÆ:\n")
                for key, value in config.INTELLIGENT_DECISION.items():
                    f.write(f"  {key}: {value}\n")
                f.write("=" * 50 + "\n")
                f.write("È£ûË°åËà™ÁÇπËÆ∞ÂΩï:\n")
                for i, pos in enumerate(self.visited_positions[:20]):
                    f.write(f"  Ëà™ÁÇπ{i+1}: ({pos[0]:.1f}, {pos[1]:.1f}, {pos[2]:.1f})\n")
                if len(self.visited_positions) > 20:
                    f.write(f"  ... ËøòÊúâ{len(self.visited_positions)-20}‰∏™Ëà™ÁÇπ\n")
                f.write("=" * 50 + "\n")
                f.write("Êï∞ÊçÆËÆ∞ÂΩï‰ø°ÊÅØ:\n")
                if self.data_logger and config.DATA_RECORDING['ENABLED']:
                    f.write(f"  CSVÊñá‰ª∂: {self.data_logger.csv_filename}\n")
                    f.write(f"  JSONÊñá‰ª∂: {self.data_logger.json_filename}\n")
                else:
                    f.write("  Êï∞ÊçÆËÆ∞ÂΩïÊú™ÂêØÁî®\n")
            self.logger.info(f"üìÑ ËØ¶ÁªÜÊä•ÂëäÂ∑≤‰øùÂ≠òËá≥: {report_filename}")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Êó†Ê≥ï‰øùÂ≠òÊä•ÂëäÊñá‰ª∂: {e}")

    def emergency_stop(self):
        if self.emergency_flag:
            return

        self.logger.error("\nüÜò Á¥ßÊÄ•ÂÅúÊ≠¢Á®ãÂ∫èÂêØÂä®!")
        self.emergency_flag = True

        self.change_state(FlightState.EMERGENCY)

        try:
            self.client.hoverAsync(vehicle_name=self.drone_name).join()
            time.sleep(1)
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(2)
            self.logger.info("‚úÖ Á¥ßÊÄ•ÈôçËêΩÊåá‰ª§Â∑≤ÂèëÈÄÅ")
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è Á¥ßÊÄ•ÈôçËêΩÂºÇÂ∏∏: {e}")

        if self.front_window:
            self.front_window.stop()

        if self.info_window:
            self.info_window.stop()

        self._cleanup_system()


# ==================== ‰∏ªÁ®ãÂ∫èÂÖ•Âè£ ====================

def main():
    print("=" * 70)
    print("AirSimNH Êó†‰∫∫Êú∫ÊÑüÁü•Êé¢Á¥¢Á≥ªÁªü - Êô∫ËÉΩÂÜ≥Á≠ñÂ¢ûÂº∫ÁâàÔºàÂèåÁ™óÂè£ÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµãÁâàÔºâ")
    print(f"ÂêØÂä®Êó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ÈÖçÁΩÆÁä∂ÊÄÅ: {'Â∑≤Âä†ËΩΩ' if CONFIG_LOADED else '‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ'}")
    print(f"Êó•ÂøóÁ∫ßÂà´: {config.SYSTEM['LOG_LEVEL']}")
    print(f"Êé¢Á¥¢Êó∂Èó¥: {config.EXPLORATION['TOTAL_TIME']}Áßí")
    print("=" * 70)
    print("Êô∫ËÉΩÂÜ≥Á≠ñÁâπÊÄß:")
    print("  ‚Ä¢ ÂêëÈáèÂú∫ÈÅøÈöúÁÆóÊ≥ï (VFH)")
    print("  ‚Ä¢ Âü∫‰∫éÁΩëÊ†ºÁöÑ‰ø°ÊÅØÂ¢ûÁõäÊé¢Á¥¢")
    print("  ‚Ä¢ PIDÂπ≥ÊªëÈ£ûË°åÊéßÂà∂")
    print("  ‚Ä¢ Ëá™ÈÄÇÂ∫îÈÄüÂ∫¶Ë∞ÉÊï¥")
    print("  ‚Ä¢ ÊÄßËÉΩÁõëÊéß‰∏éÊï∞ÊçÆÈó≠ÁéØ")
    print("  ‚Ä¢ Á∫¢Ëâ≤‰∏éËìùËâ≤Áâ©‰ΩìÊ£ÄÊµã‰∏éËÆ∞ÂΩï")
    print("=" * 70)
    print("ÊòæÁ§∫Á≥ªÁªü:")
    print("  ‚Ä¢ ÂèåÁ™óÂè£Ê®°Âºè: ÂâçËßÜÁ™óÂè£ + ‰ø°ÊÅØÁ™óÂè£")
    print("  ‚Ä¢ ÂâçËßÜÁ™óÂè£: ÊëÑÂÉèÂ§¥ÁîªÈù¢„ÄÅÊâãÂä®ÊéßÂà∂")
    print("  ‚Ä¢ ‰ø°ÊÅØÁ™óÂè£: Á≥ªÁªüÁä∂ÊÄÅ„ÄÅÊé¢Á¥¢ÁΩëÊ†º„ÄÅÁâ©‰ΩìÁªüËÆ°")
    print("=" * 70)
    print("Êï∞ÊçÆËÆ∞ÂΩï:")
    print(f"  ‚Ä¢ CSVÊ†ºÂºè: {config.DATA_RECORDING.get('SAVE_TO_CSV', False)}")
    print(f"  ‚Ä¢ JSONÊ†ºÂºè: {config.DATA_RECORDING.get('SAVE_TO_JSON', False)}")
    print(f"  ‚Ä¢ ÊÄßËÉΩÁõëÊéß: {config.DATA_RECORDING.get('PERFORMANCE_MONITORING', False)}")
    print(f"  ‚Ä¢ Á∫¢Ëâ≤Áâ©‰ΩìËÆ∞ÂΩï: {config.DATA_RECORDING.get('RECORD_RED_OBJECTS', False)}")
    print(f"  ‚Ä¢ ËìùËâ≤Áâ©‰ΩìËÆ∞ÂΩï: {config.DATA_RECORDING.get('RECORD_BLUE_OBJECTS', False)}")
    print("=" * 70)

    print("\nËØ∑ÈÄâÊã©ËøêË°åÊ®°Âºè:")
    print("  1. Êô∫ËÉΩÊé¢Á¥¢Ê®°Âºè (AIËá™‰∏ªÂÜ≥Á≠ñÔºåÂåÖÂê´ÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµã)")
    print("  2. ÊâãÂä®ÊéßÂà∂Ê®°Âºè (ÈîÆÁõòÊéßÂà∂)")
    print("  3. Ê∑∑ÂêàÊ®°Âºè (ÂÖàËá™Âä®Êé¢Á¥¢ÔºåÂêéÂèØÂàáÊç¢)")
    print("=" * 50)

    mode_choice = input("ËØ∑ËæìÂÖ•ÈÄâÊã© (1/2/3): ").strip()

    explorer = None
    try:
        explorer = PerceptiveExplorer(drone_name="")

        def signal_handler(sig, frame):
            print("\n‚ö†Ô∏è Áî®Êà∑‰∏≠Êñ≠ÔºåÊ≠£Âú®ÂÆâÂÖ®ÂÅúÊ≠¢...")
            if explorer:
                explorer.emergency_stop()
            sys.exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        if mode_choice == '1':
            print("\n" + "="*50)
            print("ÂêØÂä®Êô∫ËÉΩÊé¢Á¥¢Ê®°ÂºèÔºàÂê´ÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµãÔºâ")
            print("="*50)
            print("Ê≥®ÊÑèÔºöÂ∞ÜÊâìÂºÄ‰∏§‰∏™Á™óÂè£:")
            print("  1. ÂâçËßÜÁ™óÂè£ - ÊòæÁ§∫ÊëÑÂÉèÂ§¥ÁîªÈù¢")
            print("  2. ‰ø°ÊÅØÁ™óÂè£ - ÊòæÁ§∫Á≥ªÁªüÁä∂ÊÄÅÂíåÊé¢Á¥¢‰ø°ÊÅØ")
            print("="*50)
            explorer.run_perception_loop()

        elif mode_choice == '2':
            print("\n" + "="*50)
            print("ÂêØÂä®ÊâãÂä®ÊéßÂà∂Ê®°Âºè")
            print("="*50)

            print("Ê≠£Âú®Ëµ∑È£û...")
            explorer.client.takeoffAsync(vehicle_name="").join()
            time.sleep(2)
            explorer.client.moveToZAsync(-10, 3, vehicle_name="").join()
            time.sleep(2)
            print("Ëµ∑È£ûÂÆåÊàêÔºåÂèØ‰ª•ÂºÄÂßãÊâãÂä®ÊéßÂà∂")
            print("ËØ∑ÂàáÊç¢Âà∞Êó†‰∫∫Êú∫ÂâçËßÜÁ™óÂè£Ôºå‰ΩøÁî®WSADÈîÆÊéßÂà∂")

            explorer.run_manual_control()

        elif mode_choice == '3':
            print("\n" + "="*50)
            print("ÂêØÂä®Ê∑∑ÂêàÊ®°Âºè")
            print("="*50)

            explorer.logger.info("üîç ÂºÄÂßãÊô∫ËÉΩÊé¢Á¥¢ÔºàÂê´ÂèåËâ≤Áâ©‰ΩìÊ£ÄÊµãÔºâ...")
            original_time = config.EXPLORATION['TOTAL_TIME']
            explorer.exploration_time = min(60, original_time)

            explorer.run_perception_loop()

            if not explorer.emergency_flag:
                print("\n" + "="*50)
                print("Êô∫ËÉΩÊé¢Á¥¢Èò∂ÊÆµÁªìÊùü")
                print(f"Ê£ÄÊµãÂà∞Á∫¢Ëâ≤Áâ©‰Ωì: {explorer.stats['red_objects_detected']}‰∏™")
                print(f"Ê£ÄÊµãÂà∞ËìùËâ≤Áâ©‰Ωì: {explorer.stats['blue_objects_detected']}‰∏™")
                print(f"Ê£ÄÊµãÂà∞ÈªëËâ≤Áâ©‰Ωì: {explorer.stats['black_objects_detected']}‰∏™")
                print("ËØ∑ÈÄâÊã©‰∏ã‰∏ÄÊ≠•:")
                print("  1. ËøõÂÖ•ÊâãÂä®ÊéßÂà∂Ê®°Âºè")
                print("  2. ÁªßÁª≠Êô∫ËÉΩÊé¢Á¥¢")
                print("  3. ÁªìÊùü‰ªªÂä°ËøîËà™")
                print("="*50)

                next_choice = input("ËØ∑ËæìÂÖ•ÈÄâÊã© (1/2/3): ").strip()

                if next_choice == '1':
                    explorer.run_manual_control()
                elif next_choice == '2':
                    explorer.exploration_time = original_time - 60
                    if explorer.exploration_time > 10:
                        explorer.run_perception_loop()
                    else:
                        explorer.logger.info("‚è∞ Ââ©‰ΩôÊó∂Èó¥‰∏çË∂≥ÔºåÂºÄÂßãËøîËà™")
                        explorer._finish_mission()
                else:
                    explorer._finish_mission()

        else:
            print("‚ùå Êó†ÊïàÁöÑÈÄâÊã©ÔºåÁ®ãÂ∫èÈÄÄÂá∫")
            if explorer:
                explorer._cleanup_system()

    except Exception as e:
        print(f"\n‚ùå Á®ãÂ∫èÂêØÂä®ÂºÇÂ∏∏: {e}")
        traceback.print_exc()

        try:
            if explorer and explorer.client:
                explorer.client.landAsync().join()
                explorer.client.armDisarm(False)
                explorer.client.enableApiControl(False)
        except:
            pass


if __name__ == "__main__":
    main()