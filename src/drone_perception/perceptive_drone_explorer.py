"""
AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢æ— äººæœº
æ ¸å¿ƒï¼šè§†è§‰æ„ŸçŸ¥ â†’ è¯­ä¹‰ç†è§£ â†’ æ™ºèƒ½å†³ç­– â†’ å®‰å…¨æ‰§è¡Œ
"""

import airsim
import time
import numpy as np
import cv2
import math
from collections import deque
from dataclasses import dataclass
from enum import Enum
import threading
from typing import Tuple, List, Optional


class FlightState(Enum):
    """æ— äººæœºçŠ¶æ€æšä¸¾"""
    TAKEOFF = "èµ·é£"
    HOVERING = "æ‚¬åœè§‚æµ‹"
    EXPLORING = "ä¸»åŠ¨æ¢ç´¢"
    AVOIDING = "é¿éšœæœºåŠ¨"
    LANDING = "é™è½"
    EMERGENCY = "ç´§æ€¥çŠ¶æ€"


@dataclass
class PerceptionResult:
    """æ„ŸçŸ¥ç»“æœæ•°æ®ç»“æ„"""
    has_obstacle: bool = False
    obstacle_distance: float = 100.0
    obstacle_direction: float = 0.0  # éšœç¢ç‰©ç›¸å¯¹æ–¹å‘ï¼ˆå¼§åº¦ï¼‰
    terrain_slope: float = 0.0  # åœ°å½¢å¡åº¦
    open_space_score: float = 0.0  # å¼€é˜”åº¦è¯„åˆ† (0-1)
    recommended_height: float = -15.0  # æ¨èé£è¡Œé«˜åº¦
    safe_directions: List[float] = None  # å®‰å…¨æ–¹å‘åˆ—è¡¨

    def __post_init__(self):
        if self.safe_directions is None:
            self.safe_directions = []


class PerceptiveExplorer:
    """åŸºäºæ„ŸçŸ¥çš„è‡ªä¸»æ¢ç´¢æ— äººæœº"""

    def __init__(self, drone_name=""):
        print("=" * 60)
        print("AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢ç³»ç»Ÿ")
        print("=" * 60)

        # åˆå§‹åŒ–AirSimè¿æ¥
        self.client = airsim.MultirotorClient()
        self.client.confirmConnection()
        self.drone_name = drone_name

        # å¯ç”¨APIæ§åˆ¶
        self.client.enableApiControl(True, vehicle_name=drone_name)
        self.client.armDisarm(True, vehicle_name=drone_name)

        # çŠ¶æ€ç®¡ç†
        self.state = FlightState.TAKEOFF
        self.state_history = deque(maxlen=20)
        self.emergency_flag = False

        # æ„ŸçŸ¥å‚æ•°
        self.depth_threshold_near = 5.0  # è¿‘è·ç¦»è­¦æŠ¥é˜ˆå€¼(ç±³)
        self.depth_threshold_safe = 10.0  # å®‰å…¨è·ç¦»é˜ˆå€¼(ç±³)
        self.min_ground_clearance = 2.0  # æœ€å°ç¦»åœ°é—´éš™(ç±³)
        self.max_pitch_angle = math.radians(15)  # æœ€å¤§å…è®¸ä¿¯ä»°è§’

        # æ¢ç´¢å‚æ•°
        self.exploration_time = 180  # æ€»æ¢ç´¢æ—¶é—´(ç§’)
        self.preferred_speed = 3.0  # ä¼˜é€‰é€Ÿåº¦(m/s)
        self.max_altitude = -30  # æœ€å¤§æµ·æ‹”(ç±³)
        self.min_altitude = -8  # æœ€å°æµ·æ‹”(ç±³)

        # è®°å¿†ç³»ç»Ÿ
        self.visited_positions = deque(maxlen=100)
        self.obstacle_map = {}  # éšœç¢ç‰©ä½ç½®è®°å¿†
        self.traversability_map = {}  # åœ°å½¢å¯é€šè¡Œæ€§è®°å¿†

        # æ€§èƒ½ç›‘æ§
        self.perception_fps = 0
        self.decision_fps = 0
        self.start_time = time.time()

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
        print(f"   é¢„è®¡æ¢ç´¢æ—¶é•¿: {self.exploration_time}ç§’")

    def get_depth_perception(self) -> PerceptionResult:
        """è·å–å¹¶åˆ†ææ·±åº¦å›¾åƒï¼Œç†è§£ç¯å¢ƒ"""
        result = PerceptionResult()

        try:
            # è¯·æ±‚æ·±åº¦å›¾åƒï¼ˆä½¿ç”¨æ­£ç¡®çš„DepthPlanarç±»å‹ï¼‰
            responses = self.client.simGetImages([
                airsim.ImageRequest(
                    "0",
                    airsim.ImageType.DepthPlanar,
                    pixels_as_float=True,
                    compress=False
                )
            ])

            if not responses or not responses[0]:
                print("âš  æ·±åº¦å›¾åƒè·å–å¤±è´¥")
                return result

            # è½¬æ¢æ·±åº¦æ•°æ®ä¸ºnumpyæ•°ç»„
            depth_img = responses[0]
            depth_array = np.array(depth_img.image_data_float, dtype=np.float32)
            depth_array = depth_array.reshape(depth_img.height, depth_img.width)

            # åˆ†ææ·±åº¦å›¾åƒçš„ä¸åŒåŒºåŸŸ
            h, w = depth_array.shape

            # 1. å‰æ–¹è¿‘è·ç¦»åŒºåŸŸï¼ˆç´§æ€¥é¿éšœï¼‰
            front_near = depth_array[h // 2:, w // 3:2 * w // 3]
            min_front_distance = np.min(front_near) if front_near.size > 0 else 100

            # 2. å¤šæ–¹å‘æ‰‡å½¢æ‰«æ
            directions = []
            scan_angles = [-45, -30, -15, 0, 15, 30, 45]  # åº¦

            for angle_deg in scan_angles:
                angle_rad = math.radians(angle_deg)
                # è®¡ç®—å¯¹åº”å›¾åƒåˆ—
                col = int(w / 2 + (w / 2) * math.tan(angle_rad) * 0.5)
                col = max(0, min(w - 1, col))

                # åˆ†æè¯¥åˆ—çš„æ·±åº¦
                col_data = depth_array[h // 2:, col]
                if col_data.size > 0:
                    dir_distance = np.percentile(col_data, 25)  # ä½¿ç”¨25%åˆ†ä½æ•°ï¼ˆè¾ƒä¿å®ˆï¼‰
                    directions.append((angle_rad, dir_distance))

                    if dir_distance > self.depth_threshold_safe:
                        result.safe_directions.append(angle_rad)

            # 3. åœ°å½¢åˆ†æï¼ˆé€šè¿‡æ·±åº¦æ¢¯åº¦ä¼°è®¡å¡åº¦ï¼‰
            ground_region = depth_array[3 * h // 4:, :]
            if ground_region.size > 10:
                row_variances = np.var(ground_region, axis=1)
                result.terrain_slope = np.mean(row_variances) * 100

            # 4. å¼€é˜”åº¦è¯„åˆ†ï¼ˆåŸºäºæœ‰æ•ˆè·ç¦»åƒç´ æ¯”ä¾‹ï¼‰
            open_pixels = np.sum(depth_array[h // 2:, :] > self.depth_threshold_safe)
            total_pixels = depth_array[h // 2:, :].size
            result.open_space_score = open_pixels / total_pixels if total_pixels > 0 else 0

            # æ•´åˆæ„ŸçŸ¥ç»“æœ
            result.has_obstacle = min_front_distance < self.depth_threshold_near
            result.obstacle_distance = min_front_distance

            if directions:
                # æ‰¾å‡ºæœ€è¿‘éšœç¢ç‰©çš„æ–¹å‘
                closest_dir = min(directions, key=lambda x: x[1])
                result.obstacle_direction = closest_dir[0]

            # æ ¹æ®æ„ŸçŸ¥åŠ¨æ€è°ƒæ•´æ¨èé«˜åº¦
            if result.terrain_slope > 5:
                result.recommended_height = -20  # é™¡å³­åœ°å½¢é£é«˜äº›
            elif result.open_space_score > 0.7:
                result.recommended_height = -12  # å¼€é˜”åœ°å¸¦å¯ä»¥é£ä½äº›
            else:
                result.recommended_height = -15  # é»˜è®¤é«˜åº¦

            # æ›´æ–°æ„ŸçŸ¥FPS
            self.perception_fps = 1 / (time.time() - self.perception_start)

        except Exception as e:
            print(f"âŒ æ·±åº¦æ„ŸçŸ¥å¼‚å¸¸: {e}")

        return result

    def get_visual_perception(self):
        """è·å–è§†è§‰å›¾åƒç”¨äºé«˜çº§æ„ŸçŸ¥ï¼ˆå¯é€‰ï¼‰"""
        try:
            responses = self.client.simGetImages([
                airsim.ImageRequest("0", airsim.ImageType.Scene, False, False)
            ])

            if responses and responses[0]:
                # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                img_data = responses[0].image_data_uint8
                img_array = np.frombuffer(img_data, dtype=np.uint8)
                img = img_array.reshape(responses[0].height, responses[0].width, 3)

                # ç®€å•é¢œè‰²åˆ†æï¼ˆç¤ºä¾‹ï¼šå¯»æ‰¾ç»¿è‰²æ¤è¢«åŒºåŸŸï¼‰
                hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
                green_mask = cv2.inRange(hsv, (40, 40, 40), (80, 255, 255))
                green_ratio = np.sum(green_mask > 0) / green_mask.size

                return img, green_ratio
        except:
            pass

        return None, 0

    def make_intelligent_decision(self, perception: PerceptionResult) -> Tuple[float, float, float, float]:
        """åŸºäºæ„ŸçŸ¥ç»“æœåšå‡ºæ™ºèƒ½å†³ç­–"""

        # è·å–å½“å‰ä½ç½®å’ŒçŠ¶æ€
        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
        pos = state.kinematics_estimated.position
        vel = state.kinematics_estimated.linear_velocity

        # åŸºç¡€å†³ç­–ï¼šé€Ÿåº¦ã€åèˆªã€é«˜åº¦
        target_vx, target_vy, target_z, target_yaw = 0.0, 0.0, perception.recommended_height, 0.0

        # çŠ¶æ€æœºå†³ç­–é€»è¾‘
        if self.state == FlightState.TAKEOFF:
            target_z = -10  # èµ·é£åˆ°10ç±³
            if pos.z_val < -9.5:
                self.change_state(FlightState.HOVERING)

        elif self.state == FlightState.HOVERING:
            # æ‚¬åœè§‚å¯Ÿï¼Œç¼“æ…¢æ—‹è½¬æ‰«æ
            target_yaw = (time.time() % 10) * 0.2  # ç¼“æ…¢æ—‹è½¬

            if len(perception.safe_directions) > 0:
                self.change_state(FlightState.EXPLORING)

        elif self.state == FlightState.EXPLORING:
            # ä¸»åŠ¨æ¢ç´¢æ¨¡å¼
            if perception.has_obstacle:
                self.change_state(FlightState.AVOIDING)
                # ç´§æ€¥åˆ¶åŠ¨
                target_vx, target_vy = -vel.x_val, -vel.y_val
            else:
                # é€‰æ‹©æœ€ä½³æ¢ç´¢æ–¹å‘
                if perception.safe_directions:
                    # ä¼˜å…ˆé€‰æ‹©ä¸å½“å‰èˆªå‘ç›¸å·®45-90åº¦çš„æ–°æ–¹å‘ï¼ˆé¿å…æ¥å›æ‘†åŠ¨ï¼‰
                    current_yaw = airsim.to_eularian_angles(
                        state.kinematics_estimated.orientation
                    )[2]

                    # è¿‡æ»¤å‡ºä¸å½“å‰æ–¹å‘ä¸åŒçš„å®‰å…¨æ–¹å‘
                    diverse_dirs = [
                        d for d in perception.safe_directions
                        if abs(d - current_yaw) > math.radians(45)
                    ]

                    if diverse_dirs:
                        best_dir = diverse_dirs[0]
                    else:
                        best_dir = perception.safe_directions[0]

                    # è®¾ç½®å‰è¿›é€Ÿåº¦
                    speed_factor = min(1.0, perception.open_space_score * 1.5)
                    target_vx = self.preferred_speed * speed_factor * math.cos(best_dir)
                    target_vy = self.preferred_speed * speed_factor * math.sin(best_dir)
                else:
                    # æ²¡æœ‰å®‰å…¨æ–¹å‘ï¼Œçˆ¬å‡
                    target_z = pos.z_val - 5
                    self.change_state(FlightState.AVOIDING)

        elif self.state == FlightState.AVOIDING:
            # é¿éšœæœºåŠ¨
            if perception.has_obstacle:
                # æ ¹æ®éšœç¢ç‰©æ–¹å‘å†³å®šé¿éšœç­–ç•¥
                if abs(perception.obstacle_direction) < math.radians(30):
                    # å‰æ–¹éšœç¢ç‰©ï¼šçˆ¬å‡
                    target_z = pos.z_val - 3
                    target_vx, target_vy = 0, 0
                else:
                    # ä¾§æ–¹éšœç¢ç‰©ï¼šå‘åæ–¹å‘å¹³ç§»
                    avoid_dir = perception.obstacle_direction + math.pi
                    target_vx = 1.5 * math.cos(avoid_dir)
                    target_vy = 1.5 * math.sin(avoid_dir)
            else:
                # éšœç¢ç‰©æ¸…é™¤ï¼Œè¿”å›æ¢ç´¢
                self.change_state(FlightState.HOVERING)
                time.sleep(1)  # é¿éšœåæš‚åœè§‚å¯Ÿ

        elif self.state == FlightState.EMERGENCY:
            # ç´§æ€¥çŠ¶æ€ï¼šæ‚¬åœå¹¶å‡†å¤‡é™è½
            target_vx, target_vy, target_yaw = 0, 0, 0
            target_z = max(pos.z_val, -20)  # é™åˆ¶çˆ¬å‡

        # ç¡®ä¿é«˜åº¦åœ¨å®‰å…¨èŒƒå›´å†…
        target_z = max(self.max_altitude, min(self.min_altitude, target_z))

        return target_vx, target_vy, target_z, target_yaw

    def change_state(self, new_state: FlightState):
        """çŠ¶æ€è½¬æ¢"""
        if self.state != new_state:
            print(f"ğŸ”„ çŠ¶æ€è½¬æ¢: {self.state.value} â†’ {new_state.value}")
            self.state = new_state
            self.state_history.append((time.time(), new_state))

    def run_perception_loop(self):
        """ä¸»æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶å¾ªç¯"""
        print("\n" + "=" * 60)
        print("å¯åŠ¨æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶å¾ªç¯")
        print("=" * 60)

        # èµ·é£
        print("ğŸš€ èµ·é£ä¸­...")
        self.client.takeoffAsync(vehicle_name=self.drone_name).join()
        time.sleep(3)
        self.change_state(FlightState.HOVERING)

        # ä¸»å¾ªç¯
        loop_count = 0
        exploration_start = time.time()

        while time.time() - exploration_start < self.exploration_time and not self.emergency_flag:
            loop_start = time.time()
            loop_count += 1

            # 1. æ„ŸçŸ¥é˜¶æ®µ
            self.perception_start = time.time()
            perception = self.get_depth_perception()
            # visual_img, green_ratio = self.get_visual_perception()  # å¯é€‰

            # 2. å†³ç­–é˜¶æ®µ
            decision = self.make_intelligent_decision(perception)

            # 3. æ§åˆ¶æ‰§è¡Œé˜¶æ®µ
            target_vx, target_vy, target_z, target_yaw = decision

            # ä½¿ç”¨é€Ÿåº¦æ§åˆ¶ï¼ˆæ›´çµæ´»ï¼‰æˆ–ä½ç½®æ§åˆ¶ï¼ˆæ›´ç²¾ç¡®ï¼‰
            use_velocity_control = self.state in [FlightState.EXPLORING, FlightState.AVOIDING]

            if use_velocity_control:
                self.client.moveByVelocityZAsync(
                    target_vx, target_vy, target_z, 0.5,  # æŒç»­æ—¶é—´0.5ç§’
                    vehicle_name=self.drone_name
                )
            else:
                self.client.moveToPositionAsync(
                    0, 0, target_z, 2,  # ç›¸å¯¹å½“å‰ä½ç½®ç§»åŠ¨
                    vehicle_name=self.drone_name
                )

            # è®°å½•å½“å‰ä½ç½®
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            self.visited_positions.append((pos.x_val, pos.y_val, pos.z_val))

            # æ€§èƒ½ç›‘æ§è¾“å‡º
            if loop_count % 20 == 0:
                elapsed = time.time() - exploration_start
                print(f"\nğŸ“Š å¾ªç¯{loop_count} | å·²è¿è¡Œ{elapsed:.1f}s | çŠ¶æ€:{self.state.value}")
                print(f"   æ„ŸçŸ¥FPS:{self.perception_fps:.1f} | éšœç¢:{perception.has_obstacle}")
                print(f"   æœ€è¿‘éšœç¢:{perception.obstacle_distance:.1f}m | å¼€é˜”åº¦:{perception.open_space_score:.2f}")
                print(f"   ä½ç½®:({pos.x_val:.1f}, {pos.y_val:.1f}, {-pos.z_val:.1f}m)")
                print(f"   å®‰å…¨æ–¹å‘æ•°:{len(perception.safe_directions)}")

            # å¾ªç¯é¢‘ç‡æ§åˆ¶ï¼ˆ10Hzï¼‰
            loop_time = time.time() - loop_start
            if loop_time < 0.1:
                time.sleep(0.1 - loop_time)

        # æ¢ç´¢ç»“æŸï¼Œå‡†å¤‡é™è½
        print("\n" + "=" * 60)
        print("æ¢ç´¢å®Œæˆï¼Œå¼€å§‹è¿”èˆªé™è½")
        print("=" * 60)

        self.change_state(FlightState.LANDING)
        self.return_to_start()

    def return_to_start(self):
        """è¿”å›èµ·å§‹ç‚¹é™„è¿‘å¹¶é™è½"""
        try:
            # å›åˆ°èµ·ç‚¹é™„è¿‘ï¼ˆç®€å•å®ç°ï¼šå›åˆ°åŸç‚¹ï¼‰
            print("â†©ï¸ è¿”å›èµ·å§‹åŒºåŸŸ...")
            self.client.moveToPositionAsync(0, 0, -10, 5, vehicle_name=self.drone_name).join()
            time.sleep(2)

            # é™è½
            print("ğŸ›¬ é™è½ä¸­...")
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(3)

            # æ–­å¼€æ§åˆ¶
            self.client.armDisarm(False, vehicle_name=self.drone_name)
            self.client.enableApiControl(False, vehicle_name=self.drone_name)

            print("âœ… ä»»åŠ¡å®Œæˆï¼Œç³»ç»Ÿå®‰å…¨å…³é—­")

        except Exception as e:
            print(f"âŒ é™è½å¼‚å¸¸: {e}")
            print("âš  å°è¯•ç´§æ€¥é™è½...")
            try:
                self.client.landAsync(vehicle_name=self.drone_name).join()
            except:
                pass

    def emergency_stop(self):
        """ç´§æ€¥åœæ­¢"""
        print("ğŸ†˜ ç´§æ€¥åœæ­¢è§¦å‘ï¼")
        self.emergency_flag = True
        self.change_state(FlightState.EMERGENCY)
        self.client.hoverAsync(vehicle_name=self.drone_name).join()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    try:
        # åˆ›å»ºæ„ŸçŸ¥æ¢ç´¢å™¨
        explorer = PerceptiveExplorer(drone_name="")

        # è®¾ç½®é”®ç›˜ä¸­æ–­å¤„ç†
        import signal
        def signal_handler(sig, frame):
            print("\nâš  ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
            explorer.emergency_stop()
            exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        # è¿è¡Œä¸»å¾ªç¯
        explorer.run_perception_loop()

    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

        # å°è¯•å®‰å…¨é™è½
        try:
            client = airsim.MultirotorClient()
            client.landAsync().join()
            client.armDisarm(False)
            client.enableApiControl(False)
        except:
            pass


if __name__ == "__main__":
    main()