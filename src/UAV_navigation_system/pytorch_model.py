#!/usr/bin/env python3
"""
PyTorchæ¨¡å‹å·¥å…·ç±»
ç”¨äºåŠ è½½å’Œè¿è¡ŒPyTorchæ¨¡å‹
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2
import os


class PyTorchDroneModel:
    """PyTorchæ— äººæœºè§†è§‰æ¨¡å‹ç±»"""

    def __init__(self, model_path=None, device=None):
        self.model = None
        self.device = None
        self.class_names = ['Forest', 'Fire', 'City', 'Animal', 'Vehicle', 'Water']
        self.img_size = (224, 224)

        # è®¾ç½®è®¾å¤‡
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device

        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {self.device}")

        # å›¾åƒé¢„å¤„ç†å˜æ¢
        self.transform = transforms.Compose([
            transforms.Resize(self.img_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼Œè‡ªåŠ¨åŠ è½½
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)

    def define_model_architecture(self):
        """å®šä¹‰PyTorchæ¨¡å‹æ¶æ„ï¼ˆéœ€è¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰"""

        class DroneCNN(nn.Module):
            def __init__(self, num_classes=6):
                super(DroneCNN, self).__init__()
                self.features = nn.Sequential(
                    # ç¬¬ä¸€å±‚å·ç§¯
                    nn.Conv2d(3, 32, kernel_size=3, padding=1),
                    nn.BatchNorm2d(32),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),

                    # ç¬¬äºŒå±‚å·ç§¯
                    nn.Conv2d(32, 64, kernel_size=3, padding=1),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),

                    # ç¬¬ä¸‰å±‚å·ç§¯
                    nn.Conv2d(64, 128, kernel_size=3, padding=1),
                    nn.BatchNorm2d(128),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),

                    # ç¬¬å››å±‚å·ç§¯
                    nn.Conv2d(128, 256, kernel_size=3, padding=1),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),
                )

                self.classifier = nn.Sequential(
                    nn.Flatten(),
                    nn.Linear(256 * 14 * 14, 512),  # 224/2/2/2/2 = 14
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.5),
                    nn.Linear(512, num_classes)
                )

            def forward(self, x):
                x = self.features(x)
                x = self.classifier(x)
                return x

        return DroneCNN(num_classes=len(self.class_names))

    def load_resnet18_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹"""
        from torchvision import models

        model = models.resnet18(pretrained=False)
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, len(self.class_names))

        return model

    def load_mobilenetv2_model(self):
        """åŠ è½½é¢„è®­ç»ƒçš„MobileNetV2æ¨¡å‹"""
        from torchvision import models

        model = models.mobilenet_v2(pretrained=False)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(self.class_names))

        return model

    def load_model(self, model_path, model_type='custom'):
        """åŠ è½½PyTorchæ¨¡å‹"""
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½PyTorchæ¨¡å‹: {model_path}")

        try:
            # æ ¹æ®ç±»å‹åˆ›å»ºæ¨¡å‹æ¶æ„
            if model_type == 'resnet18':
                self.model = self.load_resnet18_model()
            elif model_type == 'mobilenet':
                self.model = self.load_mobilenetv2_model()
            else:
                self.model = self.define_model_architecture()

            # åŠ è½½æ¨¡å‹æƒé‡
            checkpoint = torch.load(model_path, map_location=self.device)

            if isinstance(checkpoint, dict):
                # å¦‚æœä¿å­˜çš„æ˜¯æ£€æŸ¥ç‚¹å­—å…¸
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                elif 'state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['state_dict'])
                else:
                    # å°è¯•ç›´æ¥åŠ è½½
                    self.model.load_state_dict(checkpoint)
            else:
                # å¦‚æœä¿å­˜çš„æ˜¯æ¨¡å‹æœ¬èº«
                self.model = checkpoint

            # ç§»åŠ¨åˆ°è®¾å¤‡
            self.model = self.model.to(self.device)

            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.eval()

            print(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“Š æ¨¡å‹ç»“æ„: {self.model.__class__.__name__}")
            print(f"ğŸ“Š å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")

            return True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
            return False

    def preprocess_image(self, image):
        """é¢„å¤„ç†å›¾åƒä»¥ä¾›PyTorchæ¨¡å‹ä½¿ç”¨"""
        # è½¬æ¢OpenCV BGRå›¾åƒä¸ºPIL RGBå›¾åƒ
        if isinstance(image, np.ndarray):
            # OpenCVå›¾åƒ (BGR) -> PILå›¾åƒ (RGB)
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image_rgb)
        else:
            pil_image = image

        # åº”ç”¨å˜æ¢
        tensor = self.transform(pil_image)

        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
        tensor = tensor.unsqueeze(0)

        # ç§»åŠ¨åˆ°è®¾å¤‡
        tensor = tensor.to(self.device)

        return tensor

    def predict(self, image):
        """å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹"""
        if self.model is None:
            print("âš ï¸  æ¨¡å‹æœªåŠ è½½")
            return None, 0

        try:
            # é¢„å¤„ç†å›¾åƒ
            input_tensor = self.preprocess_image(image)

            # ç¦ç”¨æ¢¯åº¦è®¡ç®—
            with torch.no_grad():
                # å‰å‘ä¼ æ’­
                outputs = self.model(input_tensor)

                # è·å–é¢„æµ‹ç»“æœ
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)

                # è½¬æ¢ä¸ºPythonæ ‡é‡
                class_idx = predicted.item()
                confidence_value = confidence.item()

                # è·å–ç±»åˆ«åç§°
                if 0 <= class_idx < len(self.class_names):
                    class_name = self.class_names[class_idx]
                else:
                    class_name = f"Class_{class_idx}"

                return class_name, confidence_value

        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None, 0

    def predict_batch(self, images):
        """æ‰¹é‡é¢„æµ‹å›¾åƒ"""
        if self.model is None:
            return [], []

        try:
            # é¢„å¤„ç†æ‰€æœ‰å›¾åƒ
            tensors = []
            for img in images:
                tensor = self.preprocess_image(img)
                tensors.append(tensor)

            # å †å ä¸ºæ‰¹æ¬¡
            batch = torch.cat(tensors, dim=0)
            batch = batch.to(self.device)

            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(batch)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidences, predicted = torch.max(probabilities, 1)

            # è½¬æ¢ç»“æœ
            results = []
            conf_values = []

            for i in range(len(images)):
                class_idx = predicted[i].item()
                if 0 <= class_idx < len(self.class_names):
                    class_name = self.class_names[class_idx]
                else:
                    class_name = f"Class_{class_idx}"

                results.append(class_name)
                conf_values.append(confidences[i].item())

            return results, conf_values

        except Exception as e:
            print(f"âŒ æ‰¹é‡é¢„æµ‹å¤±è´¥: {e}")
            return [], []


# æ¨¡å‹å·¥å‚å‡½æ•°
def load_pytorch_model(model_path, model_type='custom'):
    """åŠ è½½PyTorchæ¨¡å‹çš„ä¾¿æ·å‡½æ•°"""
    model = PyTorchDroneModel()
    success = model.load_model(model_path, model_type)
    return model if success else None


# æµ‹è¯•å‡½æ•°
def test_model():
    """æµ‹è¯•æ¨¡å‹åŠ è½½å’Œé¢„æµ‹"""
    print("ğŸ§ª æµ‹è¯•PyTorchæ¨¡å‹...")

    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)

    # åŠ è½½æ¨¡å‹
    model = PyTorchDroneModel()

    # æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹
    print("\n1. æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹æ¶æ„...")
    custom_model = model.define_model_architecture()
    print(f"âœ… è‡ªå®šä¹‰æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in custom_model.parameters()):,}")

    # æµ‹è¯•ResNet18
    print("\n2. æµ‹è¯•ResNet18æ¶æ„...")
    resnet_model = model.load_resnet18_model()
    print(f"âœ… ResNet18æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in resnet_model.parameters()):,}")

    # æµ‹è¯•MobileNetV2
    print("\n3. æµ‹è¯•MobileNetV2æ¶æ„...")
    mobilenet_model = model.load_mobilenetv2_model()
    print(f"âœ… MobileNetV2æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in mobilenet_model.parameters()):,}")

    print("\nğŸ§ª æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_model()