#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CARLA DQNè®­ç»ƒèŠ‚ç‚¹ - å®Œæ•´ä½¿ç”¨åŸå§‹ä»£ç 
"""
import rospy
import sys
import os
import time
import threading
import numpy as np

# è®¾ç½®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))

# ROSæ¶ˆæ¯
from std_msgs.msg import String, Float32, Int32, Bool
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

class FullCarlaTrainer:
    def __init__(self):
        # åˆå§‹åŒ–ROSèŠ‚ç‚¹
        rospy.init_node('carla_dqn_full_trainer')
        
        # è·å–å‚æ•° - ä½¿ç”¨Hyperparameters.pyä¸­çš„å€¼ä½œä¸ºé»˜è®¤å€¼
        try:
            import Hyperparameters as hp
            default_episodes = hp.EPISODES
        except:
            default_episodes = 100
            
        self.episodes = rospy.get_param('~episodes', default_episodes)
        self.model_name = rospy.get_param('~model_name', 'YY_Enhanced_ObstacleAvoidance')
        
        # åˆ›å»ºå‘å¸ƒå™¨
        self.status_pub = rospy.Publisher('/carla/full_training/status', String, queue_size=10)
        self.reward_pub = rospy.Publisher('/carla/full_training/reward', Float32, queue_size=10)
        self.episode_pub = rospy.Publisher('/carla/full_training/episode', Int32, queue_size=10)
        self.epsilon_pub = rospy.Publisher('/carla/full_training/epsilon', Float32, queue_size=10)
        
        # å›¾åƒå‘å¸ƒå™¨
        self.image_pub = rospy.Publisher('/carla/full_training/image', Image, queue_size=1)
        self.bridge = CvBridge()
        
        # å¯¼å…¥åŸå§‹ä»£ç 
        self.import_modules()
        
        rospy.loginfo(f"âœ… å®Œæ•´è®­ç»ƒèŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆ")
        rospy.loginfo(f"   è®­ç»ƒè½®æ¬¡: {self.episodes}")
        rospy.loginfo(f"   æ¨¡å‹åç§°: {self.model_name}")
        
        self.status_pub.publish(f"èŠ‚ç‚¹å¯åŠ¨ï¼Œå‡†å¤‡è®­ç»ƒ{self.episodes}è½®")
        
    def import_modules(self):
        """å¯¼å…¥æ‰€æœ‰éœ€è¦çš„æ¨¡å—"""
        try:
            # å¯¼å…¥ä¸»è®­ç»ƒå‡½æ•°
            import main
            self.main_module = main
            rospy.loginfo("âœ… å¯¼å…¥main.pyæ¨¡å—")
            
            # å¯¼å…¥è¶…å‚æ•°
            import Hyperparameters
            self.hp = Hyperparameters
            rospy.loginfo(f"âœ… å¯¼å…¥è¶…å‚æ•°: EPISODES={Hyperparameters.EPISODES}")
            
            # å¯¼å…¥ç¯å¢ƒ
            import Environment
            self.Environment = Environment
            rospy.loginfo("âœ… å¯¼å…¥ç¯å¢ƒæ¨¡å—")
            
            # å¯¼å…¥æ¨¡å‹
            import Model
            self.Model = Model
            rospy.loginfo("âœ… å¯¼å…¥æ¨¡å‹æ¨¡å—")
            
            self.import_success = True
            
        except Exception as e:
            rospy.logerr(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            self.import_success = False
            
    def publish_training_status(self, episode, reward, epsilon):
        """å‘å¸ƒè®­ç»ƒçŠ¶æ€"""
        # å‘å¸ƒçŠ¶æ€
        status_msg = String()
        status_msg.data = f"Episode {episode}: Reward={reward:.2f}, Epsilon={epsilon:.3f}"
        self.status_pub.publish(status_msg)
        
        # å‘å¸ƒå¥–åŠ±
        reward_msg = Float32()
        reward_msg.data = reward
        self.reward_pub.publish(reward_msg)
        
        # å‘å¸ƒå›åˆæ•°
        episode_msg = Int32()
        episode_msg.data = episode
        self.episode_pub.publish(episode_msg)
        
        # å‘å¸ƒæ¢ç´¢ç‡
        epsilon_msg = Float32()
        epsilon_msg.data = epsilon
        self.epsilon_pub.publish(epsilon_msg)
        
    def publish_image(self, cv_image):
        """å‘å¸ƒå›¾åƒ"""
        try:
            if cv_image is not None and len(cv_image.shape) == 3:
                # ç¡®ä¿å›¾åƒæ˜¯8ä½
                if cv_image.dtype != np.uint8:
                    cv_image = cv_image.astype(np.uint8)
                
                # è°ƒæ•´å¤§å°ä»¥ä¾¿æ˜¾ç¤º
                display_image = cv2.resize(cv_image, (640, 480))
                
                # è½¬æ¢ä¸ºROSæ¶ˆæ¯
                ros_image = self.bridge.cv2_to_imgmsg(display_image, "bgr8")
                ros_image.header.stamp = rospy.Time.now()
                ros_image.header.frame_id = "carla_camera"
                
                self.image_pub.publish(ros_image)
        except Exception as e:
            rospy.logwarn(f"å‘å¸ƒå›¾åƒå¤±è´¥: {e}")
    
    def run_original_training(self):
        """è¿è¡ŒåŸå§‹è®­ç»ƒä»£ç """
        try:
            rospy.loginfo("ğŸš— å¼€å§‹åŸå§‹CARLA DQNè®­ç»ƒ")
            
            # è¿™é‡Œç›´æ¥è°ƒç”¨ä½ åŸæ¥çš„main.pyä¸­çš„å‡½æ•°
            # ä½†éœ€è¦ç¨ä½œä¿®æ”¹ä»¥é€‚åº”ROS
            
            # 1. è®¾ç½®GPUå†…å­˜
            import tensorflow as tf
            gpu_options = tf.compat.v1.GPUOptions(
                per_process_gpu_memory_fraction=self.hp.MEMORY_FRACTION
            )
            tf.compat.v1.keras.backend.set_session(
                tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)))
            
            # 2. åˆ›å»ºç›®å½•
            for dir_name in ['models', 'expert_data', 'logs', 'training_stats']:
                if not os.path.isdir(dir_name):
                    os.makedirs(dir_name)
            
            # 3. åˆ›å»ºæ™ºèƒ½ä½“å’Œç¯å¢ƒ
            rospy.loginfo("åˆ›å»ºå¢å¼ºç‰ˆæ™ºèƒ½ä½“å’Œç¯å¢ƒ...")
            agent = self.Model.EnhancedDQNAgent(
                use_dueling=True, 
                use_per=True,
                use_curriculum=True,
                use_multi_objective=True,
                use_attention=True,
                use_enhanced_model=True
            )
            
            env = self.Environment.CarEnv(obstacle_detection_mode='advanced')
            
            # 4. è®¾ç½®è®­ç»ƒç­–ç•¥
            agent.setup_training_strategies(env)
            
            # 5. å¯åŠ¨è®­ç»ƒçº¿ç¨‹
            trainer_thread = threading.Thread(target=agent.train_in_loop, daemon=True)
            trainer_thread.start()
            
            while not agent.training_initialized:
                time.sleep(0.01)
            
            # 6. è®­ç»ƒå¾ªç¯
            rospy.loginfo(f"å¼€å§‹{self.episodes}è½®è®­ç»ƒ...")
            
            success_count = 0
            scores = []
            
            for episode in range(1, self.episodes + 1):
                if rospy.is_shutdown():
                    rospy.loginfo("ROSå…³é—­ï¼Œåœæ­¢è®­ç»ƒ")
                    break
                
                # é‡ç½®ç¯å¢ƒ
                if agent.curriculum_manager:
                    config = agent.curriculum_manager.get_current_config()
                    current_state = env.reset(episode, curriculum_config=config)
                else:
                    current_state = env.reset(episode)
                
                # é‡ç½®ç»Ÿè®¡
                score = 0
                step = 1
                done = False
                
                # è·å–æœ€å¤§æ­¥æ•°
                if agent.curriculum_manager:
                    config = agent.curriculum_manager.get_current_config()
                    max_steps = config['max_episode_steps']
                else:
                    max_steps = self.hp.SECONDS_PER_EPISODE * self.hp.FPS
                
                # å•è½®è®­ç»ƒ
                while not done and step < max_steps:
                    # é€‰æ‹©åŠ¨ä½œ
                    if np.random.random() > self.hp.EPSILON:
                        qs = agent.get_qs(current_state)
                        action = np.argmax(qs)
                    else:
                        action = np.random.randint(0, 5)
                        time.sleep(1 / self.hp.FPS)
                    
                    # æ‰§è¡ŒåŠ¨ä½œ
                    new_state, reward, done, _ = env.step(action)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦ç»éªŒ
                    is_obstacle_experience = (env.last_ped_distance < 10.0)
                    is_success_experience = (reward > 2.0 and not done)
                    
                    # æ›´æ–°ç»éªŒå›æ”¾
                    agent.update_replay_memory(
                        (current_state, action, reward, new_state, done),
                        is_obstacle=is_obstacle_experience,
                        is_success=is_success_experience
                    )
                    
                    score += reward
                    current_state = new_state
                    step += 1
                    
                    # æ¯10æ­¥å‘å¸ƒä¸€æ¬¡å›¾åƒ
                    if step % 10 == 0:
                        self.publish_image(current_state)
                    
                    if done:
                        break
                
                # å‘å¸ƒæœ¬è½®ç»“æœ
                self.publish_training_status(episode, score, self.hp.EPSILON)
                
                # è®°å½•åˆ†æ•°
                scores.append(score)
                success = score > 8
                if success:
                    success_count += 1
                
                # æ¸…ç†ç¯å¢ƒ
                env.cleanup_actors()
                
                # è¡°å‡æ¢ç´¢ç‡
                if self.hp.EPSILON > self.hp.MIN_EPSILON:
                    self.hp.EPSILON *= self.hp.EPSILON_DECAY
                    self.hp.EPSILON = max(self.hp.MIN_EPSILON, self.hp.EPSILON)
                
                # æ¯10è½®ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
                if episode % 10 == 0:
                    model_path = f"models/{self.model_name}_checkpoint_ep{episode}.model"
                    agent.save_model(model_path)
                    rospy.loginfo(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {model_path}")
                
                # æ˜¾ç¤ºè¿›åº¦
                rospy.loginfo(f"Episode {episode}/{self.episodes}: Score={score:.2f}, "
                             f"Success={success_count}, Epsilon={self.hp.EPSILON:.3f}")
            
            # è®­ç»ƒå®Œæˆ
            rospy.loginfo("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
            
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            if scores:
                final_avg = np.mean(scores[-10:]) if len(scores) >= 10 else np.mean(scores)
                final_model = f"models/{self.model_name}_final_avg{final_avg:.2f}.model"
                agent.save_model(final_model)
                rospy.loginfo(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model}")
            
            # æ¸…ç†
            agent.terminate = True
            trainer_thread.join()
            env.cleanup_actors()
            
            self.status_pub.publish("è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            rospy.logerr(f"è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            rospy.logerr(traceback.format_exc())
            self.status_pub.publish(f"è®­ç»ƒå¤±è´¥: {str(e)}")
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        rospy.loginfo("=" * 60)
        rospy.loginfo("CARLA DQNå®Œæ•´è®­ç»ƒç³»ç»Ÿ")
        rospy.loginfo("=" * 60)
        rospy.loginfo(f"è®­ç»ƒè½®æ¬¡: {self.episodes}")
        rospy.loginfo(f"ä½¿ç”¨æ¨¡å‹: {self.model_name}")
        rospy.loginfo("")
        rospy.loginfo("ğŸ“¡ å‘å¸ƒçš„è¯é¢˜:")
        rospy.loginfo("  /carla/full_training/status   - è®­ç»ƒçŠ¶æ€")
        rospy.loginfo("  /carla/full_training/reward   - å®æ—¶å¥–åŠ±")
        rospy.loginfo("  /carla/full_training/episode  - å½“å‰å›åˆ")
        rospy.loginfo("  /carla/full_training/epsilon  - æ¢ç´¢ç‡")
        rospy.loginfo("  /carla/full_training/image    - è®­ç»ƒå›¾åƒ")
        rospy.loginfo("")
        rospy.loginfo("â³ 5ç§’åå¼€å§‹è®­ç»ƒ...")
        
        time.sleep(5)
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œè®­ç»ƒ
        if self.import_success:
            train_thread = threading.Thread(target=self.run_original_training)
            train_thread.daemon = True
            train_thread.start()
        else:
            rospy.logerr("å¯¼å…¥å¤±è´¥ï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
            return
        
        # ä¿æŒèŠ‚ç‚¹è¿è¡Œ
        rospy.spin()

def main():
    trainer = FullCarlaTrainer()
    trainer.run()

if __name__ == '__main__':
    try:
        main()
    except rospy.ROSInterruptException:
        rospy.loginfo("è®­ç»ƒèŠ‚ç‚¹è¢«ä¸­æ–­")
    except Exception as e:
        rospy.logerr(f"èŠ‚ç‚¹å¼‚å¸¸: {e}")
