"""
åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDQNï¼‰çš„AirSimè‡ªåŠ¨é©¾é©¶å®‰å…¨å¯¼èˆªè®­ç»ƒç³»ç»Ÿ
å…¼å®¹æ—§ç‰ˆAirSimæœåŠ¡å™¨ï¼ˆç‰ˆæœ¬1ï¼‰çš„ä¿®å¤ç‰ˆ
"""

import os
import sys
import time
import random
import argparse
from collections import deque
from datetime import datetime

import numpy as np
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter

# AirSimå¯¼å…¥
try:
    import airsim
    print(f"âœ“ AirSimæ¨¡å—å¯¼å…¥æˆåŠŸï¼Œç‰ˆæœ¬: {airsim.__version__}")
except ImportError as e:
    print(f"AirSimæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


# ==================== é…ç½®ç±» ====================
class TrainingConfig:
    """è®­ç»ƒé…ç½®å‚æ•°"""

    def __init__(self):
        # ç½‘ç»œå‚æ•°
        self.image_size = (84, 84)  # è¾“å…¥å›¾åƒå°ºå¯¸
        self.state_dim = 15  # ç®€åŒ–çŠ¶æ€ç»´åº¦
        self.action_dim = 5  # ç®€åŒ–åŠ¨ä½œç©ºé—´

        # è®­ç»ƒå‚æ•°
        self.total_episodes = 50  # æµ‹è¯•é˜¶æ®µç”¨å°‘é‡å›åˆ
        self.max_steps = 100
        self.batch_size = 16
        self.learning_rate = 1e-3
        self.gamma = 0.99
        self.tau = 1e-3
        self.update_every = 4

        # ç»éªŒå›æ”¾
        self.buffer_size = 2000
        self.pretrain_length = 100

        # æ¢ç´¢ç­–ç•¥
        self.epsilon_start = 1.0
        self.epsilon_end = 0.1
        self.epsilon_decay = 0.99

        # å®‰å…¨å‚æ•°
        self.collision_penalty = -5.0
        self.max_speed = 10.0

        # è·¯å¾„å‚æ•°
        self.model_save_path = "./models"
        self.log_path = "./logs"
        self.save_interval = 10

        # AirSimå‚æ•°
        self.ip_address = "127.0.0.1"


# ==================== ç¥ç»ç½‘ç»œæ¶æ„ ====================
class SimpleDQN(nn.Module):
    """ç®€åŒ–ç‰ˆDQNç½‘ç»œ"""

    def __init__(self, state_dim, action_dim, image_channels=3):
        super(SimpleDQN, self).__init__()

        # è§†è§‰ç¼–ç å™¨
        self.visual_encoder = nn.Sequential(
            nn.Conv2d(image_channels, 8, kernel_size=4, stride=2),
            nn.ReLU(),
            nn.Conv2d(8, 16, kernel_size=3, stride=1),
            nn.ReLU(),
            nn.Flatten()
        )

        # è®¡ç®—å·ç§¯å±‚è¾“å‡ºç»´åº¦
        with torch.no_grad():
            sample = torch.zeros(1, image_channels, 84, 84)
            conv_out = self.visual_encoder(sample)
            self.visual_feature_dim = conv_out.shape[1]

        # çŠ¶æ€å¤„ç†å™¨
        self.state_processor = nn.Sequential(
            nn.Linear(state_dim, 32),
            nn.ReLU(),
        )

        # ç‰¹å¾èåˆå±‚
        fusion_input_dim = self.visual_feature_dim + 32
        self.fusion_layer = nn.Sequential(
            nn.Linear(fusion_input_dim, 64),
            nn.ReLU(),
        )

        # åŠ¨ä½œä»·å€¼å¤´
        self.value_stream = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, action_dim)
        )

    def forward(self, image, state):
        # å¤„ç†è§†è§‰è¾“å…¥
        visual_features = self.visual_encoder(image)

        # å¤„ç†çŠ¶æ€è¾“å…¥
        state_features = self.state_processor(state)

        # ç‰¹å¾èåˆ
        combined = torch.cat([visual_features, state_features], dim=1)
        fused_features = self.fusion_layer(combined)

        # è¾“å‡ºåŠ¨ä½œä»·å€¼
        q_values = self.value_stream(fused_features)

        return q_values


# ==================== ç»éªŒå›æ”¾ç¼“å†²åŒº ====================
class ReplayBuffer:
    """ç®€åŒ–ç‰ˆç»éªŒå›æ”¾ç¼“å†²åŒº"""

    def __init__(self, capacity):
        self.buffer = deque(maxlen=capacity)

    def push(self, experience):
        self.buffer.append(experience)

    def sample(self, batch_size):
        if len(self.buffer) < batch_size:
            return None

        indices = np.random.choice(len(self.buffer), batch_size, replace=False)
        return [self.buffer[idx] for idx in indices]

    def __len__(self):
        return len(self.buffer)


# ==================== DQNæ™ºèƒ½ä½“ ====================
class DQNAgent:
    """DQNæ™ºèƒ½ä½“"""

    def __init__(self, config, device='cpu'):
        self.config = config
        self.device = torch.device(device)

        # åˆå§‹åŒ–ç½‘ç»œ
        self.policy_net = SimpleDQN(config.state_dim, config.action_dim).to(self.device)
        self.target_net = SimpleDQN(config.state_dim, config.action_dim).to(self.device)
        self.target_net.load_state_dict(self.policy_net.state_dict())
        self.target_net.eval()

        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=config.learning_rate)

        # ç»éªŒå›æ”¾ç¼“å†²åŒº
        self.memory = ReplayBuffer(config.buffer_size)

        # è®­ç»ƒå‚æ•°
        self.epsilon = config.epsilon_start
        self.steps_done = 0

        print(f"åˆå§‹åŒ–DQNæ™ºèƒ½ä½“ï¼Œè®¾å¤‡: {self.device}")

    def select_action(self, state_image, state_vector, eval_mode=False):
        """é€‰æ‹©åŠ¨ä½œ"""
        if not eval_mode and random.random() < self.epsilon:
            return random.randrange(self.config.action_dim)

        with torch.no_grad():
            image_tensor = torch.FloatTensor(state_image).unsqueeze(0).to(self.device)
            vector_tensor = torch.FloatTensor(state_vector).unsqueeze(0).to(self.device)

            q_values = self.policy_net(image_tensor, vector_tensor)
            return q_values.argmax(1).item()

    def train_step(self):
        """è®­ç»ƒæ­¥éª¤"""
        if len(self.memory) < self.config.pretrain_length:
            return 0

        batch = self.memory.sample(self.config.batch_size)
        if batch is None:
            return 0

        # è§£æ„æ‰¹æ•°æ®
        states_img, states_vec, actions, rewards, next_states_img, next_states_vec, dones = zip(*batch)

        # è½¬æ¢ä¸ºå¼ é‡
        states_img = torch.FloatTensor(np.array(states_img)).to(self.device)
        states_vec = torch.FloatTensor(np.array(states_vec)).to(self.device)
        actions = torch.LongTensor(actions).unsqueeze(1).to(self.device)
        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(self.device)
        next_states_img = torch.FloatTensor(np.array(next_states_img)).to(self.device)
        next_states_vec = torch.FloatTensor(np.array(next_states_vec)).to(self.device)
        dones = torch.FloatTensor(dones).unsqueeze(1).to(self.device)

        # è®¡ç®—å½“å‰Qå€¼
        current_q = self.policy_net(states_img, states_vec)
        current_q = current_q.gather(1, actions)

        # è®¡ç®—ç›®æ ‡Qå€¼
        with torch.no_grad():
            next_q = self.target_net(next_states_img, next_states_vec)
            next_q_max = next_q.max(1)[0].unsqueeze(1)
            target_q = rewards + (1 - dones) * self.config.gamma * next_q_max

        # è®¡ç®—æŸå¤±
        loss = F.smooth_l1_loss(current_q, target_q)

        # åå‘ä¼ æ’­
        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)
        self.optimizer.step()

        # æ›´æ–°æ¢ç´¢ç‡
        self.epsilon = max(self.config.epsilon_end, self.epsilon * self.config.epsilon_decay)

        return loss.item()

    def update_target_network(self):
        """æ›´æ–°ç›®æ ‡ç½‘ç»œ"""
        self.target_net.load_state_dict(self.policy_net.state_dict())

    def save_model(self, episode, path=None):
        """ä¿å­˜æ¨¡å‹"""
        if path is None:
            path = self.config.model_save_path

        os.makedirs(path, exist_ok=True)
        model_path = os.path.join(path, f'airsim_dqn_episode_{episode}.pth')

        torch.save({
            'episode': episode,
            'policy_state_dict': self.policy_net.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'epsilon': self.epsilon,
        }, model_path)

        print(f"æ¨¡å‹å·²ä¿å­˜: {model_path}")

    def load_model(self, model_path):
        """åŠ è½½æ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)

        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.epsilon = checkpoint['epsilon']

        print(f"æ¨¡å‹å·²åŠ è½½: {model_path}")


# ==================== AirSimç¯å¢ƒå°è£…ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰ ====================
class AirSimSafetyEnv:
    """å…¼å®¹æ—§ç‰ˆAirSimæœåŠ¡å™¨çš„ç¯å¢ƒå°è£…"""

    def __init__(self, config):
        self.config = config
        self.client = None
        self.step_count = 0
        self.total_reward = 0
        self.collisions = 0

        print("åˆå§‹åŒ–AirSimç¯å¢ƒ...")

    def connect(self):
        """è¿æ¥åˆ°AirSimæœåŠ¡å™¨ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰"""
        try:
            print(f"å°è¯•è¿æ¥AirSimæœåŠ¡å™¨ {self.config.ip_address}...")

            # åˆ›å»ºå®¢æˆ·ç«¯
            self.client = airsim.CarClient()
            self.client.confirmConnection()
            print("âœ“ è¿æ¥æˆåŠŸ!")

            # å°è¯•å¯ç”¨APIæ§åˆ¶ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
            try:
                self.client.enableApiControl(True)
                print("âœ“ APIæ§åˆ¶å·²å¯ç”¨")
            except Exception as api_error:
                print(f"âš ï¸  APIæ§åˆ¶å¯ç”¨å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æ—§ç‰ˆï¼‰: {api_error}")
                print("å°è¯•ç»§ç»­è¿è¡Œ...")

            # é‡ç½®è½¦è¾†
            self.client.reset()
            print("âœ“ è½¦è¾†å·²é‡ç½®")

            # ç­‰å¾…ç¨³å®š
            time.sleep(1.0)

            return True

        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            print("\nè¯·ç¡®ä¿:")
            print("1. AirSimä»¿çœŸç¯å¢ƒæ­£åœ¨è¿è¡Œï¼ˆå¦‚AirSimNH.exeï¼‰")
            print("2. å·²é€‰æ‹©æ±½è½¦æ¨¡å¼")
            print("3. æœåŠ¡å™¨ç‰ˆæœ¬å…¼å®¹ï¼ˆä½¿ç”¨AirSim 1.2.6å®¢æˆ·ç«¯ï¼‰")
            return False

    def get_camera_image(self):
        """è·å–æ‘„åƒå¤´å›¾åƒ"""
        try:
            # è·å–åœºæ™¯å›¾åƒ
            responses = self.client.simGetImages([
                airsim.ImageRequest("0", airsim.ImageType.Scene, False, False)
            ])

            if responses and len(responses) > 0:
                img1d = np.frombuffer(responses[0].image_data_uint8, dtype=np.uint8)

                if img1d.size > 0:
                    img_rgb = img1d.reshape(responses[0].height, responses[0].width, 3)
                    resized = cv2.resize(img_rgb, self.config.image_size)
                    normalized = resized.astype(np.float32) / 255.0
                    normalized = np.transpose(normalized, (2, 0, 1))

                    return normalized

        except Exception as e:
            print(f"è·å–æ‘„åƒå¤´å›¾åƒå¤±è´¥: {e}")

        # è¿”å›ç©ºç™½å›¾åƒ
        return np.zeros((3, *self.config.image_size), dtype=np.float32)

    def get_vehicle_state(self):
        """è·å–è½¦è¾†çŠ¶æ€"""
        try:
            # è·å–è½¦è¾†çŠ¶æ€
            car_state = self.client.getCarState()

            # è·å–ç¢°æ’ä¿¡æ¯
            collision_info = self.client.simGetCollisionInfo()

            state_info = {
                'speed': car_state.speed,
                'velocity': [
                    car_state.kinematics_estimated.linear_velocity.x_val,
                    car_state.kinematics_estimated.linear_velocity.y_val,
                    car_state.kinematics_estimated.linear_velocity.z_val
                ],
                'position': [
                    car_state.kinematics_estimated.position.x_val,
                    car_state.kinematics_estimated.position.y_val,
                    car_state.kinematics_estimated.position.z_val
                ],
                'collision': collision_info.has_collided,
                'collision_count': collision_info.collision_count,
            }

            return state_info

        except Exception as e:
            print(f"è·å–è½¦è¾†çŠ¶æ€å¤±è´¥: {e}")
            return None

    def create_state_vector(self, state_info):
        """åˆ›å»ºçŠ¶æ€å‘é‡"""
        if state_info is None:
            return np.zeros(self.config.state_dim, dtype=np.float32)

        state_vector = []

        # é€Ÿåº¦ä¿¡æ¯
        state_vector.append(state_info['speed'] / self.config.max_speed)
        state_vector.extend([v / 10.0 for v in state_info['velocity'][:2]])

        # ä½ç½®ä¿¡æ¯
        state_vector.extend([p / 100.0 for p in state_info['position'][:2]])

        # ç¢°æ’ä¿¡æ¯
        state_vector.append(float(state_info['collision']))

        # è¡¥å…¨åˆ°æŒ‡å®šç»´åº¦
        while len(state_vector) < self.config.state_dim:
            state_vector.append(np.random.uniform(-0.1, 0.1))

        state_vector = state_vector[:self.config.state_dim]

        return np.array(state_vector, dtype=np.float32)

    def get_state(self):
        """è·å–å½“å‰çŠ¶æ€"""
        try:
            image_state = self.get_camera_image()
            state_info = self.get_vehicle_state()
            state_vector = self.create_state_vector(state_info)

            safety_flags = {
                'collision': state_info['collision'] if state_info else False,
            }

            return image_state, state_vector, safety_flags

        except Exception as e:
            print(f"è·å–çŠ¶æ€å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çŠ¶æ€
            image_state = np.zeros((3, *self.config.image_size), dtype=np.float32)
            state_vector = np.zeros(self.config.state_dim, dtype=np.float32)
            safety_flags = {'collision': False}
            return image_state, state_vector, safety_flags

    def apply_action(self, action_idx):
        """åº”ç”¨åŠ¨ä½œåˆ°è½¦è¾†"""
        # ç®€åŒ–åŠ¨ä½œç©ºé—´
        steer_actions = [-0.3, -0.1, 0.0, 0.1, 0.3]
        throttle_actions = [0.0, 0.2, 0.5, 0.8, 1.0]

        # ç¡®ä¿åŠ¨ä½œç´¢å¼•åœ¨èŒƒå›´å†…
        action_idx = min(action_idx, len(steer_actions) * len(throttle_actions) - 1)
        steer_idx = action_idx % len(steer_actions)
        throttle_idx = min(action_idx // len(steer_actions), len(throttle_actions) - 1)

        # åˆ›å»ºæ§åˆ¶å‘½ä»¤
        car_controls = airsim.CarControls()
        car_controls.steering = steer_actions[steer_idx]
        car_controls.throttle = throttle_actions[throttle_idx]
        car_controls.brake = 0.0

        # åº”ç”¨æ§åˆ¶
        try:
            self.client.setCarControls(car_controls)
            return car_controls
        except Exception as e:
            print(f"åº”ç”¨æ§åˆ¶å‘½ä»¤å¤±è´¥: {e}")
            return car_controls

    def calculate_reward(self, current_state_info, safety_flags):
        """è®¡ç®—å¥–åŠ±å‡½æ•°"""
        if current_state_info is None:
            return 0.0

        reward = 0.0
        speed = current_state_info['speed']

        # åŸºç¡€ç§»åŠ¨å¥–åŠ±
        if speed > 0.1:
            reward += 0.1

        # ç¢°æ’æƒ©ç½š
        if safety_flags['collision']:
            reward += self.config.collision_penalty
            self.collisions += 1
            print(f"âš ï¸ å‘ç”Ÿç¢°æ’! æƒ©ç½š: {self.config.collision_penalty}")

        # ç”Ÿå­˜å¥–åŠ±
        reward += 0.01

        return reward

    def step(self, action_idx):
        """æ‰§è¡Œä¸€æ­¥ç¯å¢ƒäº¤äº’"""
        self.step_count += 1

        # è·å–å½“å‰çŠ¶æ€
        prev_image, prev_vector, prev_safety = self.get_state()

        # åº”ç”¨åŠ¨ä½œ
        control = self.apply_action(action_idx)

        # ç­‰å¾…ç¯å¢ƒå“åº”
        time.sleep(0.1)

        # è·å–æ–°çŠ¶æ€
        current_image, current_vector, current_safety = self.get_state()

        # è·å–çŠ¶æ€ä¿¡æ¯ç”¨äºè®¡ç®—å¥–åŠ±
        current_state_info = self.get_vehicle_state()

        # è®¡ç®—å¥–åŠ±
        reward = self.calculate_reward(current_state_info, current_safety)
        self.total_reward += reward

        # æ£€æŸ¥æ˜¯å¦ç»ˆæ­¢
        done = False
        if current_safety['collision']:
            done = True
            print("ğŸ’¥ ç»ˆæ­¢: å‘ç”Ÿç¢°æ’")
        elif self.step_count >= self.config.max_steps:
            done = True
            print("â±ï¸ ç»ˆæ­¢: è¾¾åˆ°æœ€å¤§æ­¥æ•°")

        return (current_image, current_vector, reward,
                prev_image, prev_vector, done, current_safety)

    def reset(self):
        """é‡ç½®ç¯å¢ƒ"""
        self.step_count = 0
        self.total_reward = 0
        self.collisions = 0

        try:
            self.client.reset()
            time.sleep(1.0)  # ç­‰å¾…é‡ç½®å®Œæˆ
        except Exception as e:
            print(f"é‡ç½®ç¯å¢ƒå¤±è´¥: {e}")

        image_state, vector_state, safety_flags = self.get_state()

        return image_state, vector_state, safety_flags

    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        try:
            print("AirSimç¯å¢ƒå·²å…³é—­")
        except:
            pass


# ==================== è®­ç»ƒå‡½æ•° ====================
def train_dqn_safety_navigation(resume_model=None):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    config = TrainingConfig()

    # åˆ›å»ºTensorBoardè®°å½•å™¨
    log_dir = f"./logs/airsim_dqn_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    writer = SummaryWriter(log_dir)

    # åˆå§‹åŒ–ç¯å¢ƒå’Œæ™ºèƒ½ä½“
    env = AirSimSafetyEnv(config)
    agent = DQNAgent(config, device='cpu')

    # æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if resume_model and os.path.exists(resume_model):
        try:
            agent.load_model(resume_model)
            print(f"ä»æ¨¡å‹æ¢å¤è®­ç»ƒ: {resume_model}")
        except:
            print("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
    else:
        print("ä»å¤´å¼€å§‹è®­ç»ƒ")

    # è¿æ¥AirSimæœåŠ¡å™¨
    print("\n" + "=" * 60)
    print("æ­£åœ¨è¿æ¥AirSimæœåŠ¡å™¨...")

    if not env.connect():
        print("æ— æ³•è¿æ¥åˆ°AirSimæœåŠ¡å™¨ï¼Œé€€å‡ºè®­ç»ƒ")
        return

    print("=" * 60)

    # è®­ç»ƒå¾ªç¯
    print(f"\nå¼€å§‹æ·±åº¦å¼ºåŒ–å­¦ä¹ å®‰å…¨å¯¼èˆªè®­ç»ƒ")
    print(f"æ€»å›åˆæ•°: {config.total_episodes}")
    print(f"æœ€å¤§æ­¥æ•°: {config.max_steps}")
    print(f"è®¾å¤‡: {agent.device}")
    print("=" * 60)

    for episode in range(config.total_episodes):
        # é‡ç½®ç¯å¢ƒ
        try:
            image_state, vector_state, safety_flags = env.reset()
        except Exception as e:
            print(f"é‡ç½®ç¯å¢ƒå¤±è´¥: {e}")
            break

        episode_reward = 0
        episode_steps = 0
        episode_losses = []
        episode_start_time = time.time()

        # å›åˆå¾ªç¯
        done = False
        while not done and episode_steps < config.max_steps:
            try:
                # é€‰æ‹©åŠ¨ä½œ
                action = agent.select_action(image_state, vector_state)

                # æ‰§è¡ŒåŠ¨ä½œï¼Œè·å–æ–°çŠ¶æ€å’Œå¥–åŠ±
                (next_image, next_vector, reward,
                 prev_image, prev_vector, done, next_safety) = env.step(action)

                # å­˜å‚¨ç»éªŒ
                experience = (
                    prev_image, prev_vector, action, reward,
                    next_image, next_vector, done
                )
                agent.memory.push(experience)

                # è®­ç»ƒæ™ºèƒ½ä½“
                if agent.steps_done % config.update_every == 0:
                    loss = agent.train_step()
                    if loss > 0:
                        episode_losses.append(loss)

                # æ›´æ–°çŠ¶æ€
                image_state, vector_state = next_image, next_vector
                episode_reward += reward
                episode_steps += 1
                agent.steps_done += 1

                # ç®€å•è¿›åº¦æ˜¾ç¤º
                if episode_steps % 10 == 0:
                    print(f"  æ­¥æ•°: {episode_steps}, å¥–åŠ±: {episode_reward:.2f}, æ¢ç´¢ç‡: {agent.epsilon:.3f}")

            except Exception as e:
                print(f"å›åˆæ‰§è¡Œå‡ºé”™: {e}")
                done = True

        # è®¡ç®—å›åˆç»Ÿè®¡
        episode_time = time.time() - episode_start_time
        avg_loss = np.mean(episode_losses) if episode_losses else 0

        # è®°å½•è®­ç»ƒæ•°æ®
        writer.add_scalar('Reward/Episode', episode_reward, episode)
        writer.add_scalar('Loss/Episode', avg_loss, episode)
        writer.add_scalar('Exploration/Epsilon', agent.epsilon, episode)
        writer.add_scalar('Steps/Episode_Steps', episode_steps, episode)

        # æ‰“å°å›åˆæ€»ç»“
        print(f"\nå›åˆ {episode + 1}/{config.total_episodes}")
        print(f"  æ€»å¥–åŠ±: {episode_reward:.2f}")
        print(f"  æ­¥æ•°: {episode_steps}")
        print(f"  æ—¶é—´: {episode_time:.1f}s")
        print(f"  å¹³å‡æŸå¤±: {avg_loss:.4f}")
        print(f"  ç¢°æ’æ¬¡æ•°: {env.collisions}")
        print(f"  æ¢ç´¢ç‡: {agent.epsilon:.3f}")

        # ä¿å­˜æ¨¡å‹
        if (episode + 1) % config.save_interval == 0:
            agent.save_model(episode + 1)

        # æ›´æ–°ç›®æ ‡ç½‘ç»œ
        if (episode + 1) % 5 == 0:
            agent.update_target_network()

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    agent.save_model(config.total_episodes)

    # å…³é—­ç¯å¢ƒ
    env.close()
    writer.close()

    print("\n" + "=" * 60)
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {config.model_save_path}")
    print(f"è®­ç»ƒæ—¥å¿—: {log_dir}")
    print("=" * 60)


# ==================== è¯„ä¼°å‡½æ•° ====================
def evaluate_model(model_path, eval_episodes=3):
    """è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹"""
    config = TrainingConfig()
    env = AirSimSafetyEnv(config)
    agent = DQNAgent(config, device='cpu')

    # åŠ è½½æ¨¡å‹
    try:
        agent.load_model(model_path)
        agent.epsilon = 0.01  # è¯„ä¼°æ—¶æ¢ç´¢ç‡ä½
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # è¿æ¥ç¯å¢ƒ
    if not env.connect():
        print("æ— æ³•è¿æ¥åˆ°AirSimæœåŠ¡å™¨")
        return

    results = []

    for episode in range(eval_episodes):
        # é‡ç½®ç¯å¢ƒ
        image_state, vector_state, _ = env.reset()

        episode_reward = 0
        episode_steps = 0

        done = False
        while not done and episode_steps < config.max_steps:
            try:
                # é€‰æ‹©åŠ¨ä½œï¼ˆè¯„ä¼°æ¨¡å¼ï¼‰
                action = agent.select_action(image_state, vector_state, eval_mode=True)

                # æ‰§è¡ŒåŠ¨ä½œ
                (next_image, next_vector, reward,
                 _, _, done, _) = env.step(action)

                # æ›´æ–°
                image_state, vector_state = next_image, next_vector
                episode_reward += reward
                episode_steps += 1

                # ç®€å•æ˜¾ç¤º
                if episode_steps % 10 == 0:
                    print(f"  è¯„ä¼°æ­¥æ•°: {episode_steps}, å¥–åŠ±: {episode_reward:.2f}")

            except Exception as e:
                print(f"è¯„ä¼°å‡ºé”™: {e}")
                done = True

        results.append({
            'episode': episode + 1,
            'reward': episode_reward,
            'steps': episode_steps,
        })

        print(f"è¯„ä¼°å›åˆ {episode + 1}/{eval_episodes}: å¥–åŠ±={episode_reward:.2f}")

    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    if results:
        avg_reward = np.mean([r['reward'] for r in results])

        print("\n" + "=" * 60)
        print("è¯„ä¼°ç»“æœæ€»ç»“:")
        print(f"å¹³å‡å›åˆå¥–åŠ±: {avg_reward:.2f}")
        print("=" * 60)

    env.close()


# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    import warnings
    warnings.filterwarnings('ignore')

    print("=" * 70)
    print("åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„AirSimè‡ªåŠ¨é©¾é©¶å®‰å…¨å¯¼èˆªç³»ç»Ÿ")
    print("ç‰ˆæœ¬ï¼šå…¼å®¹æ—§ç‰ˆAirSimæœåŠ¡å™¨ (1.2.6)")
    print("=" * 70)

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs('./models', exist_ok=True)
    os.makedirs('./logs', exist_ok=True)

    # æ£€æŸ¥PyTorch
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    if torch.cuda.is_available():
        print(f"æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("å°†ä½¿ç”¨CPUè¿è¡Œ")

    # ç”¨æˆ·é€‰æ‹©
    choice = None
    valid_choices = ['1', '2', '3']

    while choice not in valid_choices:
        print("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. è®­ç»ƒæ–°æ¨¡å‹ (æ¨èå…ˆæµ‹è¯•è¿æ¥)")
        print("2. æ¢å¤è®­ç»ƒ")
        print("3. è¯„ä¼°æ¨¡å‹")

        user_input = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()

        if user_input:
            first_char = user_input[0]
            if first_char in valid_choices:
                choice = first_char
            else:
                print(f"é”™è¯¯: è¾“å…¥ '{user_input}' æ— æ•ˆã€‚è¯·è¾“å…¥ 1, 2 æˆ– 3ã€‚")
        else:
            print("é”™è¯¯: è¾“å…¥ä¸èƒ½ä¸ºç©ºã€‚è¯·è¾“å…¥ 1, 2 æˆ– 3ã€‚")

    # æ ¹æ®é€‰æ‹©æ‰§è¡Œ
    if choice == '1':
        print("\n" + "=" * 60)
        print("é‡è¦æç¤º:")
        print("1. è¯·ç¡®ä¿AirSimä»¿çœŸç¯å¢ƒæ­£åœ¨è¿è¡Œ")
        print("2. å·²é€‰æ‹©æ±½è½¦æ¨¡å¼ (Car Mode)")
        print("3. åˆå§‹è®­ç»ƒåªæœ‰50å›åˆï¼Œç”¨äºæµ‹è¯•è¿æ¥")
        print("=" * 60)

        confirm = input("\nç¡®è®¤AirSimç¯å¢ƒå·²å¯åŠ¨ï¼Ÿ(y/n): ").strip().lower()
        if confirm == 'y':
            train_dqn_safety_navigation()
        else:
            print("è¯·å…ˆå¯åŠ¨AirSimç¯å¢ƒå†è¿è¡Œç¨‹åº")
    elif choice == '2':
        model_path = None
        while not model_path:
            model_path = input("è¯·è¾“å…¥æ¨¡å‹è·¯å¾„ (ä¾‹å¦‚: ./models/airsim_dqn_episode_10.pth): ").strip()
            if not model_path:
                print("é”™è¯¯: è¾“å…¥ä¸èƒ½ä¸ºç©ºã€‚")
                continue

            if os.path.exists(model_path):
                print(f"ä»æ¨¡å‹æ¢å¤è®­ç»ƒ: {model_path}")
                train_dqn_safety_navigation(resume_model=model_path)
            else:
                print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                model_path = None
    elif choice == '3':
        model_path = None
        while not model_path:
            model_path = input("è¯·è¾“å…¥è¦è¯„ä¼°çš„æ¨¡å‹è·¯å¾„: ").strip()
            if not model_path:
                print("é”™è¯¯: è¾“å…¥ä¸èƒ½ä¸ºç©ºã€‚")
                continue

            if os.path.exists(model_path):
                print(f"è¯„ä¼°æ¨¡å‹: {model_path}")
                evaluate_model(model_path)
            else:
                print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                model_path = None


                # åœ¨ä»£ç å¼€å¤´æ·»åŠ æµ‹è¯•å‡½æ•°
                def test_airsim_connection():
                    """æµ‹è¯•AirSimè¿æ¥"""
                    try:
                        import airsim
                        client = airsim.CarClient()
                        client.confirmConnection()
                        print("âœ“ æˆåŠŸè¿æ¥åˆ°AirSimæœåŠ¡å™¨ï¼")

                        # è·å–è½¦è¾†çŠ¶æ€
                        state = client.getCarState()
                        print(f"è½¦è¾†é€Ÿåº¦: {state.speed}")

                        client.enableApiControl(True)
                        print("APIæ§åˆ¶å·²å¯ç”¨")

                        return True
                    except Exception as e:
                        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
                        print("\nè¯·ç¡®ä¿:")
                        print("1. AirSimä»¿çœŸç¯å¢ƒæ­£åœ¨è¿è¡Œ")
                        print("2. å·²é€‰æ‹©æ±½è½¦æ¨¡å¼")
                        print("3. AirSimæœåŠ¡å™¨IPåœ°å€æ­£ç¡®")
                        return False


                # åœ¨ä¸»ç¨‹åºä¸­è°ƒç”¨
                if __name__ == "__main__":
                    print("æµ‹è¯•AirSimè¿æ¥...")
                    if test_airsim_connection():
                        print("\nè¿æ¥æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
                    else:
                        print("\nè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥AirSimç¯å¢ƒã€‚")