import carla
import queue
import random
import cv2
import numpy as np

from what.models.detection.datasets.coco import COCO_CLASS_NAMES
from utils.box_utils import draw_bounding_boxes
from utils.projection import *
from utils.world import *

# -------------------------- æ–°å¢ï¼šè½¦è¾†ç±»å‹ã€è·ç¦»ã€é€Ÿåº¦ç»Ÿè®¡å·¥å…·å‡½æ•° --------------------------
def get_vehicle_brand_type(actor):
    """æå–è½¦è¾†çš„å“ç‰Œå’Œè½¦å‹ï¼ˆä»type_idä¸­è§£æï¼Œå¦‚vehicle.lincoln.mkz â†’ Lincoln MKZï¼‰"""
    try:
        parts = actor.type_id.split('.')
        if len(parts) >= 3:
            brand = parts[1].capitalize()
            model = parts[2].upper()
            return f"{brand} {model}"
        return "Unknown Vehicle"
    except:
        return "Unknown Vehicle"

def get_vehicle_speed(vehicle):
    """è·å–è½¦è¾†çš„é€Ÿåº¦ï¼ˆkm/hï¼‰"""
    try:
        velocity = vehicle.get_velocity()
        # è½¬æ¢ä¸ºkm/hï¼šé€Ÿåº¦å‘é‡çš„æ¨¡ Ã— 3.6ï¼ˆm/s â†’ km/hï¼‰
        speed = np.sqrt(velocity.x**2 + velocity.y**2 + velocity.z**2) * 3.6
        return round(speed, 1)
    except:
        return 0.0

def calculate_vehicle_stats(vehicle_data):
    """ç»Ÿè®¡è½¦è¾†ç±»å‹ã€è·ç¦»åŒºé—´ã€é€Ÿåº¦åŒºé—´"""
    # 1. è½¦è¾†ç±»å‹ç»Ÿè®¡
    type_count = {}
    # 2. è·ç¦»åŒºé—´ç»Ÿè®¡ï¼ˆ0-10m, 10-20m, 20-30m, 30-40m, 40-50mï¼‰
    distance_ranges = {"0-10m": 0, "10-20m": 0, "20-30m": 0, "30-40m": 0, "40-50m": 0}
    # 3. é€Ÿåº¦åŒºé—´ç»Ÿè®¡ï¼ˆ0-10km/h, 10-20km/h, 20-30km/h, >30km/hï¼‰
    speed_ranges = {"0-10km/h": 0, "10-20km/h": 0, "20-30km/h": 0, ">30km/h": 0}

    for _, v_type, dist, speed in vehicle_data:
        # ç±»å‹ç»Ÿè®¡
        type_count[v_type] = type_count.get(v_type, 0) + 1
        # è·ç¦»åŒºé—´ç»Ÿè®¡
        if dist < 10:
            distance_ranges["0-10m"] += 1
        elif dist < 20:
            distance_ranges["10-20m"] += 1
        elif dist < 30:
            distance_ranges["20-30m"] += 1
        elif dist < 40:
            distance_ranges["30-40m"] += 1
        else:
            distance_ranges["40-50m"] += 1
        # é€Ÿåº¦åŒºé—´ç»Ÿè®¡
        if speed < 10:
            speed_ranges["0-10km/h"] += 1
        elif speed < 20:
            speed_ranges["10-20km/h"] += 1
        elif speed < 30:
            speed_ranges["20-30km/h"] += 1
        else:
            speed_ranges[">30km/h"] += 1

    return type_count, distance_ranges, speed_ranges

def calculate_perception_stats(vehicle_distances, valid_boxes_count):
    """åŸºç¡€æ„ŸçŸ¥ç»Ÿè®¡ï¼ˆæ€»è½¦è¾†æ•°ã€å¹³å‡è·ç¦»ç­‰ï¼‰"""
    stats = {
        "total_vehicles": len(vehicle_distances),
        "valid_boxes": valid_boxes_count,
        "avg_distance": np.mean(vehicle_distances) if vehicle_distances else 0.0,
        "max_distance": np.max(vehicle_distances) if vehicle_distances else 0.0,
        "avg_speed": np.mean([d[3] for d in vehicle_data]) if vehicle_data else 0.0  # å¹³å‡é€Ÿåº¦
    }
    return stats

# -------------------------- å°æ¡†å›¾æ ¸å¿ƒå‡½æ•°ï¼ˆæ›¿æ¢ä¸ºæ–°çš„ç»Ÿè®¡ç»´åº¦ï¼‰ --------------------------
def create_small_view_layout(main_img, base_stats, vehicle_data, type_count, distance_ranges, speed_ranges, CAMERA_WIDTH=640, CAMERA_HEIGHT=640):
    """ä¸»è§†å›¾+å³ä¾§ç»Ÿè®¡é¢æ¿ï¼ˆè½¦è¾†ç±»å‹ã€è·ç¦»ã€é€Ÿåº¦ç»Ÿè®¡ï¼‰"""
    canvas_width = CAMERA_WIDTH + 350
    canvas_height = CAMERA_HEIGHT
    canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 240  # æµ…ç°è‰²èƒŒæ™¯

    # 1. ä¸»è§†å›¾ï¼ˆå·¦ä¾§640x640ï¼‰
    canvas[:CAMERA_HEIGHT, :CAMERA_WIDTH, :] = main_img

    # 2. å³ä¾§ç»Ÿè®¡é¢æ¿
    panel_x_start = CAMERA_WIDTH + 20
    # æ ‡é¢˜
    cv2.putText(canvas, "Vehicle Perception Stats", (panel_x_start, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    # åŸºç¡€ç»Ÿè®¡æ•°æ®
    base_stats_text = [
        f"Total Vehicles (50m): {base_stats['total_vehicles']}",
        f"Valid 2D Boxes: {base_stats['valid_boxes']}",
        f"Avg Distance: {base_stats['avg_distance']:.1f}m",
        f"Max Distance: {base_stats['max_distance']:.1f}m",
        f"Avg Speed: {base_stats['avg_speed']:.1f}km/h"
    ]
    y_start = 70
    line_height = 30
    for text in base_stats_text:
        cv2.putText(canvas, text, (panel_x_start, y_start), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        y_start += line_height

    # -------------------------- ç»Ÿè®¡1ï¼šè½¦è¾†ç±»å‹ï¼ˆå‰5ç§ï¼Œé¿å…è¿‡é•¿ï¼‰ --------------------------
    cv2.putText(canvas, "Vehicle Type (Top5)", (panel_x_start, y_start + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    y_start += 40
    # æŒ‰æ•°é‡æ’åºï¼Œå–å‰5ç§
    sorted_types = sorted(type_count.items(), key=lambda x: x[1], reverse=True)[:5]
    for v_type, count in sorted_types:
        if y_start > 220:  # ä¸ºåç»­ç»Ÿè®¡ç•™å‡ºç©ºé—´
            break
        # ç¼©çŸ­è¿‡é•¿çš„è½¦å‹åç§°ï¼ˆé¿å…è¶…å‡ºé¢æ¿ï¼‰
        display_type = v_type if len(v_type) <= 15 else v_type[:12] + "..."
        text = f"{display_type}: {count} vehicles"
        cv2.putText(canvas, text, (panel_x_start, y_start), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 0), 1)
        y_start += 25

    # -------------------------- ç»Ÿè®¡2ï¼šè·ç¦»åŒºé—´ï¼ˆå½©è‰²è¿›åº¦æ¡æ˜¾ç¤ºï¼‰ --------------------------
    cv2.putText(canvas, "Distance Distribution", (panel_x_start, y_start + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    y_start += 40
    # è·ç¦»åŒºé—´é¢œè‰²æ˜ å°„ï¼ˆä¸åŒåŒºé—´ä¸åŒé¢œè‰²ï¼‰
    dist_color_map = {
        "0-10m": (0, 0, 255), "10-20m": (0, 165, 255), "20-30m": (0, 255, 255),
        "30-40m": (0, 255, 0), "40-50m": (255, 0, 0)
    }
    for dist_range, count in distance_ranges.items():
        if y_start > 350:
            break
        # ç»˜åˆ¶å½©è‰²å°æ–¹å—
        color = dist_color_map.get(dist_range, (128, 128, 128))
        sq_x1 = panel_x_start
        sq_y1 = y_start - 8
        sq_x2 = panel_x_start + 15
        sq_y2 = y_start + 8
        cv2.rectangle(canvas, (sq_x1, sq_y1), (sq_x2, sq_y2), color, -1)
        cv2.rectangle(canvas, (sq_x1, sq_y1), (sq_x2, sq_y2), (0, 0, 0), 1)
        # ç»˜åˆ¶è·ç¦»åŒºé—´å’Œæ•°é‡
        text = f"{dist_range}: {count} vehicles"
        cv2.putText(canvas, text, (panel_x_start + 20, y_start + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 0), 1)
        y_start += 25

    # -------------------------- ç»Ÿè®¡3ï¼šé€Ÿåº¦åŒºé—´ï¼ˆå½©è‰²è¿›åº¦æ¡æ˜¾ç¤ºï¼‰ --------------------------
    cv2.putText(canvas, "Speed Distribution", (panel_x_start, y_start + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    y_start += 40
    # é€Ÿåº¦åŒºé—´é¢œè‰²æ˜ å°„
    speed_color_map = {
        "0-10km/h": (128, 128, 128), "10-20km/h": (0, 255, 0),
        "20-30km/h": (0, 255, 255), ">30km/h": (0, 0, 255)
    }
    for speed_range, count in speed_ranges.items():
        if y_start > canvas_height - 20:
            break
        # ç»˜åˆ¶å½©è‰²å°æ–¹å—
        color = speed_color_map.get(speed_range, (128, 128, 128))
        sq_x1 = panel_x_start
        sq_y1 = y_start - 8
        sq_x2 = panel_x_start + 15
        sq_y2 = y_start + 8
        cv2.rectangle(canvas, (sq_x1, sq_y1), (sq_x2, sq_y2), color, -1)
        cv2.rectangle(canvas, (sq_x1, sq_y1), (sq_x2, sq_y2), (0, 0, 0), 1)
        # ç»˜åˆ¶é€Ÿåº¦åŒºé—´å’Œæ•°é‡
        text = f"{speed_range}: {count} vehicles"
        cv2.putText(canvas, text, (panel_x_start + 20, y_start + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 0), 1)
        y_start += 25

    return canvas

# -------------------------- åŸå§‹ä»£ç ï¼šç›¸æœºå›è°ƒå‡½æ•° --------------------------
def camera_callback(image, rgb_image_queue):
    rgb_image_queue.put(np.reshape(np.copy(image.raw_data),
                        (image.height, image.width, 4)))

# -------------------------- ä¸»ç¨‹åºï¼ˆæ›¿æ¢ä¸ºæ–°çš„ç»Ÿè®¡ç»´åº¦ï¼‰ --------------------------
def main():
    # 1. è¿æ¥CARLAå¹¶è®¾ç½®è¶…æ—¶
    client = carla.Client('localhost', 2000)
    client.set_timeout(60.0)
    world = client.get_world()

    # 2. é…ç½®ä»¿çœŸç¯å¢ƒï¼ˆåŒæ­¥æ¨¡å¼+Traffic Managerï¼‰
    settings = world.get_settings()
    settings.synchronous_mode = True
    settings.fixed_delta_seconds = 0.05
    world.apply_settings(settings)

    # åˆå§‹åŒ–Traffic Managerï¼ˆè½¦è¾†ç§»åŠ¨æ ¸å¿ƒï¼‰
    tm = client.get_trafficmanager(8000)
    tm.set_global_distance_to_leading_vehicle(2.0)
    tm.set_random_device_seed(42)
    tm.global_percentage_speed_difference(20)  # è½¦è¾†é€Ÿåº¦80%é™é€Ÿ

    # 3. è·å–å‡ºç”Ÿç‚¹å¹¶ç”Ÿæˆä¸»è§’è½¦è¾†
    spawn_points = world.get_map().get_spawn_points()
    if not spawn_points:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„å‡ºç”Ÿç‚¹ï¼")
        return

    bp_lib = world.get_blueprint_library()
    vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2017')  # æ›´æ¢ä¸ºæ›´å¸¸è§çš„è½¦å‹
    ego_vehicle = None
    for sp in random.sample(spawn_points, min(10, len(spawn_points))):
        ego_vehicle = world.try_spawn_actor(vehicle_bp, sp)
        if ego_vehicle:
            break
    if not ego_vehicle:
        print("âŒ ä¸»è§’è½¦è¾†ç”Ÿæˆå¤±è´¥ï¼")
        return
    ego_vehicle.set_autopilot(True, tm.get_port())

    # 4. ç”Ÿæˆç›¸æœºï¼ˆä¿ç•™åŸå§‹å‚æ•°ï¼‰
    camera_bp = bp_lib.find('sensor.camera.rgb')
    camera_bp.set_attribute('image_size_x', '640')
    camera_bp.set_attribute('image_size_y', '640')
    camera_init_trans = carla.Transform(carla.Location(x=1, z=2))
    camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=ego_vehicle)
    image_queue = queue.Queue()
    camera.listen(lambda image: camera_callback(image, image_queue))

    # 5. æ¸…ç†æ—§NPCå¹¶ç”Ÿæˆæ–°NPCï¼ˆç”Ÿæˆä¸åŒå“ç‰Œçš„è½¦è¾†ï¼Œä¸°å¯Œç±»å‹ç»Ÿè®¡ï¼‰
    clear_npc(world)
    clear_static_vehicle(world)

    # é€‰æ‹©ä¸åŒå“ç‰Œçš„è½¦è¾†è“å›¾ï¼ˆä¸°å¯Œç±»å‹ç»Ÿè®¡ï¼‰
    vehicle_blueprints = [
        bp for bp in bp_lib.filter('vehicle')
        if int(bp.get_attribute('number_of_wheels')) == 4 and
        not bp.id.endswith('cycle') and not bp.id.endswith('motorcycle')
    ]
    # ç”Ÿæˆ50è¾†NPCè½¦è¾†ï¼ˆä¸åŒå“ç‰Œï¼‰
    for i in range(50):
        if not vehicle_blueprints:
            break
        npc_bp = random.choice(vehicle_blueprints)
        npc_vehicle = None
        # éå†å¤šä¸ªå‡ºç”Ÿç‚¹ï¼Œç¡®ä¿NPCç”ŸæˆæˆåŠŸ
        for sp in random.sample(spawn_points, min(5, len(spawn_points))):
            npc_vehicle = world.try_spawn_actor(npc_bp, sp)
            if npc_vehicle:
                break
        if npc_vehicle:
            npc_vehicle.set_autopilot(True, tm.get_port())

    # 6. åˆå§‹åŒ– spectator è§†è§’
    spectator = world.get_spectator()
    edges = [[0, 1], [1, 3], [3, 2], [2, 0], [0, 4], [4, 5],
             [5, 1], [5, 7], [7, 6], [6, 4], [6, 2], [7, 3]]

    # 7. ä¸»å¾ªç¯ï¼ˆè½¦è¾†æ„ŸçŸ¥æ ¸å¿ƒï¼‰
    try:
        while True:
            world.tick()

            # æ›´æ–° spectator è§†è§’ï¼ˆè·Ÿéšä¸»è§’è½¦è¾†ï¼‰
            transform = carla.Transform(ego_vehicle.get_transform().transform(
                carla.Location(x=-4, z=50)), carla.Rotation(yaw=-180, pitch=-90))
            spectator.set_transform(transform)

            # è·å–ç›¸æœºå›¾åƒï¼ˆè·³è¿‡ç©ºé˜Ÿåˆ—ï¼‰
            if image_queue.empty():
                continue
            image = image_queue.get()

            # æ›´æ–°æŠ•å½±çŸ©é˜µï¼ˆæ¯å¸§æ›´æ–°ï¼Œç¡®ä¿æŠ•å½±å‡†ç¡®ï¼‰
            world_2_camera = np.array(camera.get_transform().get_inverse_matrix())
            image_w = camera_bp.get_attribute("image_size_x").as_int()
            image_h = camera_bp.get_attribute("image_size_y").as_int()
            fov = camera_bp.get_attribute("fov").as_float()
            K = build_projection_matrix(image_w, image_h, fov)
            K_b = build_projection_matrix(image_w, image_h, fov, is_behind_camera=True)

            boxes = []
            ids = []
            vehicle_data = []  # æ ¼å¼ï¼š(id, type, distance, speed)
            vehicle_distances = []

            # éå†æ‰€æœ‰è½¦è¾†ï¼ˆç­›é€‰+æŠ•å½±ï¼‰
            for npc in world.get_actors().filter('*vehicle*'):
                if npc.id == ego_vehicle.id:
                    continue

                bb = npc.bounding_box
                dist = npc.get_transform().location.distance(ego_vehicle.get_transform().location)

                # è¿‡æ»¤1ï¼š50ç±³å†…
                if dist > 50:
                    continue

                # è¿‡æ»¤2ï¼šæ­£å‰æ–¹ï¼ˆå‘é‡å•ä½åŒ–ï¼Œç‚¹ç§¯é˜ˆå€¼0.1ï¼‰
                forward_vec = ego_vehicle.get_transform().get_forward_vector()
                ray = npc.get_transform().location - ego_vehicle.get_transform().location
                ray = ray.make_unit_vector()
                dot_product = forward_vec.dot(ray)
                if dot_product <= 0.1:
                    continue

                # 3Dè½¬2DæŠ•å½±ï¼ˆè¿‡æ»¤æ— æ•ˆç‚¹ï¼‰
                verts = [v for v in bb.get_world_vertices(npc.get_transform())]
                points_2d = []
                for vert in verts:
                    ray0 = vert - camera.get_transform().location
                    cam_forward_vec = camera.get_transform().get_forward_vector()
                    if cam_forward_vec.dot(ray0) > 0:
                        p = get_image_point(vert, K, world_2_camera)
                    else:
                        p = get_image_point(vert, K_b, world_2_camera)
                    if not (np.isnan(p[0]) or np.isnan(p[1])):
                        points_2d.append(p)

                # è‡³å°‘4ä¸ªæœ‰æ•ˆç‚¹æ‰è®¡ç®—è¾¹ç•Œæ¡†
                if len(points_2d) < 4:
                    continue

                x_min, x_max, y_min, y_max = get_2d_box_from_3d_edges(points_2d, edges, image_h, image_w)
                box_width = x_max - x_min
                box_height = y_max - y_min
                box_area = box_width * box_height

                # è¿‡æ»¤æ— æ•ˆå°æ¡†ï¼ˆé™ä½é˜ˆå€¼ï¼Œé¿å…æ¼æ£€ï¼‰
                if box_area > 50 and box_width > 10:
                    if point_in_canvas((x_min, y_min), image_h, image_w) and point_in_canvas((x_max, y_max), image_h, image_w):
                        ids.append(npc.id)
                        boxes.append(np.array([x_min, y_min, x_max, y_max]))
                        # æ”¶é›†è½¦è¾†ç±»å‹ã€è·ç¦»ã€é€Ÿåº¦ï¼ˆæ ¸å¿ƒï¼šæ–°çš„ç»Ÿè®¡æ•°æ®ï¼‰
                        v_type = get_vehicle_brand_type(npc)
                        v_speed = get_vehicle_speed(npc)
                        vehicle_data.append((npc.id, v_type, dist, v_speed))
                        vehicle_distances.append(dist)

            # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆä¿ç•™åŸå§‹è°ƒç”¨ï¼‰
            boxes = np.array(boxes)
            labels = np.array([2] * len(boxes))
            probs = np.array([1.0] * len(boxes))
            output_image = image
            if len(boxes) > 0:
                output_image = draw_bounding_boxes(image, boxes, labels, COCO_CLASS_NAMES, ids)

            # è®¡ç®—ç»Ÿè®¡æ•°æ®ï¼ˆæ–°çš„ç»´åº¦ï¼‰
            type_count, distance_ranges, speed_ranges = calculate_vehicle_stats(vehicle_data)
            # åŸºç¡€ç»Ÿè®¡ï¼ˆè¡¥å……å¹³å‡é€Ÿåº¦ï¼‰
            base_stats = {
                "total_vehicles": len(vehicle_distances),
                "valid_boxes": len(boxes),
                "avg_distance": np.mean(vehicle_distances) if vehicle_distances else 0.0,
                "max_distance": np.max(vehicle_distances) if vehicle_distances else 0.0,
                "avg_speed": np.mean([d[3] for d in vehicle_data]) if vehicle_data else 0.0
            }

            # ç”Ÿæˆå°æ¡†å›¾å¹¶æ˜¾ç¤º
            if output_image.shape[-1] == 4:
                main_img = output_image[:, :, :3].astype(np.uint8)
            else:
                main_img = output_image.astype(np.uint8)
            canvas = create_small_view_layout(main_img, base_stats, vehicle_data, type_count, distance_ranges, speed_ranges, image_w, image_h)
            cv2.imshow('2D Ground Truth (Vehicle Stats)', canvas)

            # é€€å‡ºæ¡ä»¶ï¼šæŒ‰qé”®
            if cv2.waitKey(1) == ord('q'):
                break

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        # æ¸…ç†èµ„æºï¼ˆæ¢å¤å¼‚æ­¥æ¨¡å¼ï¼‰
        settings.synchronous_mode = False
        world.apply_settings(settings)
        clear(world, camera)
        ego_vehicle.destroy()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    main()