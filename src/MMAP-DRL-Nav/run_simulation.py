# 1. å¯¼å…¥æ¨¡å—ï¼ˆæ–°å¢ cv2 å’Œ os ç”¨äºå›¾åƒä¿å­˜ï¼‰
import torch
import time
import numpy as np
import cv2  # ç”¨äºå›¾åƒä¿å­˜
import os   # ç”¨äºåˆ›å»ºç›®å½•
from models.perception_module import PerceptionModule
from models.attention_module import CrossDomainAttention
from models.decision_module import DecisionModule
from models.dqn_agent import DQNAgent
from envs.carla_environment import CarlaEnvironment
import carla

# 2. å®šä¹‰ IntegratedSystem ç±»
class IntegratedSystem:
    def __init__(self, device='cpu'):
        self.device = device
        self.perception = PerceptionModule().to(self.device)
        # è¡¥å…… input_dims å‚æ•°ï¼ˆä¸æ„ŸçŸ¥æ¨¡å—è¾“å‡ºç»´åº¦åŒ¹é…ï¼‰
        self.attention = CrossDomainAttention(
            num_blocks=6,
            input_dims=[256, 256, 6, 256, 256]
        ).to(self.device)
        self.decision = DecisionModule().to(self.device)

    def forward(self, image, lidar_data, imu_data):
        scene_info, segmentation, odometry, obstacles, boundary = self.perception(imu_data, image, lidar_data)
        fused_features = self.attention(scene_info, segmentation, odometry, obstacles, boundary)
        policy, value = self.decision(fused_features)
        return policy, value

# 3. å®šä¹‰ä¼ æ„Ÿå™¨æ•°æ®é€‚é…å‡½æ•°ï¼ˆæ¡¥æ¥CARLAå’Œæ¨¡å‹ï¼‰
def adapt_sensor_data(env, system):
    """
    ä»CARLAç¯å¢ƒè·å–çœŸå®å›¾åƒï¼Œè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
    ï¼ˆLiDAR/IMUæš‚ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œåç»­å¯æ‰©å±•ä¸ºçœŸå®ä¼ æ„Ÿå™¨ï¼‰
    """
    # 1. è·å–CARLAçœŸå®ç›¸æœºå›¾åƒ (128, 128, 3) â†’ é€‚é…æ¨¡å‹è¾“å…¥
    raw_image = env.get_observation()  # çœŸå®RGBå›¾åƒ
    # è½¬æ¢æ ¼å¼ï¼šHWC(128,128,3) â†’ CHW(3,128,128) â†’ ç¼©æ”¾è‡³256Ã—256ï¼ˆåŒ¹é…æ¨¡å‹è¾“å…¥ï¼‰
    image = torch.FloatTensor(raw_image).permute(2, 0, 1).unsqueeze(0) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
    image = torch.nn.functional.interpolate(image, size=(256, 256), mode='bilinear')  # ç¼©æ”¾è‡³256Ã—256
    image = image.to(system.device)
    
    # 2. æ¨¡æ‹ŸLiDARæ•°æ®ï¼ˆåç»­éœ€æ·»åŠ CARLA LiDARä¼ æ„Ÿå™¨ï¼‰
    lidar_data = torch.randn(1, 256, 256).unsqueeze(0).to(system.device)
    
    # 3. æ¨¡æ‹ŸIMUæ•°æ®ï¼ˆåç»­éœ€æ·»åŠ CARLA IMUä¼ æ„Ÿå™¨ï¼‰
    imu_data = torch.randn(1, 6).to(system.device)
    
    return image, lidar_data, imu_data, raw_image  # æ–°å¢è¿”å›åŸå§‹å›¾åƒ

# 4. å®šä¹‰å›¾åƒä¿å­˜å‡½æ•°
def save_camera_image(raw_image, step, save_dir="carla_camera_images"):
    """
    ä¿å­˜CARLAç›¸æœºåŸå§‹å›¾åƒåˆ°æœ¬åœ°
    :param raw_image: åŸå§‹RGBå›¾åƒ (128, 128, 3)
    :param step: ä»¿çœŸæ­¥æ•°
    :param save_dir: ä¿å­˜ç›®å½•
    """
    # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # è½¬æ¢RGBæ ¼å¼ä¸ºOpenCVçš„BGRæ ¼å¼ï¼ˆOpenCVé»˜è®¤BGRï¼‰
    image_bgr = cv2.cvtColor(raw_image, cv2.COLOR_RGB2BGR)
    
    # å®šä¹‰ä¿å­˜è·¯å¾„
    save_path = os.path.join(save_dir, f"camera_step_{step:03d}.png")  # 03d è¡¥é›¶ï¼Œå¦‚ 001, 002
    
    # ä¿å­˜å›¾åƒ
    cv2.imwrite(save_path, image_bgr)
    
    # æ‰“å°ä¿å­˜æ—¥å¿—
    print(f"ğŸ“¸ ç¬¬ {step} æ­¥ç›¸æœºå›¾åƒå·²ä¿å­˜ï¼š{save_path}")

# 5. å®šä¹‰ run_simulation å‡½æ•°
def run_simulation():
    # åˆå§‹åŒ–CARLAç¯å¢ƒ
    env = CarlaEnvironment()
    # å…³é”®ï¼šè°ƒç”¨reset()ç”Ÿæˆè½¦è¾†å’Œç›¸æœºï¼Œåˆå§‹åŒ–self.vehicle
    env.reset()
    
    # æ ¡éªŒè½¦è¾†æ˜¯å¦ç”ŸæˆæˆåŠŸ
    if env.vehicle is None:
        raise RuntimeError("âŒ è½¦è¾†ç”Ÿæˆå¤±è´¥ï¼è¯·æ£€æŸ¥ï¼š\n1. CARLAæ¨¡æ‹Ÿå™¨æ˜¯å¦å¯åŠ¨\n2. ç«¯å£æ˜¯å¦ä¸º2000\n3. åœ°å›¾æ˜¯å¦åŠ è½½å®Œæˆ")
    
    # åˆå§‹åŒ–é›†æˆç³»ç»Ÿ
    system = IntegratedSystem(device='cuda' if torch.cuda.is_available() else 'cpu')
    
    print("âœ… ä»¿çœŸå¼€å§‹ï¼Œè¿è¡Œ100æ­¥...")
    # æ§åˆ¶ä¿å­˜é¢‘ç‡ï¼šæ¯”å¦‚æ¯5æ­¥ä¿å­˜ä¸€å¼ ï¼Œæˆ–åªä¿å­˜å‰10å¼ ï¼Œé¿å…æ–‡ä»¶è¿‡å¤š
    save_frequency = 5  # æ¯5æ­¥ä¿å­˜ä¸€æ¬¡
    max_save_images = 10  # æœ€å¤šä¿å­˜10å¼ å›¾åƒ
    
    saved_count = 0
    for step in range(100):
        try:
            # è·å–é€‚é…åçš„ä¼ æ„Ÿå™¨æ•°æ® + åŸå§‹å›¾åƒ
            image, lidar_data, imu_data, raw_image = adapt_sensor_data(env, system)
            
            # ä¿å­˜ç›¸æœºå›¾åƒï¼ˆæŒ‰é¢‘ç‡ä¿å­˜ï¼Œä¸”ä¸è¶…è¿‡æœ€å¤§æ•°é‡ï¼‰
            if (step + 1) % save_frequency == 0 and saved_count < max_save_images:
                save_camera_image(raw_image, step + 1)
                saved_count += 1
            
            # å‰å‘ä¼ æ’­å¾—åˆ°ç­–ç•¥
            policy, value = system.forward(image, lidar_data, imu_data)
            
            # è½¬æ¢ä¸ºCARLAæ§åˆ¶ä¿¡å·ï¼ˆé™åˆ¶èŒƒå›´é¿å…å¼‚å¸¸ï¼‰
            throttle = float(torch.clamp(policy[0][0], 0, 1))  # æ²¹é—¨èŒƒå›´[0,1]
            steer = float(torch.clamp(policy[0][1], -1, 1))    # è½¬å‘èŒƒå›´[-1,1]
            control = carla.VehicleControl(throttle=throttle, steer=steer)
            
            # åº”ç”¨æ§åˆ¶æŒ‡ä»¤åˆ°è½¦è¾†
            env.vehicle.apply_control(control)
            
            # æ‰“å°è¿è¡Œæ—¥å¿—ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
            print(f"ç¬¬ {step+1:3d} æ­¥ | æ²¹é—¨ï¼š{throttle:.2f} | è½¬å‘ï¼š{steer:.2f} | ç›¸æœºå›¾åƒåƒç´ èŒƒå›´ï¼š{raw_image.min()}~{raw_image.max()}")
            
            time.sleep(0.1)  # æ¨¡æ‹Ÿæ—¶é—´é—´éš”
            
        except Exception as e:
            print(f"âŒ ç¬¬ {step+1} æ­¥å‡ºé”™ï¼š{str(e)}")
            break
    
    # ä»¿çœŸç»“æŸï¼Œæ¸…ç†ç¯å¢ƒ
    env.close()
    print("âœ… ä»¿çœŸç»“æŸï¼Œç¯å¢ƒå·²æ¸…ç†")
    print(f"ğŸ“‚ å…±ä¿å­˜ {saved_count} å¼ ç›¸æœºå›¾åƒåˆ°ï¼šcarla_camera_images/ ç›®å½•")

# 6. ç¨‹åºå…¥å£ï¼ˆæ”¾åœ¨æœ€åï¼‰
if __name__ == "__main__":
    # æ£€æŸ¥OpenCVæ˜¯å¦å®‰è£…
    try:
        import cv2
    except ImportError:
        print("âŒ æœªå®‰è£…OpenCVï¼Œæ— æ³•ä¿å­˜å›¾åƒï¼è¯·æ‰§è¡Œï¼špip install opencv-python")
        exit(1)
    
    run_simulation()